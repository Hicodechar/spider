
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v3,1/3] x86/ldt: Make modify_ldt synchronous - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v3,1/3] x86/ldt: Make modify_ldt synchronous</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>July 22, 2015, 7:23 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;049fdbab8ae2ecac1c8b40ecd558e9df45ccd5d3.1437592883.git.luto@kernel.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6846111/mbox/"
   >mbox</a>
|
   <a href="/patch/6846111/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6846111/">/patch/6846111/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id CE7609F38B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 22 Jul 2015 19:24:22 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 33875206A2
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 22 Jul 2015 19:24:21 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 56E1320686
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 22 Jul 2015 19:24:19 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752324AbbGVTYA (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 22 Jul 2015 15:24:00 -0400
Received: from mail.kernel.org ([198.145.29.136]:38591 &quot;EHLO mail.kernel.org&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1752188AbbGVTX4 (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 22 Jul 2015 15:23:56 -0400
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 627E620686;
	Wed, 22 Jul 2015 19:23:54 +0000 (UTC)
Received: from localhost (c-71-202-137-17.hsd1.ca.comcast.net
	[71.202.137.17])
	(using TLSv1.2 with cipher AES128-GCM-SHA256 (128/128 bits))
	(No client certificate requested)
	by mail.kernel.org (Postfix) with ESMTPSA id C93B920673;
	Wed, 22 Jul 2015 19:23:52 +0000 (UTC)
From: Andy Lutomirski &lt;luto@kernel.org&gt;
To: Peter Zijlstra &lt;peterz@infradead.org&gt;,
	Steven Rostedt &lt;rostedt@goodmis.org&gt;
Cc: &quot;security@kernel.org&quot; &lt;security@kernel.org&gt;,
	X86 ML &lt;x86@kernel.org&gt;, Borislav Petkov &lt;bp@alien8.de&gt;,
	Sasha Levin &lt;sasha.levin@oracle.com&gt;, linux-kernel@vger.kernel.org,
	Konrad Rzeszutek Wilk &lt;konrad.wilk@oracle.com&gt;,
	Boris Ostrovsky &lt;boris.ostrovsky@oracle.com&gt;,
	Andrew Cooper &lt;andrew.cooper3@citrix.com&gt;,
	Jan Beulich &lt;jbeulich@suse.com&gt;, xen-devel &lt;xen-devel@lists.xen.org&gt;,
	Andy Lutomirski &lt;luto@kernel.org&gt;, stable@vger.kernel.org
Subject: [PATCH v3 1/3] x86/ldt: Make modify_ldt synchronous
Date: Wed, 22 Jul 2015 12:23:46 -0700
Message-Id: &lt;049fdbab8ae2ecac1c8b40ecd558e9df45ccd5d3.1437592883.git.luto@kernel.org&gt;
X-Mailer: git-send-email 2.4.3
In-Reply-To: &lt;cover.1437592883.git.luto@kernel.org&gt;
References: &lt;cover.1437592883.git.luto@kernel.org&gt;
In-Reply-To: &lt;cover.1437592883.git.luto@kernel.org&gt;
References: &lt;cover.1437592883.git.luto@kernel.org&gt;
X-Spam-Status: No, score=-8.1 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a> - July 22, 2015, 7:23 p.m.</div>
<pre class="content">
modify_ldt has questionable locking and does not synchronize
threads.  Improve it: redesign the locking and synchronize all
threads&#39; LDTs using an IPI on all modifications.

This will dramatically slow down modify_ldt in multithreaded
programs, but there shouldn&#39;t be any multithreaded programs that
care about modify_ldt&#39;s performance in the first place.

Cc: stable@vger.kernel.org
<span class="signed-off-by">Signed-off-by: Andy Lutomirski &lt;luto@kernel.org&gt;</span>
---
 arch/x86/include/asm/desc.h        |  15 ---
 arch/x86/include/asm/mmu.h         |   3 +-
 arch/x86/include/asm/mmu_context.h |  53 +++++++-
 arch/x86/kernel/cpu/common.c       |   4 +-
 arch/x86/kernel/cpu/perf_event.c   |  12 +-
 arch/x86/kernel/ldt.c              | 258 ++++++++++++++++++++-----------------
 arch/x86/kernel/process_64.c       |   4 +-
 arch/x86/kernel/step.c             |   6 +-
 arch/x86/power/cpu.c               |   3 +-
 9 files changed, 209 insertions(+), 149 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=60131">Boris Ostrovsky</a> - July 22, 2015, 10:20 p.m.</div>
<pre class="content">
On 07/22/2015 03:23 PM, Andy Lutomirski wrote:
<span class="quote">&gt; modify_ldt has questionable locking and does not synchronize</span>
<span class="quote">&gt; threads.  Improve it: redesign the locking and synchronize all</span>
<span class="quote">&gt; threads&#39; LDTs using an IPI on all modifications.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This will dramatically slow down modify_ldt in multithreaded</span>
<span class="quote">&gt; programs, but there shouldn&#39;t be any multithreaded programs that</span>
<span class="quote">&gt; care about modify_ldt&#39;s performance in the first place.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Cc: stable@vger.kernel.org</span>
<span class="quote">&gt; Signed-off-by: Andy Lutomirski &lt;luto@kernel.org&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;   arch/x86/include/asm/desc.h        |  15 ---</span>
<span class="quote">&gt;   arch/x86/include/asm/mmu.h         |   3 +-</span>
<span class="quote">&gt;   arch/x86/include/asm/mmu_context.h |  53 +++++++-</span>
<span class="quote">&gt;   arch/x86/kernel/cpu/common.c       |   4 +-</span>
<span class="quote">&gt;   arch/x86/kernel/cpu/perf_event.c   |  12 +-</span>
<span class="quote">&gt;   arch/x86/kernel/ldt.c              | 258 ++++++++++++++++++++-----------------</span>
<span class="quote">&gt;   arch/x86/kernel/process_64.c       |   4 +-</span>
<span class="quote">&gt;   arch/x86/kernel/step.c             |   6 +-</span>
<span class="quote">&gt;   arch/x86/power/cpu.c               |   3 +-</span>
<span class="quote">&gt;   9 files changed, 209 insertions(+), 149 deletions(-)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; diff --git a/arch/x86/include/asm/desc.h b/arch/x86/include/asm/desc.h</span>
<span class="quote">&gt; index a0bf89fd2647..4e10d73cf018 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/asm/desc.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/asm/desc.h</span>
<span class="quote">&gt; @@ -280,21 +280,6 @@ static inline void clear_LDT(void)</span>
<span class="quote">&gt;   	set_ldt(NULL, 0);</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -/*</span>
<span class="quote">&gt; - * load one particular LDT into the current CPU</span>
<span class="quote">&gt; - */</span>
<span class="quote">&gt; -static inline void load_LDT_nolock(mm_context_t *pc)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -	set_ldt(pc-&gt;ldt, pc-&gt;size);</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -static inline void load_LDT(mm_context_t *pc)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -	preempt_disable();</span>
<span class="quote">&gt; -	load_LDT_nolock(pc);</span>
<span class="quote">&gt; -	preempt_enable();</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;   static inline unsigned long get_desc_base(const struct desc_struct *desc)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt;   	return (unsigned)(desc-&gt;base0 | ((desc-&gt;base1) &lt;&lt; 16) | ((desc-&gt;base2) &lt;&lt; 24));</span>
<span class="quote">&gt; diff --git a/arch/x86/include/asm/mmu.h b/arch/x86/include/asm/mmu.h</span>
<span class="quote">&gt; index 09b9620a73b4..364d27481a52 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/asm/mmu.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/asm/mmu.h</span>
<span class="quote">&gt; @@ -9,8 +9,7 @@</span>
<span class="quote">&gt;    * we put the segment information here.</span>
<span class="quote">&gt;    */</span>
<span class="quote">&gt;   typedef struct {</span>
<span class="quote">&gt; -	void *ldt;</span>
<span class="quote">&gt; -	int size;</span>
<span class="quote">&gt; +	struct ldt_struct *ldt;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   #ifdef CONFIG_X86_64</span>
<span class="quote">&gt;   	/* True if mm supports a task running in 32 bit compatibility mode. */</span>
<span class="quote">&gt; diff --git a/arch/x86/include/asm/mmu_context.h b/arch/x86/include/asm/mmu_context.h</span>
<span class="quote">&gt; index 804a3a6030ca..3fcff70c398e 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/asm/mmu_context.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/asm/mmu_context.h</span>
<span class="quote">&gt; @@ -34,6 +34,49 @@ static inline void load_mm_cr4(struct mm_struct *mm) {}</span>
<span class="quote">&gt;   #endif</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   /*</span>
<span class="quote">&gt; + * ldt_structs can be allocated, used, and freed, but they are never</span>
<span class="quote">&gt; + * modified while live.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +struct ldt_struct {</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * Xen requires page-aligned LDTs with special permissions.  This is</span>
<span class="quote">&gt; +	 * needed to prevent us from installing evil descriptors such as</span>
<span class="quote">&gt; +	 * call gates.  On native, we could merge the ldt_struct and LDT</span>
<span class="quote">&gt; +	 * allocations, but it&#39;s not worth trying to optimize.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	struct desc_struct *entries;</span>
<span class="quote">&gt; +	int size;</span>
<span class="quote">&gt; +};</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void load_mm_ldt(struct mm_struct *mm)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct ldt_struct *ldt;</span>
<span class="quote">&gt; +	DEBUG_LOCKS_WARN_ON(!irqs_disabled());</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* lockless_dereference synchronizes with smp_store_release */</span>
<span class="quote">&gt; +	ldt = lockless_dereference(mm-&gt;context.ldt);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * Any change to mm-&gt;context.ldt is followed by an IPI to all</span>
<span class="quote">&gt; +	 * CPUs with the mm active.  The LDT will not be freed until</span>
<span class="quote">&gt; +	 * after the IPI is handled by all such CPUs.  This means that,</span>
<span class="quote">&gt; +	 * if the ldt_struct changes before we return, the values we see</span>
<span class="quote">&gt; +	 * will be safe, and the new values will be loaded before we run</span>
<span class="quote">&gt; +	 * any user code.</span>
<span class="quote">&gt; +	 *</span>
<span class="quote">&gt; +	 * NB: don&#39;t try to convert this to use RCU without extreme care.</span>
<span class="quote">&gt; +	 * We would still need IRQs off, because we don&#39;t want to change</span>
<span class="quote">&gt; +	 * the local LDT after an IPI loaded a newer value than the one</span>
<span class="quote">&gt; +	 * that we can see.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (unlikely(ldt))</span>
<span class="quote">&gt; +		set_ldt(ldt-&gt;entries, ldt-&gt;size);</span>
<span class="quote">&gt; +	else</span>
<span class="quote">&gt; +		clear_LDT();</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt;    * Used for LDT copy/destruction.</span>
<span class="quote">&gt;    */</span>
<span class="quote">&gt;   int init_new_context(struct task_struct *tsk, struct mm_struct *mm);</span>
<span class="quote">&gt; @@ -78,12 +121,12 @@ static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,</span>
<span class="quote">&gt;   		 * was called and then modify_ldt changed</span>
<span class="quote">&gt;   		 * prev-&gt;context.ldt but suppressed an IPI to this CPU.</span>
<span class="quote">&gt;   		 * In this case, prev-&gt;context.ldt != NULL, because we</span>
<span class="quote">&gt; -		 * never free an LDT while the mm still exists.  That</span>
<span class="quote">&gt; -		 * means that next-&gt;context.ldt != prev-&gt;context.ldt,</span>
<span class="quote">&gt; -		 * because mms never share an LDT.</span>
<span class="quote">&gt; +		 * never set context.ldt to NULL while the mm still</span>
<span class="quote">&gt; +		 * exists.  That means that next-&gt;context.ldt !=</span>
<span class="quote">&gt; +		 * prev-&gt;context.ldt, because mms never share an LDT.</span>
<span class="quote">&gt;   		 */</span>
<span class="quote">&gt;   		if (unlikely(prev-&gt;context.ldt != next-&gt;context.ldt))</span>
<span class="quote">&gt; -			load_LDT_nolock(&amp;next-&gt;context);</span>
<span class="quote">&gt; +			load_mm_ldt(next);</span>
<span class="quote">&gt;   	}</span>
<span class="quote">&gt;   #ifdef CONFIG_SMP</span>
<span class="quote">&gt;   	  else {</span>
<span class="quote">&gt; @@ -106,7 +149,7 @@ static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,</span>
<span class="quote">&gt;   			load_cr3(next-&gt;pgd);</span>
<span class="quote">&gt;   			trace_tlb_flush(TLB_FLUSH_ON_TASK_SWITCH, TLB_FLUSH_ALL);</span>
<span class="quote">&gt;   			load_mm_cr4(next);</span>
<span class="quote">&gt; -			load_LDT_nolock(&amp;next-&gt;context);</span>
<span class="quote">&gt; +			load_mm_ldt(next);</span>
<span class="quote">&gt;   		}</span>
<span class="quote">&gt;   	}</span>
<span class="quote">&gt;   #endif</span>
<span class="quote">&gt; diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c</span>
<span class="quote">&gt; index 922c5e0cea4c..cb9e5df42dd2 100644</span>
<span class="quote">&gt; --- a/arch/x86/kernel/cpu/common.c</span>
<span class="quote">&gt; +++ b/arch/x86/kernel/cpu/common.c</span>
<span class="quote">&gt; @@ -1410,7 +1410,7 @@ void cpu_init(void)</span>
<span class="quote">&gt;   	load_sp0(t, &amp;current-&gt;thread);</span>
<span class="quote">&gt;   	set_tss_desc(cpu, t);</span>
<span class="quote">&gt;   	load_TR_desc();</span>
<span class="quote">&gt; -	load_LDT(&amp;init_mm.context);</span>
<span class="quote">&gt; +	load_mm_ldt(&amp;init_mm);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   	clear_all_debug_regs();</span>
<span class="quote">&gt;   	dbg_restore_debug_regs();</span>
<span class="quote">&gt; @@ -1459,7 +1459,7 @@ void cpu_init(void)</span>
<span class="quote">&gt;   	load_sp0(t, thread);</span>
<span class="quote">&gt;   	set_tss_desc(cpu, t);</span>
<span class="quote">&gt;   	load_TR_desc();</span>
<span class="quote">&gt; -	load_LDT(&amp;init_mm.context);</span>
<span class="quote">&gt; +	load_mm_ldt(&amp;init_mm);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   	t-&gt;x86_tss.io_bitmap_base = offsetof(struct tss_struct, io_bitmap);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; diff --git a/arch/x86/kernel/cpu/perf_event.c b/arch/x86/kernel/cpu/perf_event.c</span>
<span class="quote">&gt; index 3658de47900f..9469dfa55607 100644</span>
<span class="quote">&gt; --- a/arch/x86/kernel/cpu/perf_event.c</span>
<span class="quote">&gt; +++ b/arch/x86/kernel/cpu/perf_event.c</span>
<span class="quote">&gt; @@ -2179,21 +2179,25 @@ static unsigned long get_segment_base(unsigned int segment)</span>
<span class="quote">&gt;   	int idx = segment &gt;&gt; 3;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   	if ((segment &amp; SEGMENT_TI_MASK) == SEGMENT_LDT) {</span>
<span class="quote">&gt; +		struct ldt_struct *ldt;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   		if (idx &gt; LDT_ENTRIES)</span>
<span class="quote">&gt;   			return 0;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -		if (idx &gt; current-&gt;active_mm-&gt;context.size)</span>
<span class="quote">&gt; +		/* IRQs are off, so this synchronizes with smp_store_release */</span>
<span class="quote">&gt; +		ldt = lockless_dereference(current-&gt;active_mm-&gt;context.ldt);</span>
<span class="quote">&gt; +		if (!ldt || idx &gt; ldt-&gt;size)</span>
<span class="quote">&gt;   			return 0;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -		desc = current-&gt;active_mm-&gt;context.ldt;</span>
<span class="quote">&gt; +		desc = &amp;ldt-&gt;entries[idx];</span>
<span class="quote">&gt;   	} else {</span>
<span class="quote">&gt;   		if (idx &gt; GDT_ENTRIES)</span>
<span class="quote">&gt;   			return 0;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -		desc = raw_cpu_ptr(gdt_page.gdt);</span>
<span class="quote">&gt; +		desc = raw_cpu_ptr(gdt_page.gdt) + idx;</span>
<span class="quote">&gt;   	}</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	return get_desc_base(desc + idx);</span>
<span class="quote">&gt; +	return get_desc_base(desc);</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   #ifdef CONFIG_COMPAT</span>
<span class="quote">&gt; diff --git a/arch/x86/kernel/ldt.c b/arch/x86/kernel/ldt.c</span>
<span class="quote">&gt; index c37886d759cc..3ae308029dee 100644</span>
<span class="quote">&gt; --- a/arch/x86/kernel/ldt.c</span>
<span class="quote">&gt; +++ b/arch/x86/kernel/ldt.c</span>
<span class="quote">&gt; @@ -12,6 +12,7 @@</span>
<span class="quote">&gt;   #include &lt;linux/string.h&gt;</span>
<span class="quote">&gt;   #include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt;   #include &lt;linux/smp.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/slab.h&gt;</span>
<span class="quote">&gt;   #include &lt;linux/vmalloc.h&gt;</span>
<span class="quote">&gt;   #include &lt;linux/uaccess.h&gt;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; @@ -20,82 +21,83 @@</span>
<span class="quote">&gt;   #include &lt;asm/mmu_context.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/syscalls.h&gt;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -#ifdef CONFIG_SMP</span>
<span class="quote">&gt;   static void flush_ldt(void *current_mm)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt; -	if (current-&gt;active_mm == current_mm)</span>
<span class="quote">&gt; -		load_LDT(&amp;current-&gt;active_mm-&gt;context);</span>
<span class="quote">&gt; +	if (current-&gt;active_mm == current_mm) {</span>
<span class="quote">&gt; +		/* context.lock is held for us, so we don&#39;t need any locking. */</span>
<span class="quote">&gt; +		mm_context_t *pc = &amp;current-&gt;active_mm-&gt;context;</span>
<span class="quote">&gt; +		set_ldt(pc-&gt;ldt-&gt;entries, pc-&gt;ldt-&gt;size);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt; -#endif</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -static int alloc_ldt(mm_context_t *pc, int mincount, int reload)</span>
<span class="quote">&gt; +/* The caller must call finalize_ldt_struct on the result. */</span>
<span class="quote">&gt; +static struct ldt_struct *alloc_ldt_struct(int size)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt; -	void *oldldt, *newldt;</span>
<span class="quote">&gt; -	int oldsize;</span>
<span class="quote">&gt; +	struct ldt_struct *new_ldt;</span>
<span class="quote">&gt; +	int alloc_size;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	if (mincount &lt;= pc-&gt;size)</span>
<span class="quote">&gt; -		return 0;</span>
<span class="quote">&gt; -	oldsize = pc-&gt;size;</span>
<span class="quote">&gt; -	mincount = (mincount + (PAGE_SIZE / LDT_ENTRY_SIZE - 1)) &amp;</span>
<span class="quote">&gt; -			(~(PAGE_SIZE / LDT_ENTRY_SIZE - 1));</span>
<span class="quote">&gt; -	if (mincount * LDT_ENTRY_SIZE &gt; PAGE_SIZE)</span>
<span class="quote">&gt; -		newldt = vmalloc(mincount * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt; +	if (size &gt; LDT_ENTRIES)</span>
<span class="quote">&gt; +		return NULL;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	new_ldt = kmalloc(sizeof(struct ldt_struct), GFP_KERNEL);</span>
<span class="quote">&gt; +	if (!new_ldt)</span>
<span class="quote">&gt; +		return NULL;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	BUILD_BUG_ON(LDT_ENTRY_SIZE != sizeof(struct desc_struct));</span>
<span class="quote">&gt; +	alloc_size = size * LDT_ENTRY_SIZE;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (alloc_size &gt; PAGE_SIZE)</span>
<span class="quote">&gt; +		new_ldt-&gt;entries = vmalloc(alloc_size);</span>
<span class="quote">&gt;   	else</span>
<span class="quote">&gt; -		newldt = (void *)__get_free_page(GFP_KERNEL);</span>
<span class="quote">&gt; +		new_ldt-&gt;entries = (void *)__get_free_page(GFP_KERNEL);</span>
<span class="quote">&gt; +	if (!new_ldt-&gt;entries) {</span>
<span class="quote">&gt; +		kfree(new_ldt);</span>
<span class="quote">&gt; +		return NULL;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	if (!newldt)</span>
<span class="quote">&gt; -		return -ENOMEM;</span>
<span class="quote">&gt; +	new_ldt-&gt;size = size;</span>
<span class="quote">&gt; +	return new_ldt;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* After calling this, the LDT is immutable. */</span>
<span class="quote">&gt; +static void finalize_ldt_struct(struct ldt_struct *ldt)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	paravirt_alloc_ldt(ldt-&gt;entries, ldt-&gt;size);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	if (oldsize)</span>
<span class="quote">&gt; -		memcpy(newldt, pc-&gt;ldt, oldsize * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt; -	oldldt = pc-&gt;ldt;</span>
<span class="quote">&gt; -	memset(newldt + oldsize * LDT_ENTRY_SIZE, 0,</span>
<span class="quote">&gt; -	       (mincount - oldsize) * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt; +static void install_ldt(struct mm_struct *current_mm,</span>
<span class="quote">&gt; +			struct ldt_struct *ldt)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	/* context.lock is held */</span>
<span class="quote">&gt; +	preempt_disable();</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	paravirt_alloc_ldt(newldt, mincount);</span>
<span class="quote">&gt; +	/* Synchronizes with lockless_dereference in load_mm_ldt. */</span>
<span class="quote">&gt; +	smp_store_release(&amp;current_mm-&gt;context.ldt, ldt);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -#ifdef CONFIG_X86_64</span>
<span class="quote">&gt; -	/* CHECKME: Do we really need this ? */</span>
<span class="quote">&gt; -	wmb();</span>
<span class="quote">&gt; -#endif</span>
<span class="quote">&gt; -	pc-&gt;ldt = newldt;</span>
<span class="quote">&gt; -	wmb();</span>
<span class="quote">&gt; -	pc-&gt;size = mincount;</span>
<span class="quote">&gt; -	wmb();</span>
<span class="quote">&gt; +	/* Activate for this CPU. */</span>
<span class="quote">&gt; +	flush_ldt(current-&gt;mm);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	if (reload) {</span>
<span class="quote">&gt;   #ifdef CONFIG_SMP</span>
<span class="quote">&gt; -		preempt_disable();</span>
<span class="quote">&gt; -		load_LDT(pc);</span>
<span class="quote">&gt; -		if (!cpumask_equal(mm_cpumask(current-&gt;mm),</span>
<span class="quote">&gt; -				   cpumask_of(smp_processor_id())))</span>
<span class="quote">&gt; -			smp_call_function(flush_ldt, current-&gt;mm, 1);</span>
<span class="quote">&gt; -		preempt_enable();</span>
<span class="quote">&gt; -#else</span>
<span class="quote">&gt; -		load_LDT(pc);</span>
<span class="quote">&gt; +	/* Synchronize with other CPUs. */</span>
<span class="quote">&gt; +	if (!cpumask_equal(mm_cpumask(current_mm),</span>
<span class="quote">&gt; +			   cpumask_of(smp_processor_id())))</span>
<span class="quote">&gt; +		smp_call_function(flush_ldt, current_mm, 1);</span>
<span class="quote">&gt;   #endif</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; -	if (oldsize) {</span>
<span class="quote">&gt; -		paravirt_free_ldt(oldldt, oldsize);</span>
<span class="quote">&gt; -		if (oldsize * LDT_ENTRY_SIZE &gt; PAGE_SIZE)</span>
<span class="quote">&gt; -			vfree(oldldt);</span>
<span class="quote">&gt; -		else</span>
<span class="quote">&gt; -			put_page(virt_to_page(oldldt));</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; -	return 0;</span>
<span class="quote">&gt; +	preempt_enable();</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -static inline int copy_ldt(mm_context_t *new, mm_context_t *old)</span>
<span class="quote">&gt; +static void free_ldt_struct(struct ldt_struct *ldt)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt; -	int err = alloc_ldt(new, old-&gt;size, 0);</span>
<span class="quote">&gt; -	int i;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -	if (err &lt; 0)</span>
<span class="quote">&gt; -		return err;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -	for (i = 0; i &lt; old-&gt;size; i++)</span>
<span class="quote">&gt; -		write_ldt_entry(new-&gt;ldt, i, old-&gt;ldt + i * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt; -	return 0;</span>
<span class="quote">&gt; +	if (unlikely(ldt)) {</span>
<span class="quote">&gt; +		int alloc_size = sizeof(struct ldt_struct) +</span>
<span class="quote">&gt; +			ldt-&gt;size * LDT_ENTRY_SIZE;</span>
<span class="quote">&gt; +		paravirt_free_ldt(ldt-&gt;entries, ldt-&gt;size);</span>
<span class="quote">&gt; +		if (alloc_size &gt; PAGE_SIZE)</span>
<span class="quote">&gt; +			vfree(ldt-&gt;entries);</span>
<span class="quote">&gt; +		else</span>
<span class="quote">&gt; +			put_page(virt_to_page(ldt-&gt;entries));</span>
<span class="quote">&gt; +		kfree(ldt);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   /*</span>
<span class="quote">&gt; @@ -108,13 +110,32 @@ int init_new_context(struct task_struct *tsk, struct mm_struct *mm)</span>
<span class="quote">&gt;   	int retval = 0;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   	mutex_init(&amp;mm-&gt;context.lock);</span>
<span class="quote">&gt; -	mm-&gt;context.size = 0;</span>
<span class="quote">&gt;   	old_mm = current-&gt;mm;</span>
<span class="quote">&gt; -	if (old_mm &amp;&amp; old_mm-&gt;context.size &gt; 0) {</span>
<span class="quote">&gt; -		mutex_lock(&amp;old_mm-&gt;context.lock);</span>
<span class="quote">&gt; -		retval = copy_ldt(&amp;mm-&gt;context, &amp;old_mm-&gt;context);</span>
<span class="quote">&gt; -		mutex_unlock(&amp;old_mm-&gt;context.lock);</span>
<span class="quote">&gt; +	if (!old_mm) {</span>
<span class="quote">&gt; +		mm-&gt;context.ldt = NULL;</span>
<span class="quote">&gt; +		return 0;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	mutex_lock(&amp;old_mm-&gt;context.lock);</span>
<span class="quote">&gt; +	if (old_mm-&gt;context.ldt) {</span>
<span class="quote">&gt; +		struct ldt_struct *new_ldt =</span>
<span class="quote">&gt; +			alloc_ldt_struct(old_mm-&gt;context.ldt-&gt;size);</span>
<span class="quote">&gt; +		if (!new_ldt) {</span>
<span class="quote">&gt; +			retval = -ENOMEM;</span>
<span class="quote">&gt; +			goto out_unlock;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		memcpy(new_ldt-&gt;entries, old_mm-&gt;context.ldt-&gt;entries,</span>
<span class="quote">&gt; +		       new_ldt-&gt;size * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt; +		finalize_ldt_struct(new_ldt);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		mm-&gt;context.ldt = new_ldt;</span>
<span class="quote">&gt; +	} else {</span>
<span class="quote">&gt; +		mm-&gt;context.ldt = NULL;</span>
<span class="quote">&gt;   	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +out_unlock:</span>
<span class="quote">&gt; +	mutex_unlock(&amp;old_mm-&gt;context.lock);</span>
<span class="quote">&gt;   	return retval;</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; @@ -125,53 +146,47 @@ int init_new_context(struct task_struct *tsk, struct mm_struct *mm)</span>
<span class="quote">&gt;    */</span>
<span class="quote">&gt;   void destroy_context(struct mm_struct *mm)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt; -	if (mm-&gt;context.size) {</span>
<span class="quote">&gt; -#ifdef CONFIG_X86_32</span>
<span class="quote">&gt; -		/* CHECKME: Can this ever happen ? */</span>
<span class="quote">&gt; -		if (mm == current-&gt;active_mm)</span>
<span class="quote">&gt; -			clear_LDT();</span>
<span class="quote">&gt; -#endif</span>
<span class="quote">&gt; -		paravirt_free_ldt(mm-&gt;context.ldt, mm-&gt;context.size);</span>
<span class="quote">&gt; -		if (mm-&gt;context.size * LDT_ENTRY_SIZE &gt; PAGE_SIZE)</span>
<span class="quote">&gt; -			vfree(mm-&gt;context.ldt);</span>
<span class="quote">&gt; -		else</span>
<span class="quote">&gt; -			put_page(virt_to_page(mm-&gt;context.ldt));</span>
<span class="quote">&gt; -		mm-&gt;context.size = 0;</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; +	free_ldt_struct(mm-&gt;context.ldt);</span>
<span class="quote">&gt; +	mm-&gt;context.ldt = NULL;</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   static int read_ldt(void __user *ptr, unsigned long bytecount)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt; -	int err;</span>
<span class="quote">&gt; +	int retval;</span>
<span class="quote">&gt;   	unsigned long size;</span>
<span class="quote">&gt;   	struct mm_struct *mm = current-&gt;mm;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	if (!mm-&gt;context.size)</span>
<span class="quote">&gt; -		return 0;</span>
<span class="quote">&gt; +	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (!mm-&gt;context.ldt) {</span>
<span class="quote">&gt; +		retval = 0;</span>
<span class="quote">&gt; +		goto out_unlock;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   	if (bytecount &gt; LDT_ENTRY_SIZE * LDT_ENTRIES)</span>
<span class="quote">&gt;   		bytecount = LDT_ENTRY_SIZE * LDT_ENTRIES;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="quote">&gt; -	size = mm-&gt;context.size * LDT_ENTRY_SIZE;</span>
<span class="quote">&gt; +	size = mm-&gt;context.ldt-&gt;size * LDT_ENTRY_SIZE;</span>
<span class="quote">&gt;   	if (size &gt; bytecount)</span>
<span class="quote">&gt;   		size = bytecount;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	err = 0;</span>
<span class="quote">&gt; -	if (copy_to_user(ptr, mm-&gt;context.ldt, size))</span>
<span class="quote">&gt; -		err = -EFAULT;</span>
<span class="quote">&gt; -	mutex_unlock(&amp;mm-&gt;context.lock);</span>
<span class="quote">&gt; -	if (err &lt; 0)</span>
<span class="quote">&gt; -		goto error_return;</span>
<span class="quote">&gt; +	if (copy_to_user(ptr, mm-&gt;context.ldt-&gt;entries, size)) {</span>
<span class="quote">&gt; +		retval = -EFAULT;</span>
<span class="quote">&gt; +		goto out_unlock;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;   	if (size != bytecount) {</span>
<span class="quote">&gt; -		/* zero-fill the rest */</span>
<span class="quote">&gt; +		/* Zero-fill the rest and pretend we read bytecount bytes. */</span>
<span class="quote">&gt;   		if (clear_user(ptr + size, bytecount - size) != 0) {</span>
<span class="quote">&gt; -			err = -EFAULT;</span>
<span class="quote">&gt; -			goto error_return;</span>
<span class="quote">&gt; +			retval = -EFAULT;</span>
<span class="quote">&gt; +			goto out_unlock;</span>
<span class="quote">&gt;   		}</span>
<span class="quote">&gt;   	}</span>
<span class="quote">&gt; -	return bytecount;</span>
<span class="quote">&gt; -error_return:</span>
<span class="quote">&gt; -	return err;</span>
<span class="quote">&gt; +	retval = bytecount;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +out_unlock:</span>
<span class="quote">&gt; +	mutex_unlock(&amp;mm-&gt;context.lock);</span>
<span class="quote">&gt; +	return retval;</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   static int read_default_ldt(void __user *ptr, unsigned long bytecount)</span>
<span class="quote">&gt; @@ -195,6 +210,8 @@ static int write_ldt(void __user *ptr, unsigned long bytecount, int oldmode)</span>
<span class="quote">&gt;   	struct desc_struct ldt;</span>
<span class="quote">&gt;   	int error;</span>
<span class="quote">&gt;   	struct user_desc ldt_info;</span>
<span class="quote">&gt; +	int oldsize, newsize;</span>
<span class="quote">&gt; +	struct ldt_struct *new_ldt, *old_ldt;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   	error = -EINVAL;</span>
<span class="quote">&gt;   	if (bytecount != sizeof(ldt_info))</span>
<span class="quote">&gt; @@ -213,34 +230,43 @@ static int write_ldt(void __user *ptr, unsigned long bytecount, int oldmode)</span>
<span class="quote">&gt;   			goto out;</span>
<span class="quote">&gt;   	}</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="quote">&gt; -	if (ldt_info.entry_number &gt;= mm-&gt;context.size) {</span>
<span class="quote">&gt; -		error = alloc_ldt(&amp;current-&gt;mm-&gt;context,</span>
<span class="quote">&gt; -				  ldt_info.entry_number + 1, 1);</span>
<span class="quote">&gt; -		if (error &lt; 0)</span>
<span class="quote">&gt; -			goto out_unlock;</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -	/* Allow LDTs to be cleared by the user. */</span>
<span class="quote">&gt; -	if (ldt_info.base_addr == 0 &amp;&amp; ldt_info.limit == 0) {</span>
<span class="quote">&gt; -		if (oldmode || LDT_empty(&amp;ldt_info)) {</span>
<span class="quote">&gt; -			memset(&amp;ldt, 0, sizeof(ldt));</span>
<span class="quote">&gt; -			goto install;</span>
<span class="quote">&gt; +	if ((oldmode &amp;&amp; ldt_info.base_addr == 0 &amp;&amp; ldt_info.limit == 0) ||</span>
<span class="quote">&gt; +	    LDT_empty(&amp;ldt_info)) {</span>
<span class="quote">&gt; +		/* The user wants to clear the entry. */</span>
<span class="quote">&gt; +		memset(&amp;ldt, 0, sizeof(ldt));</span>
<span class="quote">&gt; +	} else {</span>
<span class="quote">&gt; +		if (!IS_ENABLED(CONFIG_X86_16BIT) &amp;&amp; !ldt_info.seg_32bit) {</span>
<span class="quote">&gt; +			error = -EINVAL;</span>
<span class="quote">&gt; +			goto out;</span>
<span class="quote">&gt;   		}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		fill_ldt(&amp;ldt, &amp;ldt_info);</span>
<span class="quote">&gt; +		if (oldmode)</span>
<span class="quote">&gt; +			ldt.avl = 0;</span>
<span class="quote">&gt;   	}</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	if (!IS_ENABLED(CONFIG_X86_16BIT) &amp;&amp; !ldt_info.seg_32bit) {</span>
<span class="quote">&gt; -		error = -EINVAL;</span>
<span class="quote">&gt; +	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	old_ldt = mm-&gt;context.ldt;</span>
<span class="quote">&gt; +	oldsize = old_ldt ? old_ldt-&gt;size : 0;</span>
<span class="quote">&gt; +	newsize = max((int)(ldt_info.entry_number + 1), oldsize);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	error = -ENOMEM;</span>
<span class="quote">&gt; +	new_ldt = alloc_ldt_struct(newsize);</span>
<span class="quote">&gt; +	if (!new_ldt)</span>
<span class="quote">&gt;   		goto out_unlock;</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	fill_ldt(&amp;ldt, &amp;ldt_info);</span>
<span class="quote">&gt; -	if (oldmode)</span>
<span class="quote">&gt; -		ldt.avl = 0;</span>
<span class="quote">&gt; +	if (old_ldt) {</span>
<span class="quote">&gt; +		memcpy(new_ldt-&gt;entries, old_ldt-&gt;entries,</span>
<span class="quote">&gt; +		       oldsize * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +	memset(new_ldt-&gt;entries + oldsize * LDT_ENTRY_SIZE, 0,</span>
<span class="quote">&gt; +	       (newsize - oldsize) * LDT_ENTRY_SIZE);</span>

We need to zero out full page (probably better in alloc_ldt_struct() 
with vmzalloc/__GFP_ZERO) --- Xen checks whole page that is assigned to  
G/LDT and gets unhappy if an invalid descriptor is found there.

This fixes one problem. There is something else that Xen gets upset 
about, I haven&#39;t figured what it is yet (and I am out tomorrow so it may 
need to wait until Friday).


-boris
<span class="quote">

&gt; +	new_ldt-&gt;entries[ldt_info.entry_number] = ldt;</span>
<span class="quote">&gt; +	finalize_ldt_struct(new_ldt);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	/* Install the new entry ...  */</span>
<span class="quote">&gt; -install:</span>
<span class="quote">&gt; -	write_ldt_entry(mm-&gt;context.ldt, ldt_info.entry_number, &amp;ldt);</span>
<span class="quote">&gt; +	install_ldt(mm, new_ldt);</span>
<span class="quote">&gt; +	free_ldt_struct(old_ldt);</span>
<span class="quote">&gt;   	error = 0;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   out_unlock:</span>
<span class="quote">&gt; diff --git a/arch/x86/kernel/process_64.c b/arch/x86/kernel/process_64.c</span>
<span class="quote">&gt; index 71d7849a07f7..f6b916387590 100644</span>
<span class="quote">&gt; --- a/arch/x86/kernel/process_64.c</span>
<span class="quote">&gt; +++ b/arch/x86/kernel/process_64.c</span>
<span class="quote">&gt; @@ -121,11 +121,11 @@ void __show_regs(struct pt_regs *regs, int all)</span>
<span class="quote">&gt;   void release_thread(struct task_struct *dead_task)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt;   	if (dead_task-&gt;mm) {</span>
<span class="quote">&gt; -		if (dead_task-&gt;mm-&gt;context.size) {</span>
<span class="quote">&gt; +		if (dead_task-&gt;mm-&gt;context.ldt) {</span>
<span class="quote">&gt;   			pr_warn(&quot;WARNING: dead process %s still has LDT? &lt;%p/%d&gt;\n&quot;,</span>
<span class="quote">&gt;   				dead_task-&gt;comm,</span>
<span class="quote">&gt;   				dead_task-&gt;mm-&gt;context.ldt,</span>
<span class="quote">&gt; -				dead_task-&gt;mm-&gt;context.size);</span>
<span class="quote">&gt; +				dead_task-&gt;mm-&gt;context.ldt-&gt;size);</span>
<span class="quote">&gt;   			BUG();</span>
<span class="quote">&gt;   		}</span>
<span class="quote">&gt;   	}</span>
<span class="quote">&gt; diff --git a/arch/x86/kernel/step.c b/arch/x86/kernel/step.c</span>
<span class="quote">&gt; index 9b4d51d0c0d0..6273324186ac 100644</span>
<span class="quote">&gt; --- a/arch/x86/kernel/step.c</span>
<span class="quote">&gt; +++ b/arch/x86/kernel/step.c</span>
<span class="quote">&gt; @@ -5,6 +5,7 @@</span>
<span class="quote">&gt;   #include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt;   #include &lt;linux/ptrace.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/desc.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/mmu_context.h&gt;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   unsigned long convert_ip_to_linear(struct task_struct *child, struct pt_regs *regs)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt; @@ -30,10 +31,11 @@ unsigned long convert_ip_to_linear(struct task_struct *child, struct pt_regs *re</span>
<span class="quote">&gt;   		seg &amp;= ~7UL;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   		mutex_lock(&amp;child-&gt;mm-&gt;context.lock);</span>
<span class="quote">&gt; -		if (unlikely((seg &gt;&gt; 3) &gt;= child-&gt;mm-&gt;context.size))</span>
<span class="quote">&gt; +		if (unlikely(!child-&gt;mm-&gt;context.ldt ||</span>
<span class="quote">&gt; +			     (seg &gt;&gt; 3) &gt;= child-&gt;mm-&gt;context.ldt-&gt;size))</span>
<span class="quote">&gt;   			addr = -1L; /* bogus selector, access would fault */</span>
<span class="quote">&gt;   		else {</span>
<span class="quote">&gt; -			desc = child-&gt;mm-&gt;context.ldt + seg;</span>
<span class="quote">&gt; +			desc = &amp;child-&gt;mm-&gt;context.ldt-&gt;entries[seg];</span>
<span class="quote">&gt;   			base = get_desc_base(desc);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   			/* 16-bit code segment? */</span>
<span class="quote">&gt; diff --git a/arch/x86/power/cpu.c b/arch/x86/power/cpu.c</span>
<span class="quote">&gt; index 0d7dd1f5ac36..9ab52791fed5 100644</span>
<span class="quote">&gt; --- a/arch/x86/power/cpu.c</span>
<span class="quote">&gt; +++ b/arch/x86/power/cpu.c</span>
<span class="quote">&gt; @@ -22,6 +22,7 @@</span>
<span class="quote">&gt;   #include &lt;asm/fpu/internal.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/debugreg.h&gt;</span>
<span class="quote">&gt;   #include &lt;asm/cpu.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/mmu_context.h&gt;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   #ifdef CONFIG_X86_32</span>
<span class="quote">&gt;   __visible unsigned long saved_context_ebx;</span>
<span class="quote">&gt; @@ -153,7 +154,7 @@ static void fix_processor_context(void)</span>
<span class="quote">&gt;   	syscall_init();				/* This sets MSR_*STAR and related */</span>
<span class="quote">&gt;   #endif</span>
<span class="quote">&gt;   	load_TR_desc();				/* This does ltr */</span>
<span class="quote">&gt; -	load_LDT(&amp;current-&gt;active_mm-&gt;context);	/* This does lldt */</span>
<span class="quote">&gt; +	load_mm_ldt(current-&gt;active_mm);	/* This does lldt */</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   	fpu__resume_cpu();</span>
<span class="quote">&gt;   }</span>

--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7500">Borislav Petkov</a> - July 24, 2015, 6:37 a.m.</div>
<pre class="content">
On Wed, Jul 22, 2015 at 12:23:46PM -0700, Andy Lutomirski wrote:
<span class="quote">&gt; modify_ldt has questionable locking and does not synchronize</span>
<span class="quote">&gt; threads.  Improve it: redesign the locking and synchronize all</span>
<span class="quote">&gt; threads&#39; LDTs using an IPI on all modifications.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This will dramatically slow down modify_ldt in multithreaded</span>
<span class="quote">&gt; programs, but there shouldn&#39;t be any multithreaded programs that</span>
<span class="quote">&gt; care about modify_ldt&#39;s performance in the first place.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: stable@vger.kernel.org</span>
<span class="quote">&gt; Signed-off-by: Andy Lutomirski &lt;luto@kernel.org&gt;</span>

...
<span class="quote">
&gt; +struct ldt_struct {</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * Xen requires page-aligned LDTs with special permissions.  This is</span>
<span class="quote">&gt; +	 * needed to prevent us from installing evil descriptors such as</span>
<span class="quote">&gt; +	 * call gates.  On native, we could merge the ldt_struct and LDT</span>
<span class="quote">&gt; +	 * allocations, but it&#39;s not worth trying to optimize.</span>

I don&#39;t think baremetal should care about xen and frankly, this is
getting ridiculous, slowly - baremetal has to wait with a potentially
critical security fix just because it breaks xen. Dammit, this level of
intrusiveness into x86 should&#39;ve never been allowed.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7500">Borislav Petkov</a> - July 24, 2015, 3:29 p.m.</div>
<pre class="content">
On Wed, Jul 22, 2015 at 12:23:46PM -0700, Andy Lutomirski wrote:
<span class="quote">&gt; modify_ldt has questionable locking and does not synchronize</span>
<span class="quote">&gt; threads.  Improve it: redesign the locking and synchronize all</span>
<span class="quote">&gt; threads&#39; LDTs using an IPI on all modifications.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This will dramatically slow down modify_ldt in multithreaded</span>
<span class="quote">&gt; programs, but there shouldn&#39;t be any multithreaded programs that</span>
<span class="quote">&gt; care about modify_ldt&#39;s performance in the first place.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: stable@vger.kernel.org</span>
<span class="quote">&gt; Signed-off-by: Andy Lutomirski &lt;luto@kernel.org&gt;</span>

Just minor stylistic nitpicks below. Otherwise looks ok to me.

...
<span class="quote">
&gt; diff --git a/arch/x86/kernel/ldt.c b/arch/x86/kernel/ldt.c</span>
<span class="quote">&gt; index c37886d759cc..3ae308029dee 100644</span>
<span class="quote">&gt; --- a/arch/x86/kernel/ldt.c</span>
<span class="quote">&gt; +++ b/arch/x86/kernel/ldt.c</span>
<span class="quote">&gt; @@ -12,6 +12,7 @@</span>
<span class="quote">&gt;  #include &lt;linux/string.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/smp.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/slab.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/vmalloc.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/uaccess.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -20,82 +21,83 @@</span>
<span class="quote">&gt;  #include &lt;asm/mmu_context.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/syscalls.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -#ifdef CONFIG_SMP</span>
<span class="quote">&gt;  static void flush_ldt(void *current_mm)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	if (current-&gt;active_mm == current_mm)</span>
<span class="quote">&gt; -		load_LDT(&amp;current-&gt;active_mm-&gt;context);</span>
<span class="quote">&gt; +	if (current-&gt;active_mm == current_mm) {</span>

Save indentation level:

	if (current-&gt;active_mm != current_mm)
		return;
<span class="quote">
&gt; +		/* context.lock is held for us, so we don&#39;t need any locking. */</span>

Stick that comment above the function name.
<span class="quote">
&gt; +		mm_context_t *pc = &amp;current-&gt;active_mm-&gt;context;</span>
<span class="quote">&gt; +		set_ldt(pc-&gt;ldt-&gt;entries, pc-&gt;ldt-&gt;size);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; -#endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static int alloc_ldt(mm_context_t *pc, int mincount, int reload)</span>
<span class="quote">&gt; +/* The caller must call finalize_ldt_struct on the result. */</span>
<span class="quote">&gt; +static struct ldt_struct *alloc_ldt_struct(int size)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	void *oldldt, *newldt;</span>
<span class="quote">&gt; -	int oldsize;</span>
<span class="quote">&gt; +	struct ldt_struct *new_ldt;</span>
<span class="quote">&gt; +	int alloc_size;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (mincount &lt;= pc-&gt;size)</span>
<span class="quote">&gt; -		return 0;</span>
<span class="quote">&gt; -	oldsize = pc-&gt;size;</span>
<span class="quote">&gt; -	mincount = (mincount + (PAGE_SIZE / LDT_ENTRY_SIZE - 1)) &amp;</span>
<span class="quote">&gt; -			(~(PAGE_SIZE / LDT_ENTRY_SIZE - 1));</span>
<span class="quote">&gt; -	if (mincount * LDT_ENTRY_SIZE &gt; PAGE_SIZE)</span>
<span class="quote">&gt; -		newldt = vmalloc(mincount * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt; +	if (size &gt; LDT_ENTRIES)</span>
<span class="quote">&gt; +		return NULL;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	new_ldt = kmalloc(sizeof(struct ldt_struct), GFP_KERNEL);</span>
<span class="quote">&gt; +	if (!new_ldt)</span>
<span class="quote">&gt; +		return NULL;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	BUILD_BUG_ON(LDT_ENTRY_SIZE != sizeof(struct desc_struct));</span>
<span class="quote">&gt; +	alloc_size = size * LDT_ENTRY_SIZE;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (alloc_size &gt; PAGE_SIZE)</span>
<span class="quote">&gt; +		new_ldt-&gt;entries = vmalloc(alloc_size);</span>
<span class="quote">&gt;  	else</span>
<span class="quote">&gt; -		newldt = (void *)__get_free_page(GFP_KERNEL);</span>
<span class="quote">&gt; +		new_ldt-&gt;entries = (void *)__get_free_page(GFP_KERNEL);</span>

newline here.
<span class="quote">
&gt; +	if (!new_ldt-&gt;entries) {</span>
<span class="quote">&gt; +		kfree(new_ldt);</span>
<span class="quote">&gt; +		return NULL;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (!newldt)</span>
<span class="quote">&gt; -		return -ENOMEM;</span>
<span class="quote">&gt; +	new_ldt-&gt;size = size;</span>
<span class="quote">&gt; +	return new_ldt;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* After calling this, the LDT is immutable. */</span>
<span class="quote">&gt; +static void finalize_ldt_struct(struct ldt_struct *ldt)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	paravirt_alloc_ldt(ldt-&gt;entries, ldt-&gt;size);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (oldsize)</span>
<span class="quote">&gt; -		memcpy(newldt, pc-&gt;ldt, oldsize * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt; -	oldldt = pc-&gt;ldt;</span>
<span class="quote">&gt; -	memset(newldt + oldsize * LDT_ENTRY_SIZE, 0,</span>
<span class="quote">&gt; -	       (mincount - oldsize) * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt; +static void install_ldt(struct mm_struct *current_mm,</span>
<span class="quote">&gt; +			struct ldt_struct *ldt)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	/* context.lock is held */</span>
<span class="quote">&gt; +	preempt_disable();</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	paravirt_alloc_ldt(newldt, mincount);</span>
<span class="quote">&gt; +	/* Synchronizes with lockless_dereference in load_mm_ldt. */</span>

Good.
<span class="quote">
&gt; +	smp_store_release(&amp;current_mm-&gt;context.ldt, ldt);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -#ifdef CONFIG_X86_64</span>
<span class="quote">&gt; -	/* CHECKME: Do we really need this ? */</span>
<span class="quote">&gt; -	wmb();</span>
<span class="quote">&gt; -#endif</span>
<span class="quote">&gt; -	pc-&gt;ldt = newldt;</span>
<span class="quote">&gt; -	wmb();</span>
<span class="quote">&gt; -	pc-&gt;size = mincount;</span>
<span class="quote">&gt; -	wmb();</span>
<span class="quote">&gt; +	/* Activate for this CPU. */</span>
<span class="quote">&gt; +	flush_ldt(current-&gt;mm);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (reload) {</span>
<span class="quote">&gt;  #ifdef CONFIG_SMP</span>
<span class="quote">&gt; -		preempt_disable();</span>
<span class="quote">&gt; -		load_LDT(pc);</span>
<span class="quote">&gt; -		if (!cpumask_equal(mm_cpumask(current-&gt;mm),</span>
<span class="quote">&gt; -				   cpumask_of(smp_processor_id())))</span>
<span class="quote">&gt; -			smp_call_function(flush_ldt, current-&gt;mm, 1);</span>
<span class="quote">&gt; -		preempt_enable();</span>
<span class="quote">&gt; -#else</span>
<span class="quote">&gt; -		load_LDT(pc);</span>
<span class="quote">&gt; +	/* Synchronize with other CPUs. */</span>
<span class="quote">&gt; +	if (!cpumask_equal(mm_cpumask(current_mm),</span>
<span class="quote">&gt; +			   cpumask_of(smp_processor_id())))</span>

Let it stick out:

	if (!cpumask_equal(mm_cpumask(current_mm), cpumask_of(smp_processor_id())))
		smp_call_function(flush_ldt, current_mm, 1);
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; -	if (oldsize) {</span>
<span class="quote">&gt; -		paravirt_free_ldt(oldldt, oldsize);</span>
<span class="quote">&gt; -		if (oldsize * LDT_ENTRY_SIZE &gt; PAGE_SIZE)</span>
<span class="quote">&gt; -			vfree(oldldt);</span>
<span class="quote">&gt; -		else</span>
<span class="quote">&gt; -			put_page(virt_to_page(oldldt));</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; -	return 0;</span>
<span class="quote">&gt; +	preempt_enable();</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static inline int copy_ldt(mm_context_t *new, mm_context_t *old)</span>
<span class="quote">&gt; +static void free_ldt_struct(struct ldt_struct *ldt)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	int err = alloc_ldt(new, old-&gt;size, 0);</span>
<span class="quote">&gt; -	int i;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -	if (err &lt; 0)</span>
<span class="quote">&gt; -		return err;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -	for (i = 0; i &lt; old-&gt;size; i++)</span>
<span class="quote">&gt; -		write_ldt_entry(new-&gt;ldt, i, old-&gt;ldt + i * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt; -	return 0;</span>
<span class="quote">&gt; +	if (unlikely(ldt)) {</span>

Save an indentation level:

	int alloc_size;

	if (!ldt)
		return;

	alloc_size = sizeof(struct ldt_struct) + ldt-&gt;size * LDT_ENTRY_SIZE;

	...
<span class="quote">
&gt; +		paravirt_free_ldt(ldt-&gt;entries, ldt-&gt;size);</span>
<span class="quote">&gt; +		if (alloc_size &gt; PAGE_SIZE)</span>
<span class="quote">&gt; +			vfree(ldt-&gt;entries);</span>
<span class="quote">&gt; +		else</span>
<span class="quote">&gt; +			put_page(virt_to_page(ldt-&gt;entries));</span>
<span class="quote">&gt; +		kfree(ldt);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt; @@ -108,13 +110,32 @@ int init_new_context(struct task_struct *tsk, struct mm_struct *mm)</span>
<span class="quote">&gt;  	int retval = 0;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	mutex_init(&amp;mm-&gt;context.lock);</span>
<span class="quote">&gt; -	mm-&gt;context.size = 0;</span>
<span class="quote">&gt;  	old_mm = current-&gt;mm;</span>
<span class="quote">&gt; -	if (old_mm &amp;&amp; old_mm-&gt;context.size &gt; 0) {</span>
<span class="quote">&gt; -		mutex_lock(&amp;old_mm-&gt;context.lock);</span>
<span class="quote">&gt; -		retval = copy_ldt(&amp;mm-&gt;context, &amp;old_mm-&gt;context);</span>
<span class="quote">&gt; -		mutex_unlock(&amp;old_mm-&gt;context.lock);</span>
<span class="quote">&gt; +	if (!old_mm) {</span>
<span class="quote">&gt; +		mm-&gt;context.ldt = NULL;</span>
<span class="quote">&gt; +		return 0;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	mutex_lock(&amp;old_mm-&gt;context.lock);</span>
<span class="quote">&gt; +	if (old_mm-&gt;context.ldt) {</span>

Same here:

	if (!old_mm-&gt;context.ldt) {
		mm-&gt;context.ldt = NULL;
		goto out_unlock;
	}

	new_ldt = ...
<span class="quote">
&gt; +		struct ldt_struct *new_ldt =</span>
<span class="quote">&gt; +			alloc_ldt_struct(old_mm-&gt;context.ldt-&gt;size);</span>
<span class="quote">&gt; +		if (!new_ldt) {</span>
<span class="quote">&gt; +			retval = -ENOMEM;</span>
<span class="quote">&gt; +			goto out_unlock;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		memcpy(new_ldt-&gt;entries, old_mm-&gt;context.ldt-&gt;entries,</span>
<span class="quote">&gt; +		       new_ldt-&gt;size * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt; +		finalize_ldt_struct(new_ldt);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		mm-&gt;context.ldt = new_ldt;</span>
<span class="quote">&gt; +	} else {</span>
<span class="quote">&gt; +		mm-&gt;context.ldt = NULL;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +out_unlock:</span>
<span class="quote">&gt; +	mutex_unlock(&amp;old_mm-&gt;context.lock);</span>
<span class="quote">&gt;  	return retval;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -125,53 +146,47 @@ int init_new_context(struct task_struct *tsk, struct mm_struct *mm)</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  void destroy_context(struct mm_struct *mm)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	if (mm-&gt;context.size) {</span>
<span class="quote">&gt; -#ifdef CONFIG_X86_32</span>
<span class="quote">&gt; -		/* CHECKME: Can this ever happen ? */</span>
<span class="quote">&gt; -		if (mm == current-&gt;active_mm)</span>
<span class="quote">&gt; -			clear_LDT();</span>
<span class="quote">&gt; -#endif</span>
<span class="quote">&gt; -		paravirt_free_ldt(mm-&gt;context.ldt, mm-&gt;context.size);</span>
<span class="quote">&gt; -		if (mm-&gt;context.size * LDT_ENTRY_SIZE &gt; PAGE_SIZE)</span>
<span class="quote">&gt; -			vfree(mm-&gt;context.ldt);</span>
<span class="quote">&gt; -		else</span>
<span class="quote">&gt; -			put_page(virt_to_page(mm-&gt;context.ldt));</span>
<span class="quote">&gt; -		mm-&gt;context.size = 0;</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; +	free_ldt_struct(mm-&gt;context.ldt);</span>
<span class="quote">&gt; +	mm-&gt;context.ldt = NULL;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int read_ldt(void __user *ptr, unsigned long bytecount)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	int err;</span>
<span class="quote">&gt; +	int retval;</span>
<span class="quote">&gt;  	unsigned long size;</span>
<span class="quote">&gt;  	struct mm_struct *mm = current-&gt;mm;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (!mm-&gt;context.size)</span>
<span class="quote">&gt; -		return 0;</span>
<span class="quote">&gt; +	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (!mm-&gt;context.ldt) {</span>
<span class="quote">&gt; +		retval = 0;</span>
<span class="quote">&gt; +		goto out_unlock;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	if (bytecount &gt; LDT_ENTRY_SIZE * LDT_ENTRIES)</span>
<span class="quote">&gt;  		bytecount = LDT_ENTRY_SIZE * LDT_ENTRIES;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="quote">&gt; -	size = mm-&gt;context.size * LDT_ENTRY_SIZE;</span>
<span class="quote">&gt; +	size = mm-&gt;context.ldt-&gt;size * LDT_ENTRY_SIZE;</span>
<span class="quote">&gt;  	if (size &gt; bytecount)</span>
<span class="quote">&gt;  		size = bytecount;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	err = 0;</span>
<span class="quote">&gt; -	if (copy_to_user(ptr, mm-&gt;context.ldt, size))</span>
<span class="quote">&gt; -		err = -EFAULT;</span>
<span class="quote">&gt; -	mutex_unlock(&amp;mm-&gt;context.lock);</span>
<span class="quote">&gt; -	if (err &lt; 0)</span>
<span class="quote">&gt; -		goto error_return;</span>
<span class="quote">&gt; +	if (copy_to_user(ptr, mm-&gt;context.ldt-&gt;entries, size)) {</span>
<span class="quote">&gt; +		retval = -EFAULT;</span>
<span class="quote">&gt; +		goto out_unlock;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	if (size != bytecount) {</span>
<span class="quote">&gt; -		/* zero-fill the rest */</span>
<span class="quote">&gt; +		/* Zero-fill the rest and pretend we read bytecount bytes. */</span>
<span class="quote">&gt;  		if (clear_user(ptr + size, bytecount - size) != 0) {</span>

Make that:

		if (clear_user(ptr + size, bytecount - size))
<span class="quote">
&gt; -			err = -EFAULT;</span>
<span class="quote">&gt; -			goto error_return;</span>
<span class="quote">&gt; +			retval = -EFAULT;</span>
<span class="quote">&gt; +			goto out_unlock;</span>
<span class="quote">&gt;  		}</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; -	return bytecount;</span>
<span class="quote">&gt; -error_return:</span>
<span class="quote">&gt; -	return err;</span>
<span class="quote">&gt; +	retval = bytecount;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +out_unlock:</span>
<span class="quote">&gt; +	mutex_unlock(&amp;mm-&gt;context.lock);</span>
<span class="quote">&gt; +	return retval;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int read_default_ldt(void __user *ptr, unsigned long bytecount)</span>
<span class="quote">&gt; @@ -195,6 +210,8 @@ static int write_ldt(void __user *ptr, unsigned long bytecount, int oldmode)</span>
<span class="quote">&gt;  	struct desc_struct ldt;</span>
<span class="quote">&gt;  	int error;</span>
<span class="quote">&gt;  	struct user_desc ldt_info;</span>
<span class="quote">&gt; +	int oldsize, newsize;</span>
<span class="quote">&gt; +	struct ldt_struct *new_ldt, *old_ldt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	error = -EINVAL;</span>
<span class="quote">&gt;  	if (bytecount != sizeof(ldt_info))</span>
<span class="quote">&gt; @@ -213,34 +230,43 @@ static int write_ldt(void __user *ptr, unsigned long bytecount, int oldmode)</span>
<span class="quote">&gt;  			goto out;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="quote">&gt; -	if (ldt_info.entry_number &gt;= mm-&gt;context.size) {</span>
<span class="quote">&gt; -		error = alloc_ldt(&amp;current-&gt;mm-&gt;context,</span>
<span class="quote">&gt; -				  ldt_info.entry_number + 1, 1);</span>
<span class="quote">&gt; -		if (error &lt; 0)</span>
<span class="quote">&gt; -			goto out_unlock;</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -	/* Allow LDTs to be cleared by the user. */</span>
<span class="quote">&gt; -	if (ldt_info.base_addr == 0 &amp;&amp; ldt_info.limit == 0) {</span>
<span class="quote">&gt; -		if (oldmode || LDT_empty(&amp;ldt_info)) {</span>
<span class="quote">&gt; -			memset(&amp;ldt, 0, sizeof(ldt));</span>
<span class="quote">&gt; -			goto install;</span>
<span class="quote">&gt; +	if ((oldmode &amp;&amp; ldt_info.base_addr == 0 &amp;&amp; ldt_info.limit == 0) ||</span>

Shorten:

	if ((oldmode &amp;&amp; !ldt_info.base_addr &amp;&amp; !ldt_info.limit) ||
<span class="quote">
&gt; +	    LDT_empty(&amp;ldt_info)) {</span>
<span class="quote">&gt; +		/* The user wants to clear the entry. */</span>
<span class="quote">&gt; +		memset(&amp;ldt, 0, sizeof(ldt));</span>
<span class="quote">&gt; +	} else {</span>
<span class="quote">&gt; +		if (!IS_ENABLED(CONFIG_X86_16BIT) &amp;&amp; !ldt_info.seg_32bit) {</span>
<span class="quote">&gt; +			error = -EINVAL;</span>
<span class="quote">&gt; +			goto out;</span>
<span class="quote">&gt;  		}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		fill_ldt(&amp;ldt, &amp;ldt_info);</span>
<span class="quote">&gt; +		if (oldmode)</span>
<span class="quote">&gt; +			ldt.avl = 0;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (!IS_ENABLED(CONFIG_X86_16BIT) &amp;&amp; !ldt_info.seg_32bit) {</span>
<span class="quote">&gt; -		error = -EINVAL;</span>
<span class="quote">&gt; +	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	old_ldt = mm-&gt;context.ldt;</span>
<span class="quote">&gt; +	oldsize = old_ldt ? old_ldt-&gt;size : 0;</span>
<span class="quote">&gt; +	newsize = max((int)(ldt_info.entry_number + 1), oldsize);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	error = -ENOMEM;</span>
<span class="quote">&gt; +	new_ldt = alloc_ldt_struct(newsize);</span>
<span class="quote">&gt; +	if (!new_ldt)</span>
<span class="quote">&gt;  		goto out_unlock;</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	fill_ldt(&amp;ldt, &amp;ldt_info);</span>
<span class="quote">&gt; -	if (oldmode)</span>
<span class="quote">&gt; -		ldt.avl = 0;</span>
<span class="quote">&gt; +	if (old_ldt) {</span>
<span class="quote">&gt; +		memcpy(new_ldt-&gt;entries, old_ldt-&gt;entries,</span>
<span class="quote">&gt; +		       oldsize * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt; +	}</span>

Single if-statement doesn&#39;t need {} and you don&#39;t absolutely need to
keep 80cols. Just let it stick out.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=60131">Boris Ostrovsky</a> - July 25, 2015, 4:13 a.m.</div>
<pre class="content">
On 07/22/2015 06:20 PM, Boris Ostrovsky wrote:
<span class="quote">&gt; On 07/22/2015 03:23 PM, Andy Lutomirski wrote:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +    error = -ENOMEM;</span>
<span class="quote">&gt;&gt; +    new_ldt = alloc_ldt_struct(newsize);</span>
<span class="quote">&gt;&gt; +    if (!new_ldt)</span>
<span class="quote">&gt;&gt;           goto out_unlock;</span>
<span class="quote">&gt;&gt; -    }</span>
<span class="quote">&gt;&gt;   -    fill_ldt(&amp;ldt, &amp;ldt_info);</span>
<span class="quote">&gt;&gt; -    if (oldmode)</span>
<span class="quote">&gt;&gt; -        ldt.avl = 0;</span>
<span class="quote">&gt;&gt; +    if (old_ldt) {</span>
<span class="quote">&gt;&gt; +        memcpy(new_ldt-&gt;entries, old_ldt-&gt;entries,</span>
<span class="quote">&gt;&gt; +               oldsize * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt;&gt; +    }</span>
<span class="quote">&gt;&gt; +    memset(new_ldt-&gt;entries + oldsize * LDT_ENTRY_SIZE, 0,</span>
<span class="quote">&gt;&gt; +           (newsize - oldsize) * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; We need to zero out full page (probably better in alloc_ldt_struct() </span>
<span class="quote">&gt; with vmzalloc/__GFP_ZERO) --- Xen checks whole page that is assigned </span>
<span class="quote">&gt; to  G/LDT and gets unhappy if an invalid descriptor is found there.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This fixes one problem. There is something else that Xen gets upset </span>
<span class="quote">&gt; about, I haven&#39;t figured what it is yet (and I am out tomorrow so it </span>
<span class="quote">&gt; may need to wait until Friday).</span>
<span class="quote">&gt;</span>


What I thought was another problem turned out not to be one so both 64- 
and 32-bit tests passed on 64-bit PV (when allocated LDT is zeroed out)

However, on 32-bit kernel the test is failing multicpu test, I don&#39;t 
know yet what it is.

-boris


--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=41531">Andy Lutomirski</a> - July 25, 2015, 4:52 a.m.</div>
<pre class="content">
On Fri, Jul 24, 2015 at 8:29 AM, Borislav Petkov &lt;bp@alien8.de&gt; wrote:
<span class="quote">&gt; Let it stick out:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         if (!cpumask_equal(mm_cpumask(current_mm), cpumask_of(smp_processor_id())))</span>
<span class="quote">&gt;                 smp_call_function(flush_ldt, current_mm, 1);</span>

I see your wide terminal and raise you a complete rewrite of that
function.  Sigh, why did I assume the old code was the right way to do
it?
<span class="quote">
&gt;&gt;  #endif</span>
<span class="quote">&gt;&gt; -     }</span>
<span class="quote">&gt;&gt; -     if (oldsize) {</span>
<span class="quote">&gt;&gt; -             paravirt_free_ldt(oldldt, oldsize);</span>
<span class="quote">&gt;&gt; -             if (oldsize * LDT_ENTRY_SIZE &gt; PAGE_SIZE)</span>
<span class="quote">&gt;&gt; -                     vfree(oldldt);</span>
<span class="quote">&gt;&gt; -             else</span>
<span class="quote">&gt;&gt; -                     put_page(virt_to_page(oldldt));</span>
<span class="quote">&gt;&gt; -     }</span>
<span class="quote">&gt;&gt; -     return 0;</span>
<span class="quote">&gt;&gt; +     preempt_enable();</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -static inline int copy_ldt(mm_context_t *new, mm_context_t *old)</span>
<span class="quote">&gt;&gt; +static void free_ldt_struct(struct ldt_struct *ldt)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt; -     int err = alloc_ldt(new, old-&gt;size, 0);</span>
<span class="quote">&gt;&gt; -     int i;</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt; -     if (err &lt; 0)</span>
<span class="quote">&gt;&gt; -             return err;</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt; -     for (i = 0; i &lt; old-&gt;size; i++)</span>
<span class="quote">&gt;&gt; -             write_ldt_entry(new-&gt;ldt, i, old-&gt;ldt + i * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt;&gt; -     return 0;</span>
<span class="quote">&gt;&gt; +     if (unlikely(ldt)) {</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Save an indentation level:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         int alloc_size;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         if (!ldt)</span>
<span class="quote">&gt;                 return;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         alloc_size = sizeof(struct ldt_struct) + ldt-&gt;size * LDT_ENTRY_SIZE;</span>
<span class="quote">&gt;</span>

Hah we both missed it.  This is wrong.  (Fix your backport!)
<span class="quote">
&gt;         ...</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +             paravirt_free_ldt(ldt-&gt;entries, ldt-&gt;size);</span>
<span class="quote">&gt;&gt; +             if (alloc_size &gt; PAGE_SIZE)</span>
<span class="quote">&gt;&gt; +                     vfree(ldt-&gt;entries);</span>
<span class="quote">&gt;&gt; +             else</span>
<span class="quote">&gt;&gt; +                     put_page(virt_to_page(ldt-&gt;entries));</span>

I&#39;m not sure this is correct, so I changed it to something obviously
correct (kmalloc/kfree).
<span class="quote">
&gt;&gt;</span>
<span class="quote">&gt;&gt; -     fill_ldt(&amp;ldt, &amp;ldt_info);</span>
<span class="quote">&gt;&gt; -     if (oldmode)</span>
<span class="quote">&gt;&gt; -             ldt.avl = 0;</span>
<span class="quote">&gt;&gt; +     if (old_ldt) {</span>
<span class="quote">&gt;&gt; +             memcpy(new_ldt-&gt;entries, old_ldt-&gt;entries,</span>
<span class="quote">&gt;&gt; +                    oldsize * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt;&gt; +     }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Single if-statement doesn&#39;t need {} and you don&#39;t absolutely need to</span>
<span class="quote">&gt; keep 80cols. Just let it stick out.</span>

You read too many of Linus&#39; comments about using wider terminals :)

--Andy
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=41531">Andy Lutomirski</a> - July 25, 2015, 4:58 a.m.</div>
<pre class="content">
On Fri, Jul 24, 2015 at 9:13 PM, Boris Ostrovsky
&lt;boris.ostrovsky@oracle.com&gt; wrote:
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; On 07/22/2015 06:20 PM, Boris Ostrovsky wrote:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; On 07/22/2015 03:23 PM, Andy Lutomirski wrote:</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; +    error = -ENOMEM;</span>
<span class="quote">&gt;&gt;&gt; +    new_ldt = alloc_ldt_struct(newsize);</span>
<span class="quote">&gt;&gt;&gt; +    if (!new_ldt)</span>
<span class="quote">&gt;&gt;&gt;           goto out_unlock;</span>
<span class="quote">&gt;&gt;&gt; -    }</span>
<span class="quote">&gt;&gt;&gt;   -    fill_ldt(&amp;ldt, &amp;ldt_info);</span>
<span class="quote">&gt;&gt;&gt; -    if (oldmode)</span>
<span class="quote">&gt;&gt;&gt; -        ldt.avl = 0;</span>
<span class="quote">&gt;&gt;&gt; +    if (old_ldt) {</span>
<span class="quote">&gt;&gt;&gt; +        memcpy(new_ldt-&gt;entries, old_ldt-&gt;entries,</span>
<span class="quote">&gt;&gt;&gt; +               oldsize * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt;&gt;&gt; +    }</span>
<span class="quote">&gt;&gt;&gt; +    memset(new_ldt-&gt;entries + oldsize * LDT_ENTRY_SIZE, 0,</span>
<span class="quote">&gt;&gt;&gt; +           (newsize - oldsize) * LDT_ENTRY_SIZE);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; We need to zero out full page (probably better in alloc_ldt_struct() with</span>
<span class="quote">&gt;&gt; vmzalloc/__GFP_ZERO) --- Xen checks whole page that is assigned to  G/LDT</span>
<span class="quote">&gt;&gt; and gets unhappy if an invalid descriptor is found there.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This fixes one problem. There is something else that Xen gets upset about,</span>
<span class="quote">&gt;&gt; I haven&#39;t figured what it is yet (and I am out tomorrow so it may need to</span>
<span class="quote">&gt;&gt; wait until Friday).</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; What I thought was another problem turned out not to be one so both 64- and</span>
<span class="quote">&gt; 32-bit tests passed on 64-bit PV (when allocated LDT is zeroed out)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; However, on 32-bit kernel the test is failing multicpu test, I don&#39;t know</span>
<span class="quote">&gt; yet what it is.</span>

Test case bug or unrelated kernel bug depending on your point of view.
I forgot that x86_32 and x86_64 have very different handling of IRET
faults.  Wait for v2 :)

--Andy
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7500">Borislav Petkov</a> - July 25, 2015, 8:37 a.m.</div>
<pre class="content">
On Fri, Jul 24, 2015 at 09:52:01PM -0700, Andy Lutomirski wrote:
<span class="quote">&gt; I see your wide terminal and raise you a complete rewrite of that</span>
<span class="quote">&gt; function.  Sigh, why did I assume the old code was the right way to do</span>
<span class="quote">&gt; it?</span>

That&#39;s a mostly wrong assumption, as experience proves.
<span class="quote">
&gt; Hah we both missed it.  This is wrong.  (Fix your backport!)</span>

Yikes:

	alloc_size = size * LDT_ENTRY_SIZE;

But hey, I made you spot it, still! :-)

Done.
<span class="quote">
&gt; I&#39;m not sure this is correct, so I changed it to something obviously</span>
<span class="quote">&gt; correct (kmalloc/kfree).</span>

Someone thought she won&#39;t get contiguous memory from kmalloc(). But how
big can alloc_size be to fail...
<span class="quote">
&gt; You read too many of Linus&#39; comments about using wider terminals :)</span>

Nah, I&#39;m just trying to put back some sanity in that 80 cols rule which,
even you, think is a hard one. And I say, keep 80 cols but sanity can
override it if what 80 cols produces, is crap.

I trust you&#39;re sane enough to apply that and not think C++ or java
wankery. Woahahahah...
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/desc.h b/arch/x86/include/asm/desc.h</span>
<span class="p_header">index a0bf89fd2647..4e10d73cf018 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/desc.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/desc.h</span>
<span class="p_chunk">@@ -280,21 +280,6 @@</span> <span class="p_context"> static inline void clear_LDT(void)</span>
 	set_ldt(NULL, 0);
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * load one particular LDT into the current CPU</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline void load_LDT_nolock(mm_context_t *pc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	set_ldt(pc-&gt;ldt, pc-&gt;size);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void load_LDT(mm_context_t *pc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	preempt_disable();</span>
<span class="p_del">-	load_LDT_nolock(pc);</span>
<span class="p_del">-	preempt_enable();</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static inline unsigned long get_desc_base(const struct desc_struct *desc)
 {
 	return (unsigned)(desc-&gt;base0 | ((desc-&gt;base1) &lt;&lt; 16) | ((desc-&gt;base2) &lt;&lt; 24));
<span class="p_header">diff --git a/arch/x86/include/asm/mmu.h b/arch/x86/include/asm/mmu.h</span>
<span class="p_header">index 09b9620a73b4..364d27481a52 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mmu.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mmu.h</span>
<span class="p_chunk">@@ -9,8 +9,7 @@</span> <span class="p_context"></span>
  * we put the segment information here.
  */
 typedef struct {
<span class="p_del">-	void *ldt;</span>
<span class="p_del">-	int size;</span>
<span class="p_add">+	struct ldt_struct *ldt;</span>
 
 #ifdef CONFIG_X86_64
 	/* True if mm supports a task running in 32 bit compatibility mode. */
<span class="p_header">diff --git a/arch/x86/include/asm/mmu_context.h b/arch/x86/include/asm/mmu_context.h</span>
<span class="p_header">index 804a3a6030ca..3fcff70c398e 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mmu_context.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mmu_context.h</span>
<span class="p_chunk">@@ -34,6 +34,49 @@</span> <span class="p_context"> static inline void load_mm_cr4(struct mm_struct *mm) {}</span>
 #endif
 
 /*
<span class="p_add">+ * ldt_structs can be allocated, used, and freed, but they are never</span>
<span class="p_add">+ * modified while live.</span>
<span class="p_add">+ */</span>
<span class="p_add">+struct ldt_struct {</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Xen requires page-aligned LDTs with special permissions.  This is</span>
<span class="p_add">+	 * needed to prevent us from installing evil descriptors such as</span>
<span class="p_add">+	 * call gates.  On native, we could merge the ldt_struct and LDT</span>
<span class="p_add">+	 * allocations, but it&#39;s not worth trying to optimize.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	struct desc_struct *entries;</span>
<span class="p_add">+	int size;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void load_mm_ldt(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct ldt_struct *ldt;</span>
<span class="p_add">+	DEBUG_LOCKS_WARN_ON(!irqs_disabled());</span>
<span class="p_add">+</span>
<span class="p_add">+	/* lockless_dereference synchronizes with smp_store_release */</span>
<span class="p_add">+	ldt = lockless_dereference(mm-&gt;context.ldt);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Any change to mm-&gt;context.ldt is followed by an IPI to all</span>
<span class="p_add">+	 * CPUs with the mm active.  The LDT will not be freed until</span>
<span class="p_add">+	 * after the IPI is handled by all such CPUs.  This means that,</span>
<span class="p_add">+	 * if the ldt_struct changes before we return, the values we see</span>
<span class="p_add">+	 * will be safe, and the new values will be loaded before we run</span>
<span class="p_add">+	 * any user code.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * NB: don&#39;t try to convert this to use RCU without extreme care.</span>
<span class="p_add">+	 * We would still need IRQs off, because we don&#39;t want to change</span>
<span class="p_add">+	 * the local LDT after an IPI loaded a newer value than the one</span>
<span class="p_add">+	 * that we can see.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(ldt))</span>
<span class="p_add">+		set_ldt(ldt-&gt;entries, ldt-&gt;size);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		clear_LDT();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Used for LDT copy/destruction.
  */
 int init_new_context(struct task_struct *tsk, struct mm_struct *mm);
<span class="p_chunk">@@ -78,12 +121,12 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,</span>
 		 * was called and then modify_ldt changed
 		 * prev-&gt;context.ldt but suppressed an IPI to this CPU.
 		 * In this case, prev-&gt;context.ldt != NULL, because we
<span class="p_del">-		 * never free an LDT while the mm still exists.  That</span>
<span class="p_del">-		 * means that next-&gt;context.ldt != prev-&gt;context.ldt,</span>
<span class="p_del">-		 * because mms never share an LDT.</span>
<span class="p_add">+		 * never set context.ldt to NULL while the mm still</span>
<span class="p_add">+		 * exists.  That means that next-&gt;context.ldt !=</span>
<span class="p_add">+		 * prev-&gt;context.ldt, because mms never share an LDT.</span>
 		 */
 		if (unlikely(prev-&gt;context.ldt != next-&gt;context.ldt))
<span class="p_del">-			load_LDT_nolock(&amp;next-&gt;context);</span>
<span class="p_add">+			load_mm_ldt(next);</span>
 	}
 #ifdef CONFIG_SMP
 	  else {
<span class="p_chunk">@@ -106,7 +149,7 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,</span>
 			load_cr3(next-&gt;pgd);
 			trace_tlb_flush(TLB_FLUSH_ON_TASK_SWITCH, TLB_FLUSH_ALL);
 			load_mm_cr4(next);
<span class="p_del">-			load_LDT_nolock(&amp;next-&gt;context);</span>
<span class="p_add">+			load_mm_ldt(next);</span>
 		}
 	}
 #endif
<span class="p_header">diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c</span>
<span class="p_header">index 922c5e0cea4c..cb9e5df42dd2 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/common.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/common.c</span>
<span class="p_chunk">@@ -1410,7 +1410,7 @@</span> <span class="p_context"> void cpu_init(void)</span>
 	load_sp0(t, &amp;current-&gt;thread);
 	set_tss_desc(cpu, t);
 	load_TR_desc();
<span class="p_del">-	load_LDT(&amp;init_mm.context);</span>
<span class="p_add">+	load_mm_ldt(&amp;init_mm);</span>
 
 	clear_all_debug_regs();
 	dbg_restore_debug_regs();
<span class="p_chunk">@@ -1459,7 +1459,7 @@</span> <span class="p_context"> void cpu_init(void)</span>
 	load_sp0(t, thread);
 	set_tss_desc(cpu, t);
 	load_TR_desc();
<span class="p_del">-	load_LDT(&amp;init_mm.context);</span>
<span class="p_add">+	load_mm_ldt(&amp;init_mm);</span>
 
 	t-&gt;x86_tss.io_bitmap_base = offsetof(struct tss_struct, io_bitmap);
 
<span class="p_header">diff --git a/arch/x86/kernel/cpu/perf_event.c b/arch/x86/kernel/cpu/perf_event.c</span>
<span class="p_header">index 3658de47900f..9469dfa55607 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/perf_event.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/perf_event.c</span>
<span class="p_chunk">@@ -2179,21 +2179,25 @@</span> <span class="p_context"> static unsigned long get_segment_base(unsigned int segment)</span>
 	int idx = segment &gt;&gt; 3;
 
 	if ((segment &amp; SEGMENT_TI_MASK) == SEGMENT_LDT) {
<span class="p_add">+		struct ldt_struct *ldt;</span>
<span class="p_add">+</span>
 		if (idx &gt; LDT_ENTRIES)
 			return 0;
 
<span class="p_del">-		if (idx &gt; current-&gt;active_mm-&gt;context.size)</span>
<span class="p_add">+		/* IRQs are off, so this synchronizes with smp_store_release */</span>
<span class="p_add">+		ldt = lockless_dereference(current-&gt;active_mm-&gt;context.ldt);</span>
<span class="p_add">+		if (!ldt || idx &gt; ldt-&gt;size)</span>
 			return 0;
 
<span class="p_del">-		desc = current-&gt;active_mm-&gt;context.ldt;</span>
<span class="p_add">+		desc = &amp;ldt-&gt;entries[idx];</span>
 	} else {
 		if (idx &gt; GDT_ENTRIES)
 			return 0;
 
<span class="p_del">-		desc = raw_cpu_ptr(gdt_page.gdt);</span>
<span class="p_add">+		desc = raw_cpu_ptr(gdt_page.gdt) + idx;</span>
 	}
 
<span class="p_del">-	return get_desc_base(desc + idx);</span>
<span class="p_add">+	return get_desc_base(desc);</span>
 }
 
 #ifdef CONFIG_COMPAT
<span class="p_header">diff --git a/arch/x86/kernel/ldt.c b/arch/x86/kernel/ldt.c</span>
<span class="p_header">index c37886d759cc..3ae308029dee 100644</span>
<span class="p_header">--- a/arch/x86/kernel/ldt.c</span>
<span class="p_header">+++ b/arch/x86/kernel/ldt.c</span>
<span class="p_chunk">@@ -12,6 +12,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/string.h&gt;
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/smp.h&gt;
<span class="p_add">+#include &lt;linux/slab.h&gt;</span>
 #include &lt;linux/vmalloc.h&gt;
 #include &lt;linux/uaccess.h&gt;
 
<span class="p_chunk">@@ -20,82 +21,83 @@</span> <span class="p_context"></span>
 #include &lt;asm/mmu_context.h&gt;
 #include &lt;asm/syscalls.h&gt;
 
<span class="p_del">-#ifdef CONFIG_SMP</span>
 static void flush_ldt(void *current_mm)
 {
<span class="p_del">-	if (current-&gt;active_mm == current_mm)</span>
<span class="p_del">-		load_LDT(&amp;current-&gt;active_mm-&gt;context);</span>
<span class="p_add">+	if (current-&gt;active_mm == current_mm) {</span>
<span class="p_add">+		/* context.lock is held for us, so we don&#39;t need any locking. */</span>
<span class="p_add">+		mm_context_t *pc = &amp;current-&gt;active_mm-&gt;context;</span>
<span class="p_add">+		set_ldt(pc-&gt;ldt-&gt;entries, pc-&gt;ldt-&gt;size);</span>
<span class="p_add">+	}</span>
 }
<span class="p_del">-#endif</span>
 
<span class="p_del">-static int alloc_ldt(mm_context_t *pc, int mincount, int reload)</span>
<span class="p_add">+/* The caller must call finalize_ldt_struct on the result. */</span>
<span class="p_add">+static struct ldt_struct *alloc_ldt_struct(int size)</span>
 {
<span class="p_del">-	void *oldldt, *newldt;</span>
<span class="p_del">-	int oldsize;</span>
<span class="p_add">+	struct ldt_struct *new_ldt;</span>
<span class="p_add">+	int alloc_size;</span>
 
<span class="p_del">-	if (mincount &lt;= pc-&gt;size)</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-	oldsize = pc-&gt;size;</span>
<span class="p_del">-	mincount = (mincount + (PAGE_SIZE / LDT_ENTRY_SIZE - 1)) &amp;</span>
<span class="p_del">-			(~(PAGE_SIZE / LDT_ENTRY_SIZE - 1));</span>
<span class="p_del">-	if (mincount * LDT_ENTRY_SIZE &gt; PAGE_SIZE)</span>
<span class="p_del">-		newldt = vmalloc(mincount * LDT_ENTRY_SIZE);</span>
<span class="p_add">+	if (size &gt; LDT_ENTRIES)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	new_ldt = kmalloc(sizeof(struct ldt_struct), GFP_KERNEL);</span>
<span class="p_add">+	if (!new_ldt)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	BUILD_BUG_ON(LDT_ENTRY_SIZE != sizeof(struct desc_struct));</span>
<span class="p_add">+	alloc_size = size * LDT_ENTRY_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (alloc_size &gt; PAGE_SIZE)</span>
<span class="p_add">+		new_ldt-&gt;entries = vmalloc(alloc_size);</span>
 	else
<span class="p_del">-		newldt = (void *)__get_free_page(GFP_KERNEL);</span>
<span class="p_add">+		new_ldt-&gt;entries = (void *)__get_free_page(GFP_KERNEL);</span>
<span class="p_add">+	if (!new_ldt-&gt;entries) {</span>
<span class="p_add">+		kfree(new_ldt);</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-	if (!newldt)</span>
<span class="p_del">-		return -ENOMEM;</span>
<span class="p_add">+	new_ldt-&gt;size = size;</span>
<span class="p_add">+	return new_ldt;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* After calling this, the LDT is immutable. */</span>
<span class="p_add">+static void finalize_ldt_struct(struct ldt_struct *ldt)</span>
<span class="p_add">+{</span>
<span class="p_add">+	paravirt_alloc_ldt(ldt-&gt;entries, ldt-&gt;size);</span>
<span class="p_add">+}</span>
 
<span class="p_del">-	if (oldsize)</span>
<span class="p_del">-		memcpy(newldt, pc-&gt;ldt, oldsize * LDT_ENTRY_SIZE);</span>
<span class="p_del">-	oldldt = pc-&gt;ldt;</span>
<span class="p_del">-	memset(newldt + oldsize * LDT_ENTRY_SIZE, 0,</span>
<span class="p_del">-	       (mincount - oldsize) * LDT_ENTRY_SIZE);</span>
<span class="p_add">+static void install_ldt(struct mm_struct *current_mm,</span>
<span class="p_add">+			struct ldt_struct *ldt)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* context.lock is held */</span>
<span class="p_add">+	preempt_disable();</span>
 
<span class="p_del">-	paravirt_alloc_ldt(newldt, mincount);</span>
<span class="p_add">+	/* Synchronizes with lockless_dereference in load_mm_ldt. */</span>
<span class="p_add">+	smp_store_release(&amp;current_mm-&gt;context.ldt, ldt);</span>
 
<span class="p_del">-#ifdef CONFIG_X86_64</span>
<span class="p_del">-	/* CHECKME: Do we really need this ? */</span>
<span class="p_del">-	wmb();</span>
<span class="p_del">-#endif</span>
<span class="p_del">-	pc-&gt;ldt = newldt;</span>
<span class="p_del">-	wmb();</span>
<span class="p_del">-	pc-&gt;size = mincount;</span>
<span class="p_del">-	wmb();</span>
<span class="p_add">+	/* Activate for this CPU. */</span>
<span class="p_add">+	flush_ldt(current-&gt;mm);</span>
 
<span class="p_del">-	if (reload) {</span>
 #ifdef CONFIG_SMP
<span class="p_del">-		preempt_disable();</span>
<span class="p_del">-		load_LDT(pc);</span>
<span class="p_del">-		if (!cpumask_equal(mm_cpumask(current-&gt;mm),</span>
<span class="p_del">-				   cpumask_of(smp_processor_id())))</span>
<span class="p_del">-			smp_call_function(flush_ldt, current-&gt;mm, 1);</span>
<span class="p_del">-		preempt_enable();</span>
<span class="p_del">-#else</span>
<span class="p_del">-		load_LDT(pc);</span>
<span class="p_add">+	/* Synchronize with other CPUs. */</span>
<span class="p_add">+	if (!cpumask_equal(mm_cpumask(current_mm),</span>
<span class="p_add">+			   cpumask_of(smp_processor_id())))</span>
<span class="p_add">+		smp_call_function(flush_ldt, current_mm, 1);</span>
 #endif
<span class="p_del">-	}</span>
<span class="p_del">-	if (oldsize) {</span>
<span class="p_del">-		paravirt_free_ldt(oldldt, oldsize);</span>
<span class="p_del">-		if (oldsize * LDT_ENTRY_SIZE &gt; PAGE_SIZE)</span>
<span class="p_del">-			vfree(oldldt);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			put_page(virt_to_page(oldldt));</span>
<span class="p_del">-	}</span>
<span class="p_del">-	return 0;</span>
<span class="p_add">+	preempt_enable();</span>
 }
 
<span class="p_del">-static inline int copy_ldt(mm_context_t *new, mm_context_t *old)</span>
<span class="p_add">+static void free_ldt_struct(struct ldt_struct *ldt)</span>
 {
<span class="p_del">-	int err = alloc_ldt(new, old-&gt;size, 0);</span>
<span class="p_del">-	int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (err &lt; 0)</span>
<span class="p_del">-		return err;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; old-&gt;size; i++)</span>
<span class="p_del">-		write_ldt_entry(new-&gt;ldt, i, old-&gt;ldt + i * LDT_ENTRY_SIZE);</span>
<span class="p_del">-	return 0;</span>
<span class="p_add">+	if (unlikely(ldt)) {</span>
<span class="p_add">+		int alloc_size = sizeof(struct ldt_struct) +</span>
<span class="p_add">+			ldt-&gt;size * LDT_ENTRY_SIZE;</span>
<span class="p_add">+		paravirt_free_ldt(ldt-&gt;entries, ldt-&gt;size);</span>
<span class="p_add">+		if (alloc_size &gt; PAGE_SIZE)</span>
<span class="p_add">+			vfree(ldt-&gt;entries);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			put_page(virt_to_page(ldt-&gt;entries));</span>
<span class="p_add">+		kfree(ldt);</span>
<span class="p_add">+	}</span>
 }
 
 /*
<span class="p_chunk">@@ -108,13 +110,32 @@</span> <span class="p_context"> int init_new_context(struct task_struct *tsk, struct mm_struct *mm)</span>
 	int retval = 0;
 
 	mutex_init(&amp;mm-&gt;context.lock);
<span class="p_del">-	mm-&gt;context.size = 0;</span>
 	old_mm = current-&gt;mm;
<span class="p_del">-	if (old_mm &amp;&amp; old_mm-&gt;context.size &gt; 0) {</span>
<span class="p_del">-		mutex_lock(&amp;old_mm-&gt;context.lock);</span>
<span class="p_del">-		retval = copy_ldt(&amp;mm-&gt;context, &amp;old_mm-&gt;context);</span>
<span class="p_del">-		mutex_unlock(&amp;old_mm-&gt;context.lock);</span>
<span class="p_add">+	if (!old_mm) {</span>
<span class="p_add">+		mm-&gt;context.ldt = NULL;</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;old_mm-&gt;context.lock);</span>
<span class="p_add">+	if (old_mm-&gt;context.ldt) {</span>
<span class="p_add">+		struct ldt_struct *new_ldt =</span>
<span class="p_add">+			alloc_ldt_struct(old_mm-&gt;context.ldt-&gt;size);</span>
<span class="p_add">+		if (!new_ldt) {</span>
<span class="p_add">+			retval = -ENOMEM;</span>
<span class="p_add">+			goto out_unlock;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		memcpy(new_ldt-&gt;entries, old_mm-&gt;context.ldt-&gt;entries,</span>
<span class="p_add">+		       new_ldt-&gt;size * LDT_ENTRY_SIZE);</span>
<span class="p_add">+		finalize_ldt_struct(new_ldt);</span>
<span class="p_add">+</span>
<span class="p_add">+		mm-&gt;context.ldt = new_ldt;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		mm-&gt;context.ldt = NULL;</span>
 	}
<span class="p_add">+</span>
<span class="p_add">+out_unlock:</span>
<span class="p_add">+	mutex_unlock(&amp;old_mm-&gt;context.lock);</span>
 	return retval;
 }
 
<span class="p_chunk">@@ -125,53 +146,47 @@</span> <span class="p_context"> int init_new_context(struct task_struct *tsk, struct mm_struct *mm)</span>
  */
 void destroy_context(struct mm_struct *mm)
 {
<span class="p_del">-	if (mm-&gt;context.size) {</span>
<span class="p_del">-#ifdef CONFIG_X86_32</span>
<span class="p_del">-		/* CHECKME: Can this ever happen ? */</span>
<span class="p_del">-		if (mm == current-&gt;active_mm)</span>
<span class="p_del">-			clear_LDT();</span>
<span class="p_del">-#endif</span>
<span class="p_del">-		paravirt_free_ldt(mm-&gt;context.ldt, mm-&gt;context.size);</span>
<span class="p_del">-		if (mm-&gt;context.size * LDT_ENTRY_SIZE &gt; PAGE_SIZE)</span>
<span class="p_del">-			vfree(mm-&gt;context.ldt);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			put_page(virt_to_page(mm-&gt;context.ldt));</span>
<span class="p_del">-		mm-&gt;context.size = 0;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	free_ldt_struct(mm-&gt;context.ldt);</span>
<span class="p_add">+	mm-&gt;context.ldt = NULL;</span>
 }
 
 static int read_ldt(void __user *ptr, unsigned long bytecount)
 {
<span class="p_del">-	int err;</span>
<span class="p_add">+	int retval;</span>
 	unsigned long size;
 	struct mm_struct *mm = current-&gt;mm;
 
<span class="p_del">-	if (!mm-&gt;context.size)</span>
<span class="p_del">-		return 0;</span>
<span class="p_add">+	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!mm-&gt;context.ldt) {</span>
<span class="p_add">+		retval = 0;</span>
<span class="p_add">+		goto out_unlock;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (bytecount &gt; LDT_ENTRY_SIZE * LDT_ENTRIES)
 		bytecount = LDT_ENTRY_SIZE * LDT_ENTRIES;
 
<span class="p_del">-	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="p_del">-	size = mm-&gt;context.size * LDT_ENTRY_SIZE;</span>
<span class="p_add">+	size = mm-&gt;context.ldt-&gt;size * LDT_ENTRY_SIZE;</span>
 	if (size &gt; bytecount)
 		size = bytecount;
 
<span class="p_del">-	err = 0;</span>
<span class="p_del">-	if (copy_to_user(ptr, mm-&gt;context.ldt, size))</span>
<span class="p_del">-		err = -EFAULT;</span>
<span class="p_del">-	mutex_unlock(&amp;mm-&gt;context.lock);</span>
<span class="p_del">-	if (err &lt; 0)</span>
<span class="p_del">-		goto error_return;</span>
<span class="p_add">+	if (copy_to_user(ptr, mm-&gt;context.ldt-&gt;entries, size)) {</span>
<span class="p_add">+		retval = -EFAULT;</span>
<span class="p_add">+		goto out_unlock;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (size != bytecount) {
<span class="p_del">-		/* zero-fill the rest */</span>
<span class="p_add">+		/* Zero-fill the rest and pretend we read bytecount bytes. */</span>
 		if (clear_user(ptr + size, bytecount - size) != 0) {
<span class="p_del">-			err = -EFAULT;</span>
<span class="p_del">-			goto error_return;</span>
<span class="p_add">+			retval = -EFAULT;</span>
<span class="p_add">+			goto out_unlock;</span>
 		}
 	}
<span class="p_del">-	return bytecount;</span>
<span class="p_del">-error_return:</span>
<span class="p_del">-	return err;</span>
<span class="p_add">+	retval = bytecount;</span>
<span class="p_add">+</span>
<span class="p_add">+out_unlock:</span>
<span class="p_add">+	mutex_unlock(&amp;mm-&gt;context.lock);</span>
<span class="p_add">+	return retval;</span>
 }
 
 static int read_default_ldt(void __user *ptr, unsigned long bytecount)
<span class="p_chunk">@@ -195,6 +210,8 @@</span> <span class="p_context"> static int write_ldt(void __user *ptr, unsigned long bytecount, int oldmode)</span>
 	struct desc_struct ldt;
 	int error;
 	struct user_desc ldt_info;
<span class="p_add">+	int oldsize, newsize;</span>
<span class="p_add">+	struct ldt_struct *new_ldt, *old_ldt;</span>
 
 	error = -EINVAL;
 	if (bytecount != sizeof(ldt_info))
<span class="p_chunk">@@ -213,34 +230,43 @@</span> <span class="p_context"> static int write_ldt(void __user *ptr, unsigned long bytecount, int oldmode)</span>
 			goto out;
 	}
 
<span class="p_del">-	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="p_del">-	if (ldt_info.entry_number &gt;= mm-&gt;context.size) {</span>
<span class="p_del">-		error = alloc_ldt(&amp;current-&gt;mm-&gt;context,</span>
<span class="p_del">-				  ldt_info.entry_number + 1, 1);</span>
<span class="p_del">-		if (error &lt; 0)</span>
<span class="p_del">-			goto out_unlock;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Allow LDTs to be cleared by the user. */</span>
<span class="p_del">-	if (ldt_info.base_addr == 0 &amp;&amp; ldt_info.limit == 0) {</span>
<span class="p_del">-		if (oldmode || LDT_empty(&amp;ldt_info)) {</span>
<span class="p_del">-			memset(&amp;ldt, 0, sizeof(ldt));</span>
<span class="p_del">-			goto install;</span>
<span class="p_add">+	if ((oldmode &amp;&amp; ldt_info.base_addr == 0 &amp;&amp; ldt_info.limit == 0) ||</span>
<span class="p_add">+	    LDT_empty(&amp;ldt_info)) {</span>
<span class="p_add">+		/* The user wants to clear the entry. */</span>
<span class="p_add">+		memset(&amp;ldt, 0, sizeof(ldt));</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		if (!IS_ENABLED(CONFIG_X86_16BIT) &amp;&amp; !ldt_info.seg_32bit) {</span>
<span class="p_add">+			error = -EINVAL;</span>
<span class="p_add">+			goto out;</span>
 		}
<span class="p_add">+</span>
<span class="p_add">+		fill_ldt(&amp;ldt, &amp;ldt_info);</span>
<span class="p_add">+		if (oldmode)</span>
<span class="p_add">+			ldt.avl = 0;</span>
 	}
 
<span class="p_del">-	if (!IS_ENABLED(CONFIG_X86_16BIT) &amp;&amp; !ldt_info.seg_32bit) {</span>
<span class="p_del">-		error = -EINVAL;</span>
<span class="p_add">+	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	old_ldt = mm-&gt;context.ldt;</span>
<span class="p_add">+	oldsize = old_ldt ? old_ldt-&gt;size : 0;</span>
<span class="p_add">+	newsize = max((int)(ldt_info.entry_number + 1), oldsize);</span>
<span class="p_add">+</span>
<span class="p_add">+	error = -ENOMEM;</span>
<span class="p_add">+	new_ldt = alloc_ldt_struct(newsize);</span>
<span class="p_add">+	if (!new_ldt)</span>
 		goto out_unlock;
<span class="p_del">-	}</span>
 
<span class="p_del">-	fill_ldt(&amp;ldt, &amp;ldt_info);</span>
<span class="p_del">-	if (oldmode)</span>
<span class="p_del">-		ldt.avl = 0;</span>
<span class="p_add">+	if (old_ldt) {</span>
<span class="p_add">+		memcpy(new_ldt-&gt;entries, old_ldt-&gt;entries,</span>
<span class="p_add">+		       oldsize * LDT_ENTRY_SIZE);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	memset(new_ldt-&gt;entries + oldsize * LDT_ENTRY_SIZE, 0,</span>
<span class="p_add">+	       (newsize - oldsize) * LDT_ENTRY_SIZE);</span>
<span class="p_add">+	new_ldt-&gt;entries[ldt_info.entry_number] = ldt;</span>
<span class="p_add">+	finalize_ldt_struct(new_ldt);</span>
 
<span class="p_del">-	/* Install the new entry ...  */</span>
<span class="p_del">-install:</span>
<span class="p_del">-	write_ldt_entry(mm-&gt;context.ldt, ldt_info.entry_number, &amp;ldt);</span>
<span class="p_add">+	install_ldt(mm, new_ldt);</span>
<span class="p_add">+	free_ldt_struct(old_ldt);</span>
 	error = 0;
 
 out_unlock:
<span class="p_header">diff --git a/arch/x86/kernel/process_64.c b/arch/x86/kernel/process_64.c</span>
<span class="p_header">index 71d7849a07f7..f6b916387590 100644</span>
<span class="p_header">--- a/arch/x86/kernel/process_64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/process_64.c</span>
<span class="p_chunk">@@ -121,11 +121,11 @@</span> <span class="p_context"> void __show_regs(struct pt_regs *regs, int all)</span>
 void release_thread(struct task_struct *dead_task)
 {
 	if (dead_task-&gt;mm) {
<span class="p_del">-		if (dead_task-&gt;mm-&gt;context.size) {</span>
<span class="p_add">+		if (dead_task-&gt;mm-&gt;context.ldt) {</span>
 			pr_warn(&quot;WARNING: dead process %s still has LDT? &lt;%p/%d&gt;\n&quot;,
 				dead_task-&gt;comm,
 				dead_task-&gt;mm-&gt;context.ldt,
<span class="p_del">-				dead_task-&gt;mm-&gt;context.size);</span>
<span class="p_add">+				dead_task-&gt;mm-&gt;context.ldt-&gt;size);</span>
 			BUG();
 		}
 	}
<span class="p_header">diff --git a/arch/x86/kernel/step.c b/arch/x86/kernel/step.c</span>
<span class="p_header">index 9b4d51d0c0d0..6273324186ac 100644</span>
<span class="p_header">--- a/arch/x86/kernel/step.c</span>
<span class="p_header">+++ b/arch/x86/kernel/step.c</span>
<span class="p_chunk">@@ -5,6 +5,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/ptrace.h&gt;
 #include &lt;asm/desc.h&gt;
<span class="p_add">+#include &lt;asm/mmu_context.h&gt;</span>
 
 unsigned long convert_ip_to_linear(struct task_struct *child, struct pt_regs *regs)
 {
<span class="p_chunk">@@ -30,10 +31,11 @@</span> <span class="p_context"> unsigned long convert_ip_to_linear(struct task_struct *child, struct pt_regs *re</span>
 		seg &amp;= ~7UL;
 
 		mutex_lock(&amp;child-&gt;mm-&gt;context.lock);
<span class="p_del">-		if (unlikely((seg &gt;&gt; 3) &gt;= child-&gt;mm-&gt;context.size))</span>
<span class="p_add">+		if (unlikely(!child-&gt;mm-&gt;context.ldt ||</span>
<span class="p_add">+			     (seg &gt;&gt; 3) &gt;= child-&gt;mm-&gt;context.ldt-&gt;size))</span>
 			addr = -1L; /* bogus selector, access would fault */
 		else {
<span class="p_del">-			desc = child-&gt;mm-&gt;context.ldt + seg;</span>
<span class="p_add">+			desc = &amp;child-&gt;mm-&gt;context.ldt-&gt;entries[seg];</span>
 			base = get_desc_base(desc);
 
 			/* 16-bit code segment? */
<span class="p_header">diff --git a/arch/x86/power/cpu.c b/arch/x86/power/cpu.c</span>
<span class="p_header">index 0d7dd1f5ac36..9ab52791fed5 100644</span>
<span class="p_header">--- a/arch/x86/power/cpu.c</span>
<span class="p_header">+++ b/arch/x86/power/cpu.c</span>
<span class="p_chunk">@@ -22,6 +22,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/fpu/internal.h&gt;
 #include &lt;asm/debugreg.h&gt;
 #include &lt;asm/cpu.h&gt;
<span class="p_add">+#include &lt;asm/mmu_context.h&gt;</span>
 
 #ifdef CONFIG_X86_32
 __visible unsigned long saved_context_ebx;
<span class="p_chunk">@@ -153,7 +154,7 @@</span> <span class="p_context"> static void fix_processor_context(void)</span>
 	syscall_init();				/* This sets MSR_*STAR and related */
 #endif
 	load_TR_desc();				/* This does ltr */
<span class="p_del">-	load_LDT(&amp;current-&gt;active_mm-&gt;context);	/* This does lldt */</span>
<span class="p_add">+	load_mm_ldt(current-&gt;active_mm);	/* This does lldt */</span>
 
 	fpu__resume_cpu();
 }

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



