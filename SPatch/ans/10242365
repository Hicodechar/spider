
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[GIT,pull] x86/pti updates for 4.16 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [GIT,pull] x86/pti updates for 4.16</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=107">Thomas Gleixner</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Feb. 26, 2018, 1:25 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;alpine.DEB.2.21.1802261358090.1896@nanos.tec.linutronix.de&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10242365/mbox/"
   >mbox</a>
|
   <a href="/patch/10242365/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10242365/">/patch/10242365/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	DCB13602DC for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 26 Feb 2018 13:25:25 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id C42932A009
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 26 Feb 2018 13:25:25 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id B6CFF2A00E; Mon, 26 Feb 2018 13:25:25 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A881A2A009
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 26 Feb 2018 13:25:21 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753571AbeBZNZP (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 26 Feb 2018 08:25:15 -0500
Received: from Galois.linutronix.de ([146.0.238.70]:43836 &quot;EHLO
	Galois.linutronix.de&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753271AbeBZNZJ (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 26 Feb 2018 08:25:09 -0500
Received: from hsi-kbw-5-158-153-52.hsi19.kabel-badenwuerttemberg.de
	([5.158.153.52] helo=nanos.tec.linutronix.de)
	by Galois.linutronix.de with esmtpsa
	(TLS1.2:DHE_RSA_AES_256_CBC_SHA256:256) (Exim 4.80)
	(envelope-from &lt;tglx@linutronix.de&gt;)
	id 1eqIij-00021h-1d; Mon, 26 Feb 2018 14:21:33 +0100
Date: Mon, 26 Feb 2018 14:25:23 +0100 (CET)
From: Thomas Gleixner &lt;tglx@linutronix.de&gt;
To: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
cc: LKML &lt;linux-kernel@vger.kernel.org&gt;, Ingo Molnar &lt;mingo@kernel.org&gt;,
	Greg KH &lt;gregkh@linuxfoundation.org&gt;, David Woodhouse &lt;dwmw@amazon.co.uk&gt;
Subject: [GIT pull] x86/pti updates for 4.16
Message-ID: &lt;alpine.DEB.2.21.1802261358090.1896@nanos.tec.linutronix.de&gt;
User-Agent: Alpine 2.21 (DEB 202 2017-01-01)
MIME-Version: 1.0
Content-Type: multipart/mixed; boundary=&quot;8323329-421047950-1519651523=:1896&quot;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=107">Thomas Gleixner</a> - Feb. 26, 2018, 1:25 p.m.</div>
<pre class="content">
Linus,

please pull the latest x86-pti-for-linus git tree from:

   git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git x86-pti-for-linus

Yet another pile of melted spectrum related changes:

 - Sanitize the array_index_nospec protection mechanism: Remove the
   overengineered array_index_nospec_mask_check() magic and allow
   const-qualified types as index to avoid temporary storage in a non-const
   local variable.

 - Make the microcode loader more robust by properly propagating error
   codes. Provide information about new feature bits after micro code was
   updated so administrators can act upon.

 - Optimizations of the entry ASM code which reduce code footprint and make
   the code simpler and faster.

 - Fix the {pmd,pud}_{set,clear}_flags() implementations to work properly
   on paravirt kernels by removing the address translation operations.

 - Revert the harmful vmexit_fill_RSB() optimization

 - Use IBRS around firmware calls

 - Teach objtool about retpolines and add annotations for indirect jumps
   and calls.

 - Explicitely disable jumplabel patching in __init code and handle
   patching failures proper instead of silently ignoring them.

 - Remove indirect paravirt calls for writing the speculation control MSR
   as these calls are obviously proving the same attack vector which is
   tried to be mitigated.

 - A few small fixes which address build issues with recent compiler and
   assembler versions.

Thanks,

	tglx

------------------&gt;
Borislav Petkov (3):
      x86/microcode: Propagate return value from updating functions
      x86/CPU: Add a microcode loader callback
      x86/CPU: Check CPU feature bits after microcode upgrade

Dan Williams (2):
      nospec: Kill array_index_nospec_mask_check()
      nospec: Include &lt;asm/barrier.h&gt; dependency

David Woodhouse (3):
      Revert &quot;x86/retpoline: Simplify vmexit_fill_RSB()&quot;
      x86/speculation: Use IBRS if available before calling into firmware
      x86/retpoline: Support retpoline builds with Clang

Dominik Brodowski (8):
      x86/entry: Reduce the code footprint of the &#39;idtentry&#39; macro
      x86/entry/64: Use &#39;xorl&#39; for faster register clearing
      x86/entry/64: Move PUSH_AND_CLEAR_REGS from interrupt macro to helper function
      x86/entry/64: Move ENTER_IRQ_STACK from interrupt macro to interrupt_entry
      x86/entry/64: Move the switch_to_thread_stack() call to interrupt_entry()
      x86/entry/64: Remove &#39;interrupt&#39; macro
      x86/entry/64: Move ASM_CLAC to interrupt_entry()
      x86/entry/64: Open-code switch_to_thread_stack()

Ingo Molnar (1):
      x86/speculation: Move firmware_restrict_branch_speculation_*() from C to CPP

Jan Beulich (5):
      x86/mm: Fix {pmd,pud}_{set,clear}_flags()
      x86/asm: Improve how GEN_*_SUFFIXED_RMWcc() specify clobbers
      x86/IO-APIC: Avoid warning in 32-bit builds
      x86/LDT: Avoid warning in 32-bit builds with older gcc
      x86-64/realmode: Add instruction suffix

Jann Horn (1):
      x86/mm: Remove stale comment about KMEMCHECK

Josh Poimboeuf (4):
      jump_label: Explicitly disable jump labels in __init code
      jump_label: Warn on failed jump_label patching attempt
      extable: Make init_kernel_text() global
      x86/entry/64: Simplify ENCODE_FRAME_POINTER

Paolo Bonzini (2):
      KVM/x86: Remove indirect MSR op calls from SPEC_CTRL
      KVM/VMX: Optimize vmx_vcpu_run() and svm_vcpu_run() by marking the RDMSR path as unlikely()

Peter Zijlstra (8):
      x86/speculation, objtool: Annotate indirect calls/jumps for objtool
      x86/paravirt, objtool: Annotate indirect calls
      x86/boot, objtool: Annotate indirect jump in secondary_startup_64()
      x86/mm/sme, objtool: Annotate indirect call in sme_encrypt_execute()
      objtool: Use existing global variables for options
      objtool: Add retpoline validation
      objtool: Add module specific retpoline rules
      objtool, retpolines: Integrate objtool with retpoline support more closely

Rasmus Villemoes (1):
      nospec: Allow index argument to have const-qualified type


 Makefile                              |   5 ++
 arch/x86/Kconfig                      |   1 +
 arch/x86/Makefile                     |   7 +-
 arch/x86/entry/calling.h              |  34 ++++----
 arch/x86/entry/entry_32.S             |   3 +-
 arch/x86/entry/entry_64.S             | 153 ++++++++++++++++++++--------------
 arch/x86/entry/entry_64_compat.S      |  71 +++++++++-------
 arch/x86/include/asm/apm.h            |   6 ++
 arch/x86/include/asm/asm-prototypes.h |   3 -
 arch/x86/include/asm/cpufeatures.h    |   1 +
 arch/x86/include/asm/efi.h            |  17 +++-
 arch/x86/include/asm/microcode.h      |   9 +-
 arch/x86/include/asm/mmu_context.h    |   1 +
 arch/x86/include/asm/nospec-branch.h  | 138 +++++++++++++++++++++++++-----
 arch/x86/include/asm/paravirt.h       |  17 +++-
 arch/x86/include/asm/paravirt_types.h |   5 +-
 arch/x86/include/asm/pgtable.h        |   8 +-
 arch/x86/include/asm/pgtable_types.h  |  10 +++
 arch/x86/include/asm/processor.h      |   1 +
 arch/x86/include/asm/refcount.h       |   4 +-
 arch/x86/include/asm/rmwcc.h          |  16 ++--
 arch/x86/kernel/apic/io_apic.c        |   2 +-
 arch/x86/kernel/cpu/bugs.c            |  12 ++-
 arch/x86/kernel/cpu/common.c          |  30 +++++++
 arch/x86/kernel/cpu/microcode/amd.c   |  10 +--
 arch/x86/kernel/cpu/microcode/core.c  |  39 +++++----
 arch/x86/kernel/cpu/microcode/intel.c |  10 +--
 arch/x86/kernel/head_64.S             |   2 +
 arch/x86/kernel/unwind_orc.c          |   3 +-
 arch/x86/kvm/svm.c                    |   9 +-
 arch/x86/kvm/vmx.c                    |   9 +-
 arch/x86/lib/Makefile                 |   1 -
 arch/x86/lib/retpoline.S              |  56 -------------
 arch/x86/mm/fault.c                   |   4 -
 arch/x86/mm/mem_encrypt_boot.S        |   2 +
 arch/x86/realmode/rm/trampoline_64.S  |   2 +-
 include/linux/compiler-clang.h        |   5 ++
 include/linux/compiler-gcc.h          |   4 +
 include/linux/init.h                  |   8 +-
 include/linux/jump_label.h            |   3 +
 include/linux/kernel.h                |   1 +
 include/linux/nospec.h                |  26 +-----
 init/main.c                           |   2 +
 kernel/extable.c                      |   2 +-
 kernel/jump_label.c                   |  27 ++++--
 scripts/Makefile.build                |   8 ++
 tools/objtool/builtin-check.c         |   6 +-
 tools/objtool/builtin-orc.c           |   6 +-
 tools/objtool/builtin.h               |   5 ++
 tools/objtool/check.c                 | 100 +++++++++++++++++++++-
 tools/objtool/check.h                 |   3 +-
 51 files changed, 604 insertions(+), 303 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=77">Linus Torvalds</a> - Feb. 26, 2018, 8:07 p.m.</div>
<pre class="content">
On Mon, Feb 26, 2018 at 5:25 AM, Thomas Gleixner &lt;tglx@linutronix.de&gt; wrote:
<span class="quote">&gt;</span>
<span class="quote">&gt;  - Teach objtool about retpolines and add annotations for indirect jumps</span>
<span class="quote">&gt;    and calls.</span>

So now we have that

  drivers/watchdog/.tmp_hpwdt.o: warning: objtool: .text+0x24:
indirect call found in RETPOLINE build

upstream.

Is the hpwdt de-crapification patch that was quoted in the discussion
about this monster lined up somewhere?


               Linus
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=95791">Josh Poimboeuf</a> - Feb. 27, 2018, 5:53 p.m.</div>
<pre class="content">
On Mon, Feb 26, 2018 at 12:07:32PM -0800, Linus Torvalds wrote:
<span class="quote">&gt; On Mon, Feb 26, 2018 at 5:25 AM, Thomas Gleixner &lt;tglx@linutronix.de&gt; wrote:</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt;  - Teach objtool about retpolines and add annotations for indirect jumps</span>
<span class="quote">&gt; &gt;    and calls.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So now we have that</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;   drivers/watchdog/.tmp_hpwdt.o: warning: objtool: .text+0x24:</span>
<span class="quote">&gt; indirect call found in RETPOLINE build</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; upstream.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Is the hpwdt de-crapification patch that was quoted in the discussion</span>
<span class="quote">&gt; about this monster lined up somewhere?</span>

I believe that patch is still under review:

  https://lkml.kernel.org/r/20180226032227.14615-3-jerry.hoemann@hpe.com
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 79ad2bfa24b6..3dfce4d2f25d 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -489,6 +489,11 @@</span> <span class="p_context"> KBUILD_CFLAGS += $(CLANG_TARGET) $(CLANG_GCC_TC)</span>
 KBUILD_AFLAGS += $(CLANG_TARGET) $(CLANG_GCC_TC)
 endif
 
<span class="p_add">+RETPOLINE_CFLAGS_GCC := -mindirect-branch=thunk-extern -mindirect-branch-register</span>
<span class="p_add">+RETPOLINE_CFLAGS_CLANG := -mretpoline-external-thunk</span>
<span class="p_add">+RETPOLINE_CFLAGS := $(call cc-option,$(RETPOLINE_CFLAGS_GCC),$(call cc-option,$(RETPOLINE_CFLAGS_CLANG)))</span>
<span class="p_add">+export RETPOLINE_CFLAGS</span>
<span class="p_add">+</span>
 ifeq ($(config-targets),1)
 # ===========================================================================
 # *config targets only - make sure prerequisites are updated, and descend
<span class="p_header">diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig</span>
<span class="p_header">index 63bf349b2b24..c1aed6c0e413 100644</span>
<span class="p_header">--- a/arch/x86/Kconfig</span>
<span class="p_header">+++ b/arch/x86/Kconfig</span>
<span class="p_chunk">@@ -436,6 +436,7 @@</span> <span class="p_context"> config GOLDFISH</span>
 config RETPOLINE
 	bool &quot;Avoid speculative indirect branches in kernel&quot;
 	default y
<span class="p_add">+	select STACK_VALIDATION if HAVE_STACK_VALIDATION</span>
 	help
 	  Compile kernel with the retpoline compiler options to guard against
 	  kernel-to-user data leaks by avoiding speculative indirect
<span class="p_header">diff --git a/arch/x86/Makefile b/arch/x86/Makefile</span>
<span class="p_header">index fad55160dcb9..498c1b812300 100644</span>
<span class="p_header">--- a/arch/x86/Makefile</span>
<span class="p_header">+++ b/arch/x86/Makefile</span>
<span class="p_chunk">@@ -232,10 +232,9 @@</span> <span class="p_context"> KBUILD_CFLAGS += -fno-asynchronous-unwind-tables</span>
 
 # Avoid indirect branches in kernel to deal with Spectre
 ifdef CONFIG_RETPOLINE
<span class="p_del">-    RETPOLINE_CFLAGS += $(call cc-option,-mindirect-branch=thunk-extern -mindirect-branch-register)</span>
<span class="p_del">-    ifneq ($(RETPOLINE_CFLAGS),)</span>
<span class="p_del">-        KBUILD_CFLAGS += $(RETPOLINE_CFLAGS) -DRETPOLINE</span>
<span class="p_del">-    endif</span>
<span class="p_add">+ifneq ($(RETPOLINE_CFLAGS),)</span>
<span class="p_add">+  KBUILD_CFLAGS += $(RETPOLINE_CFLAGS) -DRETPOLINE</span>
<span class="p_add">+endif</span>
 endif
 
 archscripts: scripts_basic
<span class="p_header">diff --git a/arch/x86/entry/calling.h b/arch/x86/entry/calling.h</span>
<span class="p_header">index dce7092ab24a..be63330c5511 100644</span>
<span class="p_header">--- a/arch/x86/entry/calling.h</span>
<span class="p_header">+++ b/arch/x86/entry/calling.h</span>
<span class="p_chunk">@@ -97,7 +97,7 @@</span> <span class="p_context"> For 32-bit we have the following conventions - kernel is built with</span>
 
 #define SIZEOF_PTREGS	21*8
 
<span class="p_del">-.macro PUSH_AND_CLEAR_REGS rdx=%rdx rax=%rax</span>
<span class="p_add">+.macro PUSH_AND_CLEAR_REGS rdx=%rdx rax=%rax save_ret=0</span>
 	/*
 	 * Push registers and sanitize registers of values that a
 	 * speculation attack might otherwise want to exploit. The
<span class="p_chunk">@@ -105,32 +105,41 @@</span> <span class="p_context"> For 32-bit we have the following conventions - kernel is built with</span>
 	 * could be put to use in a speculative execution gadget.
 	 * Interleave XOR with PUSH for better uop scheduling:
 	 */
<span class="p_add">+	.if \save_ret</span>
<span class="p_add">+	pushq	%rsi		/* pt_regs-&gt;si */</span>
<span class="p_add">+	movq	8(%rsp), %rsi	/* temporarily store the return address in %rsi */</span>
<span class="p_add">+	movq	%rdi, 8(%rsp)	/* pt_regs-&gt;di (overwriting original return address) */</span>
<span class="p_add">+	.else</span>
 	pushq   %rdi		/* pt_regs-&gt;di */
 	pushq   %rsi		/* pt_regs-&gt;si */
<span class="p_add">+	.endif</span>
 	pushq	\rdx		/* pt_regs-&gt;dx */
 	pushq   %rcx		/* pt_regs-&gt;cx */
 	pushq   \rax		/* pt_regs-&gt;ax */
 	pushq   %r8		/* pt_regs-&gt;r8 */
<span class="p_del">-	xorq    %r8, %r8	/* nospec   r8 */</span>
<span class="p_add">+	xorl	%r8d, %r8d	/* nospec   r8 */</span>
 	pushq   %r9		/* pt_regs-&gt;r9 */
<span class="p_del">-	xorq    %r9, %r9	/* nospec   r9 */</span>
<span class="p_add">+	xorl	%r9d, %r9d	/* nospec   r9 */</span>
 	pushq   %r10		/* pt_regs-&gt;r10 */
<span class="p_del">-	xorq    %r10, %r10	/* nospec   r10 */</span>
<span class="p_add">+	xorl	%r10d, %r10d	/* nospec   r10 */</span>
 	pushq   %r11		/* pt_regs-&gt;r11 */
<span class="p_del">-	xorq    %r11, %r11	/* nospec   r11*/</span>
<span class="p_add">+	xorl	%r11d, %r11d	/* nospec   r11*/</span>
 	pushq	%rbx		/* pt_regs-&gt;rbx */
 	xorl    %ebx, %ebx	/* nospec   rbx*/
 	pushq	%rbp		/* pt_regs-&gt;rbp */
 	xorl    %ebp, %ebp	/* nospec   rbp*/
 	pushq	%r12		/* pt_regs-&gt;r12 */
<span class="p_del">-	xorq    %r12, %r12	/* nospec   r12*/</span>
<span class="p_add">+	xorl	%r12d, %r12d	/* nospec   r12*/</span>
 	pushq	%r13		/* pt_regs-&gt;r13 */
<span class="p_del">-	xorq    %r13, %r13	/* nospec   r13*/</span>
<span class="p_add">+	xorl	%r13d, %r13d	/* nospec   r13*/</span>
 	pushq	%r14		/* pt_regs-&gt;r14 */
<span class="p_del">-	xorq    %r14, %r14	/* nospec   r14*/</span>
<span class="p_add">+	xorl	%r14d, %r14d	/* nospec   r14*/</span>
 	pushq	%r15		/* pt_regs-&gt;r15 */
<span class="p_del">-	xorq    %r15, %r15	/* nospec   r15*/</span>
<span class="p_add">+	xorl	%r15d, %r15d	/* nospec   r15*/</span>
 	UNWIND_HINT_REGS
<span class="p_add">+	.if \save_ret</span>
<span class="p_add">+	pushq	%rsi		/* return address on top of stack */</span>
<span class="p_add">+	.endif</span>
 .endm
 
 .macro POP_REGS pop_rdi=1 skip_r11rcx=0
<span class="p_chunk">@@ -172,12 +181,7 @@</span> <span class="p_context"> For 32-bit we have the following conventions - kernel is built with</span>
  */
 .macro ENCODE_FRAME_POINTER ptregs_offset=0
 #ifdef CONFIG_FRAME_POINTER
<span class="p_del">-	.if \ptregs_offset</span>
<span class="p_del">-		leaq \ptregs_offset(%rsp), %rbp</span>
<span class="p_del">-	.else</span>
<span class="p_del">-		mov %rsp, %rbp</span>
<span class="p_del">-	.endif</span>
<span class="p_del">-	orq	$0x1, %rbp</span>
<span class="p_add">+	leaq 1+\ptregs_offset(%rsp), %rbp</span>
 #endif
 .endm
 
<span class="p_header">diff --git a/arch/x86/entry/entry_32.S b/arch/x86/entry/entry_32.S</span>
<span class="p_header">index 16c2c022540d..6ad064c8cf35 100644</span>
<span class="p_header">--- a/arch/x86/entry/entry_32.S</span>
<span class="p_header">+++ b/arch/x86/entry/entry_32.S</span>
<span class="p_chunk">@@ -252,8 +252,7 @@</span> <span class="p_context"> ENTRY(__switch_to_asm)</span>
 	 * exist, overwrite the RSB with entries which capture
 	 * speculative execution to prevent attack.
 	 */
<span class="p_del">-	/* Clobbers %ebx */</span>
<span class="p_del">-	FILL_RETURN_BUFFER RSB_CLEAR_LOOPS, X86_FEATURE_RSB_CTXSW</span>
<span class="p_add">+	FILL_RETURN_BUFFER %ebx, RSB_CLEAR_LOOPS, X86_FEATURE_RSB_CTXSW</span>
 #endif
 
 	/* restore callee-saved registers */
<span class="p_header">diff --git a/arch/x86/entry/entry_64.S b/arch/x86/entry/entry_64.S</span>
<span class="p_header">index 8971bd64d515..d5c7f18f79ac 100644</span>
<span class="p_header">--- a/arch/x86/entry/entry_64.S</span>
<span class="p_header">+++ b/arch/x86/entry/entry_64.S</span>
<span class="p_chunk">@@ -364,8 +364,7 @@</span> <span class="p_context"> ENTRY(__switch_to_asm)</span>
 	 * exist, overwrite the RSB with entries which capture
 	 * speculative execution to prevent attack.
 	 */
<span class="p_del">-	/* Clobbers %rbx */</span>
<span class="p_del">-	FILL_RETURN_BUFFER RSB_CLEAR_LOOPS, X86_FEATURE_RSB_CTXSW</span>
<span class="p_add">+	FILL_RETURN_BUFFER %r12, RSB_CLEAR_LOOPS, X86_FEATURE_RSB_CTXSW</span>
 #endif
 
 	/* restore callee-saved registers */
<span class="p_chunk">@@ -449,9 +448,19 @@</span> <span class="p_context"> END(irq_entries_start)</span>
  *
  * The invariant is that, if irq_count != -1, then the IRQ stack is in use.
  */
<span class="p_del">-.macro ENTER_IRQ_STACK regs=1 old_rsp</span>
<span class="p_add">+.macro ENTER_IRQ_STACK regs=1 old_rsp save_ret=0</span>
 	DEBUG_ENTRY_ASSERT_IRQS_OFF
<span class="p_add">+</span>
<span class="p_add">+	.if \save_ret</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If save_ret is set, the original stack contains one additional</span>
<span class="p_add">+	 * entry -- the return address. Therefore, move the address one</span>
<span class="p_add">+	 * entry below %rsp to \old_rsp.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	leaq	8(%rsp), \old_rsp</span>
<span class="p_add">+	.else</span>
 	movq	%rsp, \old_rsp
<span class="p_add">+	.endif</span>
 
 	.if \regs
 	UNWIND_HINT_REGS base=\old_rsp
<span class="p_chunk">@@ -497,6 +506,15 @@</span> <span class="p_context"> END(irq_entries_start)</span>
 	.if \regs
 	UNWIND_HINT_REGS indirect=1
 	.endif
<span class="p_add">+</span>
<span class="p_add">+	.if \save_ret</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Push the return address to the stack. This return address can</span>
<span class="p_add">+	 * be found at the &quot;real&quot; original RSP, which was offset by 8 at</span>
<span class="p_add">+	 * the beginning of this macro.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pushq	-8(\old_rsp)</span>
<span class="p_add">+	.endif</span>
 .endm
 
 /*
<span class="p_chunk">@@ -520,27 +538,65 @@</span> <span class="p_context"> END(irq_entries_start)</span>
 .endm
 
 /*
<span class="p_del">- * Interrupt entry/exit.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Interrupt entry points save only callee clobbered registers in fast path.</span>
<span class="p_add">+ * Interrupt entry helper function.</span>
  *
<span class="p_del">- * Entry runs with interrupts off.</span>
<span class="p_add">+ * Entry runs with interrupts off. Stack layout at entry:</span>
<span class="p_add">+ * +----------------------------------------------------+</span>
<span class="p_add">+ * | regs-&gt;ss						|</span>
<span class="p_add">+ * | regs-&gt;rsp						|</span>
<span class="p_add">+ * | regs-&gt;eflags					|</span>
<span class="p_add">+ * | regs-&gt;cs						|</span>
<span class="p_add">+ * | regs-&gt;ip						|</span>
<span class="p_add">+ * +----------------------------------------------------+</span>
<span class="p_add">+ * | regs-&gt;orig_ax = ~(interrupt number)		|</span>
<span class="p_add">+ * +----------------------------------------------------+</span>
<span class="p_add">+ * | return address					|</span>
<span class="p_add">+ * +----------------------------------------------------+</span>
  */
<span class="p_del">-</span>
<span class="p_del">-/* 0(%rsp): ~(interrupt number) */</span>
<span class="p_del">-	.macro interrupt func</span>
<span class="p_add">+ENTRY(interrupt_entry)</span>
<span class="p_add">+	UNWIND_HINT_FUNC</span>
<span class="p_add">+	ASM_CLAC</span>
 	cld
 
<span class="p_del">-	testb	$3, CS-ORIG_RAX(%rsp)</span>
<span class="p_add">+	testb	$3, CS-ORIG_RAX+8(%rsp)</span>
 	jz	1f
 	SWAPGS
<span class="p_del">-	call	switch_to_thread_stack</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Switch to the thread stack. The IRET frame and orig_ax are</span>
<span class="p_add">+	 * on the stack, as well as the return address. RDI..R12 are</span>
<span class="p_add">+	 * not (yet) on the stack and space has not (yet) been</span>
<span class="p_add">+	 * allocated for them.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pushq	%rdi</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Need to switch before accessing the thread stack. */</span>
<span class="p_add">+	SWITCH_TO_KERNEL_CR3 scratch_reg=%rdi</span>
<span class="p_add">+	movq	%rsp, %rdi</span>
<span class="p_add">+	movq	PER_CPU_VAR(cpu_current_top_of_stack), %rsp</span>
<span class="p_add">+</span>
<span class="p_add">+	 /*</span>
<span class="p_add">+	  * We have RDI, return address, and orig_ax on the stack on</span>
<span class="p_add">+	  * top of the IRET frame. That means offset=24</span>
<span class="p_add">+	  */</span>
<span class="p_add">+	UNWIND_HINT_IRET_REGS base=%rdi offset=24</span>
<span class="p_add">+</span>
<span class="p_add">+	pushq	7*8(%rdi)		/* regs-&gt;ss */</span>
<span class="p_add">+	pushq	6*8(%rdi)		/* regs-&gt;rsp */</span>
<span class="p_add">+	pushq	5*8(%rdi)		/* regs-&gt;eflags */</span>
<span class="p_add">+	pushq	4*8(%rdi)		/* regs-&gt;cs */</span>
<span class="p_add">+	pushq	3*8(%rdi)		/* regs-&gt;ip */</span>
<span class="p_add">+	pushq	2*8(%rdi)		/* regs-&gt;orig_ax */</span>
<span class="p_add">+	pushq	8(%rdi)			/* return address */</span>
<span class="p_add">+	UNWIND_HINT_FUNC</span>
<span class="p_add">+</span>
<span class="p_add">+	movq	(%rdi), %rdi</span>
 1:
 
<span class="p_del">-	PUSH_AND_CLEAR_REGS</span>
<span class="p_del">-	ENCODE_FRAME_POINTER</span>
<span class="p_add">+	PUSH_AND_CLEAR_REGS save_ret=1</span>
<span class="p_add">+	ENCODE_FRAME_POINTER 8</span>
 
<span class="p_del">-	testb	$3, CS(%rsp)</span>
<span class="p_add">+	testb	$3, CS+8(%rsp)</span>
 	jz	1f
 
 	/*
<span class="p_chunk">@@ -548,7 +604,7 @@</span> <span class="p_context"> END(irq_entries_start)</span>
 	 *
 	 * We need to tell lockdep that IRQs are off.  We can&#39;t do this until
 	 * we fix gsbase, and we should do it before enter_from_user_mode
<span class="p_del">-	 * (which can take locks).  Since TRACE_IRQS_OFF idempotent,</span>
<span class="p_add">+	 * (which can take locks).  Since TRACE_IRQS_OFF is idempotent,</span>
 	 * the simplest way to handle it is to just call it twice if
 	 * we enter from user mode.  There&#39;s no reason to optimize this since
 	 * TRACE_IRQS_OFF is a no-op if lockdep is off.
<span class="p_chunk">@@ -558,12 +614,15 @@</span> <span class="p_context"> END(irq_entries_start)</span>
 	CALL_enter_from_user_mode
 
 1:
<span class="p_del">-	ENTER_IRQ_STACK old_rsp=%rdi</span>
<span class="p_add">+	ENTER_IRQ_STACK old_rsp=%rdi save_ret=1</span>
 	/* We entered an interrupt context - irqs are off: */
 	TRACE_IRQS_OFF
 
<span class="p_del">-	call	\func	/* rdi points to pt_regs */</span>
<span class="p_del">-	.endm</span>
<span class="p_add">+	ret</span>
<span class="p_add">+END(interrupt_entry)</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+/* Interrupt entry/exit. */</span>
 
 	/*
 	 * The interrupt stubs push (~vector+0x80) onto the stack and
<span class="p_chunk">@@ -571,9 +630,10 @@</span> <span class="p_context"> END(irq_entries_start)</span>
 	 */
 	.p2align CONFIG_X86_L1_CACHE_SHIFT
 common_interrupt:
<span class="p_del">-	ASM_CLAC</span>
 	addq	$-0x80, (%rsp)			/* Adjust vector to [-256, -1] range */
<span class="p_del">-	interrupt do_IRQ</span>
<span class="p_add">+	call	interrupt_entry</span>
<span class="p_add">+	UNWIND_HINT_REGS indirect=1</span>
<span class="p_add">+	call	do_IRQ	/* rdi points to pt_regs */</span>
 	/* 0(%rsp): old RSP */
 ret_from_intr:
 	DISABLE_INTERRUPTS(CLBR_ANY)
<span class="p_chunk">@@ -766,10 +826,11 @@</span> <span class="p_context"> END(common_interrupt)</span>
 .macro apicinterrupt3 num sym do_sym
 ENTRY(\sym)
 	UNWIND_HINT_IRET_REGS
<span class="p_del">-	ASM_CLAC</span>
 	pushq	$~(\num)
 .Lcommon_\sym:
<span class="p_del">-	interrupt \do_sym</span>
<span class="p_add">+	call	interrupt_entry</span>
<span class="p_add">+	UNWIND_HINT_REGS indirect=1</span>
<span class="p_add">+	call	\do_sym	/* rdi points to pt_regs */</span>
 	jmp	ret_from_intr
 END(\sym)
 .endm
<span class="p_chunk">@@ -832,34 +893,6 @@</span> <span class="p_context"> apicinterrupt IRQ_WORK_VECTOR			irq_work_interrupt		smp_irq_work_interrupt</span>
  */
 #define CPU_TSS_IST(x) PER_CPU_VAR(cpu_tss_rw) + (TSS_ist + ((x) - 1) * 8)
 
<span class="p_del">-/*</span>
<span class="p_del">- * Switch to the thread stack.  This is called with the IRET frame and</span>
<span class="p_del">- * orig_ax on the stack.  (That is, RDI..R12 are not on the stack and</span>
<span class="p_del">- * space has not been allocated for them.)</span>
<span class="p_del">- */</span>
<span class="p_del">-ENTRY(switch_to_thread_stack)</span>
<span class="p_del">-	UNWIND_HINT_FUNC</span>
<span class="p_del">-</span>
<span class="p_del">-	pushq	%rdi</span>
<span class="p_del">-	/* Need to switch before accessing the thread stack. */</span>
<span class="p_del">-	SWITCH_TO_KERNEL_CR3 scratch_reg=%rdi</span>
<span class="p_del">-	movq	%rsp, %rdi</span>
<span class="p_del">-	movq	PER_CPU_VAR(cpu_current_top_of_stack), %rsp</span>
<span class="p_del">-	UNWIND_HINT sp_offset=16 sp_reg=ORC_REG_DI</span>
<span class="p_del">-</span>
<span class="p_del">-	pushq	7*8(%rdi)		/* regs-&gt;ss */</span>
<span class="p_del">-	pushq	6*8(%rdi)		/* regs-&gt;rsp */</span>
<span class="p_del">-	pushq	5*8(%rdi)		/* regs-&gt;eflags */</span>
<span class="p_del">-	pushq	4*8(%rdi)		/* regs-&gt;cs */</span>
<span class="p_del">-	pushq	3*8(%rdi)		/* regs-&gt;ip */</span>
<span class="p_del">-	pushq	2*8(%rdi)		/* regs-&gt;orig_ax */</span>
<span class="p_del">-	pushq	8(%rdi)			/* return address */</span>
<span class="p_del">-	UNWIND_HINT_FUNC</span>
<span class="p_del">-</span>
<span class="p_del">-	movq	(%rdi), %rdi</span>
<span class="p_del">-	ret</span>
<span class="p_del">-END(switch_to_thread_stack)</span>
<span class="p_del">-</span>
 .macro idtentry sym do_sym has_error_code:req paranoid=0 shift_ist=-1
 ENTRY(\sym)
 	UNWIND_HINT_IRET_REGS offset=\has_error_code*8
<span class="p_chunk">@@ -875,12 +908,8 @@</span> <span class="p_context"> ENTRY(\sym)</span>
 	pushq	$-1				/* ORIG_RAX: no syscall to restart */
 	.endif
 
<span class="p_del">-	/* Save all registers in pt_regs */</span>
<span class="p_del">-	PUSH_AND_CLEAR_REGS</span>
<span class="p_del">-	ENCODE_FRAME_POINTER</span>
<span class="p_del">-</span>
 	.if \paranoid &lt; 2
<span class="p_del">-	testb	$3, CS(%rsp)			/* If coming from userspace, switch stacks */</span>
<span class="p_add">+	testb	$3, CS-ORIG_RAX(%rsp)		/* If coming from userspace, switch stacks */</span>
 	jnz	.Lfrom_usermode_switch_stack_\@
 	.endif
 
<span class="p_chunk">@@ -1130,13 +1159,15 @@</span> <span class="p_context"> idtentry machine_check		do_mce			has_error_code=0	paranoid=1</span>
 #endif
 
 /*
<span class="p_del">- * Switch gs if needed.</span>
<span class="p_add">+ * Save all registers in pt_regs, and switch gs if needed.</span>
  * Use slow, but surefire &quot;are we in kernel?&quot; check.
  * Return: ebx=0: need swapgs on exit, ebx=1: otherwise
  */
 ENTRY(paranoid_entry)
 	UNWIND_HINT_FUNC
 	cld
<span class="p_add">+	PUSH_AND_CLEAR_REGS save_ret=1</span>
<span class="p_add">+	ENCODE_FRAME_POINTER 8</span>
 	movl	$1, %ebx
 	movl	$MSR_GS_BASE, %ecx
 	rdmsr
<span class="p_chunk">@@ -1181,12 +1212,14 @@</span> <span class="p_context"> ENTRY(paranoid_exit)</span>
 END(paranoid_exit)
 
 /*
<span class="p_del">- * Switch gs if needed.</span>
<span class="p_add">+ * Save all registers in pt_regs, and switch GS if needed.</span>
  * Return: EBX=0: came from user mode; EBX=1: otherwise
  */
 ENTRY(error_entry)
<span class="p_del">-	UNWIND_HINT_REGS offset=8</span>
<span class="p_add">+	UNWIND_HINT_FUNC</span>
 	cld
<span class="p_add">+	PUSH_AND_CLEAR_REGS save_ret=1</span>
<span class="p_add">+	ENCODE_FRAME_POINTER 8</span>
 	testb	$3, CS+8(%rsp)
 	jz	.Lerror_kernelspace
 
<span class="p_chunk">@@ -1577,8 +1610,6 @@</span> <span class="p_context"> end_repeat_nmi:</span>
 	 * frame to point back to repeat_nmi.
 	 */
 	pushq	$-1				/* ORIG_RAX: no syscall to restart */
<span class="p_del">-	PUSH_AND_CLEAR_REGS</span>
<span class="p_del">-	ENCODE_FRAME_POINTER</span>
 
 	/*
 	 * Use paranoid_entry to handle SWAPGS, but no need to use paranoid_exit
<span class="p_header">diff --git a/arch/x86/entry/entry_64_compat.S b/arch/x86/entry/entry_64_compat.S</span>
<span class="p_header">index fd65e016e413..e811dd9c5e99 100644</span>
<span class="p_header">--- a/arch/x86/entry/entry_64_compat.S</span>
<span class="p_header">+++ b/arch/x86/entry/entry_64_compat.S</span>
<span class="p_chunk">@@ -85,25 +85,25 @@</span> <span class="p_context"> ENTRY(entry_SYSENTER_compat)</span>
 	pushq	%rcx			/* pt_regs-&gt;cx */
 	pushq	$-ENOSYS		/* pt_regs-&gt;ax */
 	pushq   $0			/* pt_regs-&gt;r8  = 0 */
<span class="p_del">-	xorq	%r8, %r8		/* nospec   r8 */</span>
<span class="p_add">+	xorl	%r8d, %r8d		/* nospec   r8 */</span>
 	pushq   $0			/* pt_regs-&gt;r9  = 0 */
<span class="p_del">-	xorq	%r9, %r9		/* nospec   r9 */</span>
<span class="p_add">+	xorl	%r9d, %r9d		/* nospec   r9 */</span>
 	pushq   $0			/* pt_regs-&gt;r10 = 0 */
<span class="p_del">-	xorq	%r10, %r10		/* nospec   r10 */</span>
<span class="p_add">+	xorl	%r10d, %r10d		/* nospec   r10 */</span>
 	pushq   $0			/* pt_regs-&gt;r11 = 0 */
<span class="p_del">-	xorq	%r11, %r11		/* nospec   r11 */</span>
<span class="p_add">+	xorl	%r11d, %r11d		/* nospec   r11 */</span>
 	pushq   %rbx                    /* pt_regs-&gt;rbx */
 	xorl	%ebx, %ebx		/* nospec   rbx */
 	pushq   %rbp                    /* pt_regs-&gt;rbp (will be overwritten) */
 	xorl	%ebp, %ebp		/* nospec   rbp */
 	pushq   $0			/* pt_regs-&gt;r12 = 0 */
<span class="p_del">-	xorq	%r12, %r12		/* nospec   r12 */</span>
<span class="p_add">+	xorl	%r12d, %r12d		/* nospec   r12 */</span>
 	pushq   $0			/* pt_regs-&gt;r13 = 0 */
<span class="p_del">-	xorq	%r13, %r13		/* nospec   r13 */</span>
<span class="p_add">+	xorl	%r13d, %r13d		/* nospec   r13 */</span>
 	pushq   $0			/* pt_regs-&gt;r14 = 0 */
<span class="p_del">-	xorq	%r14, %r14		/* nospec   r14 */</span>
<span class="p_add">+	xorl	%r14d, %r14d		/* nospec   r14 */</span>
 	pushq   $0			/* pt_regs-&gt;r15 = 0 */
<span class="p_del">-	xorq	%r15, %r15		/* nospec   r15 */</span>
<span class="p_add">+	xorl	%r15d, %r15d		/* nospec   r15 */</span>
 	cld
 
 	/*
<span class="p_chunk">@@ -224,25 +224,25 @@</span> <span class="p_context"> GLOBAL(entry_SYSCALL_compat_after_hwframe)</span>
 	pushq	%rbp			/* pt_regs-&gt;cx (stashed in bp) */
 	pushq	$-ENOSYS		/* pt_regs-&gt;ax */
 	pushq   $0			/* pt_regs-&gt;r8  = 0 */
<span class="p_del">-	xorq	%r8, %r8		/* nospec   r8 */</span>
<span class="p_add">+	xorl	%r8d, %r8d		/* nospec   r8 */</span>
 	pushq   $0			/* pt_regs-&gt;r9  = 0 */
<span class="p_del">-	xorq	%r9, %r9		/* nospec   r9 */</span>
<span class="p_add">+	xorl	%r9d, %r9d		/* nospec   r9 */</span>
 	pushq   $0			/* pt_regs-&gt;r10 = 0 */
<span class="p_del">-	xorq	%r10, %r10		/* nospec   r10 */</span>
<span class="p_add">+	xorl	%r10d, %r10d		/* nospec   r10 */</span>
 	pushq   $0			/* pt_regs-&gt;r11 = 0 */
<span class="p_del">-	xorq	%r11, %r11		/* nospec   r11 */</span>
<span class="p_add">+	xorl	%r11d, %r11d		/* nospec   r11 */</span>
 	pushq   %rbx                    /* pt_regs-&gt;rbx */
 	xorl	%ebx, %ebx		/* nospec   rbx */
 	pushq   %rbp                    /* pt_regs-&gt;rbp (will be overwritten) */
 	xorl	%ebp, %ebp		/* nospec   rbp */
 	pushq   $0			/* pt_regs-&gt;r12 = 0 */
<span class="p_del">-	xorq	%r12, %r12		/* nospec   r12 */</span>
<span class="p_add">+	xorl	%r12d, %r12d		/* nospec   r12 */</span>
 	pushq   $0			/* pt_regs-&gt;r13 = 0 */
<span class="p_del">-	xorq	%r13, %r13		/* nospec   r13 */</span>
<span class="p_add">+	xorl	%r13d, %r13d		/* nospec   r13 */</span>
 	pushq   $0			/* pt_regs-&gt;r14 = 0 */
<span class="p_del">-	xorq	%r14, %r14		/* nospec   r14 */</span>
<span class="p_add">+	xorl	%r14d, %r14d		/* nospec   r14 */</span>
 	pushq   $0			/* pt_regs-&gt;r15 = 0 */
<span class="p_del">-	xorq	%r15, %r15		/* nospec   r15 */</span>
<span class="p_add">+	xorl	%r15d, %r15d		/* nospec   r15 */</span>
 
 	/*
 	 * User mode is traced as though IRQs are on, and SYSENTER
<span class="p_chunk">@@ -298,9 +298,9 @@</span> <span class="p_context"> sysret32_from_system_call:</span>
 	 */
 	SWITCH_TO_USER_CR3_NOSTACK scratch_reg=%r8 scratch_reg2=%r9
 
<span class="p_del">-	xorq	%r8, %r8</span>
<span class="p_del">-	xorq	%r9, %r9</span>
<span class="p_del">-	xorq	%r10, %r10</span>
<span class="p_add">+	xorl	%r8d, %r8d</span>
<span class="p_add">+	xorl	%r9d, %r9d</span>
<span class="p_add">+	xorl	%r10d, %r10d</span>
 	swapgs
 	sysretl
 END(entry_SYSCALL_compat)
<span class="p_chunk">@@ -347,10 +347,23 @@</span> <span class="p_context"> ENTRY(entry_INT80_compat)</span>
 	 */
 	movl	%eax, %eax
 
<span class="p_add">+	/* switch to thread stack expects orig_ax and rdi to be pushed */</span>
 	pushq	%rax			/* pt_regs-&gt;orig_ax */
<span class="p_add">+	pushq	%rdi			/* pt_regs-&gt;di */</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Need to switch before accessing the thread stack. */</span>
<span class="p_add">+	SWITCH_TO_KERNEL_CR3 scratch_reg=%rdi</span>
<span class="p_add">+	movq	%rsp, %rdi</span>
<span class="p_add">+	movq	PER_CPU_VAR(cpu_current_top_of_stack), %rsp</span>
<span class="p_add">+</span>
<span class="p_add">+	pushq	6*8(%rdi)		/* regs-&gt;ss */</span>
<span class="p_add">+	pushq	5*8(%rdi)		/* regs-&gt;rsp */</span>
<span class="p_add">+	pushq	4*8(%rdi)		/* regs-&gt;eflags */</span>
<span class="p_add">+	pushq	3*8(%rdi)		/* regs-&gt;cs */</span>
<span class="p_add">+	pushq	2*8(%rdi)		/* regs-&gt;ip */</span>
<span class="p_add">+	pushq	1*8(%rdi)		/* regs-&gt;orig_ax */</span>
 
<span class="p_del">-	/* switch to thread stack expects orig_ax to be pushed */</span>
<span class="p_del">-	call	switch_to_thread_stack</span>
<span class="p_add">+	movq	(%rdi), %rdi		/* restore %rdi */</span>
 
 	pushq	%rdi			/* pt_regs-&gt;di */
 	pushq	%rsi			/* pt_regs-&gt;si */
<span class="p_chunk">@@ -358,25 +371,25 @@</span> <span class="p_context"> ENTRY(entry_INT80_compat)</span>
 	pushq	%rcx			/* pt_regs-&gt;cx */
 	pushq	$-ENOSYS		/* pt_regs-&gt;ax */
 	pushq   $0			/* pt_regs-&gt;r8  = 0 */
<span class="p_del">-	xorq	%r8, %r8		/* nospec   r8 */</span>
<span class="p_add">+	xorl	%r8d, %r8d		/* nospec   r8 */</span>
 	pushq   $0			/* pt_regs-&gt;r9  = 0 */
<span class="p_del">-	xorq	%r9, %r9		/* nospec   r9 */</span>
<span class="p_add">+	xorl	%r9d, %r9d		/* nospec   r9 */</span>
 	pushq   $0			/* pt_regs-&gt;r10 = 0 */
<span class="p_del">-	xorq	%r10, %r10		/* nospec   r10 */</span>
<span class="p_add">+	xorl	%r10d, %r10d		/* nospec   r10 */</span>
 	pushq   $0			/* pt_regs-&gt;r11 = 0 */
<span class="p_del">-	xorq	%r11, %r11		/* nospec   r11 */</span>
<span class="p_add">+	xorl	%r11d, %r11d		/* nospec   r11 */</span>
 	pushq   %rbx                    /* pt_regs-&gt;rbx */
 	xorl	%ebx, %ebx		/* nospec   rbx */
 	pushq   %rbp                    /* pt_regs-&gt;rbp */
 	xorl	%ebp, %ebp		/* nospec   rbp */
 	pushq   %r12                    /* pt_regs-&gt;r12 */
<span class="p_del">-	xorq	%r12, %r12		/* nospec   r12 */</span>
<span class="p_add">+	xorl	%r12d, %r12d		/* nospec   r12 */</span>
 	pushq   %r13                    /* pt_regs-&gt;r13 */
<span class="p_del">-	xorq	%r13, %r13		/* nospec   r13 */</span>
<span class="p_add">+	xorl	%r13d, %r13d		/* nospec   r13 */</span>
 	pushq   %r14                    /* pt_regs-&gt;r14 */
<span class="p_del">-	xorq	%r14, %r14		/* nospec   r14 */</span>
<span class="p_add">+	xorl	%r14d, %r14d		/* nospec   r14 */</span>
 	pushq   %r15                    /* pt_regs-&gt;r15 */
<span class="p_del">-	xorq	%r15, %r15		/* nospec   r15 */</span>
<span class="p_add">+	xorl	%r15d, %r15d		/* nospec   r15 */</span>
 	cld
 
 	/*
<span class="p_header">diff --git a/arch/x86/include/asm/apm.h b/arch/x86/include/asm/apm.h</span>
<span class="p_header">index 4d4015ddcf26..c356098b6fb9 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/apm.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/apm.h</span>
<span class="p_chunk">@@ -7,6 +7,8 @@</span> <span class="p_context"></span>
 #ifndef _ASM_X86_MACH_DEFAULT_APM_H
 #define _ASM_X86_MACH_DEFAULT_APM_H
 
<span class="p_add">+#include &lt;asm/nospec-branch.h&gt;</span>
<span class="p_add">+</span>
 #ifdef APM_ZERO_SEGS
 #	define APM_DO_ZERO_SEGS \
 		&quot;pushl %%ds\n\t&quot; \
<span class="p_chunk">@@ -32,6 +34,7 @@</span> <span class="p_context"> static inline void apm_bios_call_asm(u32 func, u32 ebx_in, u32 ecx_in,</span>
 	 * N.B. We do NOT need a cld after the BIOS call
 	 * because we always save and restore the flags.
 	 */
<span class="p_add">+	firmware_restrict_branch_speculation_start();</span>
 	__asm__ __volatile__(APM_DO_ZERO_SEGS
 		&quot;pushl %%edi\n\t&quot;
 		&quot;pushl %%ebp\n\t&quot;
<span class="p_chunk">@@ -44,6 +47,7 @@</span> <span class="p_context"> static inline void apm_bios_call_asm(u32 func, u32 ebx_in, u32 ecx_in,</span>
 		  &quot;=S&quot; (*esi)
 		: &quot;a&quot; (func), &quot;b&quot; (ebx_in), &quot;c&quot; (ecx_in)
 		: &quot;memory&quot;, &quot;cc&quot;);
<span class="p_add">+	firmware_restrict_branch_speculation_end();</span>
 }
 
 static inline bool apm_bios_call_simple_asm(u32 func, u32 ebx_in,
<span class="p_chunk">@@ -56,6 +60,7 @@</span> <span class="p_context"> static inline bool apm_bios_call_simple_asm(u32 func, u32 ebx_in,</span>
 	 * N.B. We do NOT need a cld after the BIOS call
 	 * because we always save and restore the flags.
 	 */
<span class="p_add">+	firmware_restrict_branch_speculation_start();</span>
 	__asm__ __volatile__(APM_DO_ZERO_SEGS
 		&quot;pushl %%edi\n\t&quot;
 		&quot;pushl %%ebp\n\t&quot;
<span class="p_chunk">@@ -68,6 +73,7 @@</span> <span class="p_context"> static inline bool apm_bios_call_simple_asm(u32 func, u32 ebx_in,</span>
 		  &quot;=S&quot; (si)
 		: &quot;a&quot; (func), &quot;b&quot; (ebx_in), &quot;c&quot; (ecx_in)
 		: &quot;memory&quot;, &quot;cc&quot;);
<span class="p_add">+	firmware_restrict_branch_speculation_end();</span>
 	return error;
 }
 
<span class="p_header">diff --git a/arch/x86/include/asm/asm-prototypes.h b/arch/x86/include/asm/asm-prototypes.h</span>
<span class="p_header">index 4d111616524b..1908214b9125 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/asm-prototypes.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/asm-prototypes.h</span>
<span class="p_chunk">@@ -38,7 +38,4 @@</span> <span class="p_context"> INDIRECT_THUNK(dx)</span>
 INDIRECT_THUNK(si)
 INDIRECT_THUNK(di)
 INDIRECT_THUNK(bp)
<span class="p_del">-asmlinkage void __fill_rsb(void);</span>
<span class="p_del">-asmlinkage void __clear_rsb(void);</span>
<span class="p_del">-</span>
 #endif /* CONFIG_RETPOLINE */
<span class="p_header">diff --git a/arch/x86/include/asm/cpufeatures.h b/arch/x86/include/asm/cpufeatures.h</span>
<span class="p_header">index 0dfe4d3f74e2..f41079da38c5 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/cpufeatures.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/cpufeatures.h</span>
<span class="p_chunk">@@ -213,6 +213,7 @@</span> <span class="p_context"></span>
 #define X86_FEATURE_SEV			( 7*32+20) /* AMD Secure Encrypted Virtualization */
 
 #define X86_FEATURE_USE_IBPB		( 7*32+21) /* &quot;&quot; Indirect Branch Prediction Barrier enabled */
<span class="p_add">+#define X86_FEATURE_USE_IBRS_FW		( 7*32+22) /* &quot;&quot; Use IBRS during runtime firmware calls */</span>
 
 /* Virtualization flags: Linux defined, word 8 */
 #define X86_FEATURE_TPR_SHADOW		( 8*32+ 0) /* Intel TPR Shadow */
<span class="p_header">diff --git a/arch/x86/include/asm/efi.h b/arch/x86/include/asm/efi.h</span>
<span class="p_header">index 85f6ccb80b91..a399c1ebf6f0 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/efi.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/efi.h</span>
<span class="p_chunk">@@ -6,6 +6,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/pgtable.h&gt;
 #include &lt;asm/processor-flags.h&gt;
 #include &lt;asm/tlb.h&gt;
<span class="p_add">+#include &lt;asm/nospec-branch.h&gt;</span>
 
 /*
  * We map the EFI regions needed for runtime services non-contiguously,
<span class="p_chunk">@@ -36,8 +37,18 @@</span> <span class="p_context"></span>
 
 extern asmlinkage unsigned long efi_call_phys(void *, ...);
 
<span class="p_del">-#define arch_efi_call_virt_setup()	kernel_fpu_begin()</span>
<span class="p_del">-#define arch_efi_call_virt_teardown()	kernel_fpu_end()</span>
<span class="p_add">+#define arch_efi_call_virt_setup()					\</span>
<span class="p_add">+({									\</span>
<span class="p_add">+	kernel_fpu_begin();						\</span>
<span class="p_add">+	firmware_restrict_branch_speculation_start();			\</span>
<span class="p_add">+})</span>
<span class="p_add">+</span>
<span class="p_add">+#define arch_efi_call_virt_teardown()					\</span>
<span class="p_add">+({									\</span>
<span class="p_add">+	firmware_restrict_branch_speculation_end();			\</span>
<span class="p_add">+	kernel_fpu_end();						\</span>
<span class="p_add">+})</span>
<span class="p_add">+</span>
 
 /*
  * Wrap all the virtual calls in a way that forces the parameters on the stack.
<span class="p_chunk">@@ -73,6 +84,7 @@</span> <span class="p_context"> struct efi_scratch {</span>
 	efi_sync_low_kernel_mappings();					\
 	preempt_disable();						\
 	__kernel_fpu_begin();						\
<span class="p_add">+	firmware_restrict_branch_speculation_start();			\</span>
 									\
 	if (efi_scratch.use_pgd) {					\
 		efi_scratch.prev_cr3 = __read_cr3();			\
<span class="p_chunk">@@ -91,6 +103,7 @@</span> <span class="p_context"> struct efi_scratch {</span>
 		__flush_tlb_all();					\
 	}								\
 									\
<span class="p_add">+	firmware_restrict_branch_speculation_end();			\</span>
 	__kernel_fpu_end();						\
 	preempt_enable();						\
 })
<span class="p_header">diff --git a/arch/x86/include/asm/microcode.h b/arch/x86/include/asm/microcode.h</span>
<span class="p_header">index 55520cec8b27..7fb1047d61c7 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/microcode.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/microcode.h</span>
<span class="p_chunk">@@ -37,7 +37,12 @@</span> <span class="p_context"> struct cpu_signature {</span>
 
 struct device;
 
<span class="p_del">-enum ucode_state { UCODE_ERROR, UCODE_OK, UCODE_NFOUND };</span>
<span class="p_add">+enum ucode_state {</span>
<span class="p_add">+	UCODE_OK	= 0,</span>
<span class="p_add">+	UCODE_UPDATED,</span>
<span class="p_add">+	UCODE_NFOUND,</span>
<span class="p_add">+	UCODE_ERROR,</span>
<span class="p_add">+};</span>
 
 struct microcode_ops {
 	enum ucode_state (*request_microcode_user) (int cpu,
<span class="p_chunk">@@ -54,7 +59,7 @@</span> <span class="p_context"> struct microcode_ops {</span>
 	 * are being called.
 	 * See also the &quot;Synchronization&quot; section in microcode_core.c.
 	 */
<span class="p_del">-	int (*apply_microcode) (int cpu);</span>
<span class="p_add">+	enum ucode_state (*apply_microcode) (int cpu);</span>
 	int (*collect_cpu_info) (int cpu, struct cpu_signature *csig);
 };
 
<span class="p_header">diff --git a/arch/x86/include/asm/mmu_context.h b/arch/x86/include/asm/mmu_context.h</span>
<span class="p_header">index c931b88982a0..1de72ce514cd 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mmu_context.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mmu_context.h</span>
<span class="p_chunk">@@ -74,6 +74,7 @@</span> <span class="p_context"> static inline void *ldt_slot_va(int slot)</span>
 	return (void *)(LDT_BASE_ADDR + LDT_SLOT_STRIDE * slot);
 #else
 	BUG();
<span class="p_add">+	return (void *)fix_to_virt(FIX_HOLE);</span>
 #endif
 }
 
<span class="p_header">diff --git a/arch/x86/include/asm/nospec-branch.h b/arch/x86/include/asm/nospec-branch.h</span>
<span class="p_header">index 76b058533e47..b7063cfa19f9 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/nospec-branch.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/nospec-branch.h</span>
<span class="p_chunk">@@ -8,6 +8,50 @@</span> <span class="p_context"></span>
 #include &lt;asm/cpufeatures.h&gt;
 #include &lt;asm/msr-index.h&gt;
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Fill the CPU return stack buffer.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Each entry in the RSB, if used for a speculative &#39;ret&#39;, contains an</span>
<span class="p_add">+ * infinite &#39;pause; lfence; jmp&#39; loop to capture speculative execution.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This is required in various cases for retpoline and IBRS-based</span>
<span class="p_add">+ * mitigations for the Spectre variant 2 vulnerability. Sometimes to</span>
<span class="p_add">+ * eliminate potentially bogus entries from the RSB, and sometimes</span>
<span class="p_add">+ * purely to ensure that it doesn&#39;t get empty, which on some CPUs would</span>
<span class="p_add">+ * allow predictions from other (unwanted!) sources to be used.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * We define a CPP macro such that it can be used from both .S files and</span>
<span class="p_add">+ * inline assembly. It&#39;s possible to do a .macro and then include that</span>
<span class="p_add">+ * from C via asm(&quot;.include &lt;asm/nospec-branch.h&gt;&quot;) but let&#39;s not go there.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#define RSB_CLEAR_LOOPS		32	/* To forcibly overwrite all entries */</span>
<span class="p_add">+#define RSB_FILL_LOOPS		16	/* To avoid underflow */</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Google experimented with loop-unrolling and this turned out to be</span>
<span class="p_add">+ * the optimal version  two calls, each with their own speculation</span>
<span class="p_add">+ * trap should their return address end up getting used, in a loop.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define __FILL_RETURN_BUFFER(reg, nr, sp)	\</span>
<span class="p_add">+	mov	$(nr/2), reg;			\</span>
<span class="p_add">+771:						\</span>
<span class="p_add">+	call	772f;				\</span>
<span class="p_add">+773:	/* speculation trap */			\</span>
<span class="p_add">+	pause;					\</span>
<span class="p_add">+	lfence;					\</span>
<span class="p_add">+	jmp	773b;				\</span>
<span class="p_add">+772:						\</span>
<span class="p_add">+	call	774f;				\</span>
<span class="p_add">+775:	/* speculation trap */			\</span>
<span class="p_add">+	pause;					\</span>
<span class="p_add">+	lfence;					\</span>
<span class="p_add">+	jmp	775b;				\</span>
<span class="p_add">+774:						\</span>
<span class="p_add">+	dec	reg;				\</span>
<span class="p_add">+	jnz	771b;				\</span>
<span class="p_add">+	add	$(BITS_PER_LONG/8) * nr, sp;</span>
<span class="p_add">+</span>
 #ifdef __ASSEMBLY__
 
 /*
<span class="p_chunk">@@ -23,6 +67,18 @@</span> <span class="p_context"></span>
 	.popsection
 .endm
 
<span class="p_add">+/*</span>
<span class="p_add">+ * This should be used immediately before an indirect jump/call. It tells</span>
<span class="p_add">+ * objtool the subsequent indirect jump/call is vouched safe for retpoline</span>
<span class="p_add">+ * builds.</span>
<span class="p_add">+ */</span>
<span class="p_add">+.macro ANNOTATE_RETPOLINE_SAFE</span>
<span class="p_add">+	.Lannotate_\@:</span>
<span class="p_add">+	.pushsection .discard.retpoline_safe</span>
<span class="p_add">+	_ASM_PTR .Lannotate_\@</span>
<span class="p_add">+	.popsection</span>
<span class="p_add">+.endm</span>
<span class="p_add">+</span>
 /*
  * These are the bare retpoline primitives for indirect jmp and call.
  * Do not use these directly; they only exist to make the ALTERNATIVE
<span class="p_chunk">@@ -59,9 +115,9 @@</span> <span class="p_context"></span>
 .macro JMP_NOSPEC reg:req
 #ifdef CONFIG_RETPOLINE
 	ANNOTATE_NOSPEC_ALTERNATIVE
<span class="p_del">-	ALTERNATIVE_2 __stringify(jmp *\reg),				\</span>
<span class="p_add">+	ALTERNATIVE_2 __stringify(ANNOTATE_RETPOLINE_SAFE; jmp *\reg),	\</span>
 		__stringify(RETPOLINE_JMP \reg), X86_FEATURE_RETPOLINE,	\
<span class="p_del">-		__stringify(lfence; jmp *\reg), X86_FEATURE_RETPOLINE_AMD</span>
<span class="p_add">+		__stringify(lfence; ANNOTATE_RETPOLINE_SAFE; jmp *\reg), X86_FEATURE_RETPOLINE_AMD</span>
 #else
 	jmp	*\reg
 #endif
<span class="p_chunk">@@ -70,18 +126,25 @@</span> <span class="p_context"></span>
 .macro CALL_NOSPEC reg:req
 #ifdef CONFIG_RETPOLINE
 	ANNOTATE_NOSPEC_ALTERNATIVE
<span class="p_del">-	ALTERNATIVE_2 __stringify(call *\reg),				\</span>
<span class="p_add">+	ALTERNATIVE_2 __stringify(ANNOTATE_RETPOLINE_SAFE; call *\reg),	\</span>
 		__stringify(RETPOLINE_CALL \reg), X86_FEATURE_RETPOLINE,\
<span class="p_del">-		__stringify(lfence; call *\reg), X86_FEATURE_RETPOLINE_AMD</span>
<span class="p_add">+		__stringify(lfence; ANNOTATE_RETPOLINE_SAFE; call *\reg), X86_FEATURE_RETPOLINE_AMD</span>
 #else
 	call	*\reg
 #endif
 .endm
 
<span class="p_del">-/* This clobbers the BX register */</span>
<span class="p_del">-.macro FILL_RETURN_BUFFER nr:req ftr:req</span>
<span class="p_add">+ /*</span>
<span class="p_add">+  * A simpler FILL_RETURN_BUFFER macro. Don&#39;t make people use the CPP</span>
<span class="p_add">+  * monstrosity above, manually.</span>
<span class="p_add">+  */</span>
<span class="p_add">+.macro FILL_RETURN_BUFFER reg:req nr:req ftr:req</span>
 #ifdef CONFIG_RETPOLINE
<span class="p_del">-	ALTERNATIVE &quot;&quot;, &quot;call __clear_rsb&quot;, \ftr</span>
<span class="p_add">+	ANNOTATE_NOSPEC_ALTERNATIVE</span>
<span class="p_add">+	ALTERNATIVE &quot;jmp .Lskip_rsb_\@&quot;,				\</span>
<span class="p_add">+		__stringify(__FILL_RETURN_BUFFER(\reg,\nr,%_ASM_SP))	\</span>
<span class="p_add">+		\ftr</span>
<span class="p_add">+.Lskip_rsb_\@:</span>
 #endif
 .endm
 
<span class="p_chunk">@@ -93,6 +156,12 @@</span> <span class="p_context"></span>
 	&quot;.long 999b - .\n\t&quot;					\
 	&quot;.popsection\n\t&quot;
 
<span class="p_add">+#define ANNOTATE_RETPOLINE_SAFE					\</span>
<span class="p_add">+	&quot;999:\n\t&quot;						\</span>
<span class="p_add">+	&quot;.pushsection .discard.retpoline_safe\n\t&quot;		\</span>
<span class="p_add">+	_ASM_PTR &quot; 999b\n\t&quot;					\</span>
<span class="p_add">+	&quot;.popsection\n\t&quot;</span>
<span class="p_add">+</span>
 #if defined(CONFIG_X86_64) &amp;&amp; defined(RETPOLINE)
 
 /*
<span class="p_chunk">@@ -102,6 +171,7 @@</span> <span class="p_context"></span>
 # define CALL_NOSPEC						\
 	ANNOTATE_NOSPEC_ALTERNATIVE				\
 	ALTERNATIVE(						\
<span class="p_add">+	ANNOTATE_RETPOLINE_SAFE					\</span>
 	&quot;call *%[thunk_target]\n&quot;,				\
 	&quot;call __x86_indirect_thunk_%V[thunk_target]\n&quot;,		\
 	X86_FEATURE_RETPOLINE)
<span class="p_chunk">@@ -156,25 +226,53 @@</span> <span class="p_context"> extern char __indirect_thunk_end[];</span>
 static inline void vmexit_fill_RSB(void)
 {
 #ifdef CONFIG_RETPOLINE
<span class="p_del">-	alternative_input(&quot;&quot;,</span>
<span class="p_del">-			  &quot;call __fill_rsb&quot;,</span>
<span class="p_del">-			  X86_FEATURE_RETPOLINE,</span>
<span class="p_del">-			  ASM_NO_INPUT_CLOBBER(_ASM_BX, &quot;memory&quot;));</span>
<span class="p_add">+	unsigned long loops;</span>
<span class="p_add">+</span>
<span class="p_add">+	asm volatile (ANNOTATE_NOSPEC_ALTERNATIVE</span>
<span class="p_add">+		      ALTERNATIVE(&quot;jmp 910f&quot;,</span>
<span class="p_add">+				  __stringify(__FILL_RETURN_BUFFER(%0, RSB_CLEAR_LOOPS, %1)),</span>
<span class="p_add">+				  X86_FEATURE_RETPOLINE)</span>
<span class="p_add">+		      &quot;910:&quot;</span>
<span class="p_add">+		      : &quot;=r&quot; (loops), ASM_CALL_CONSTRAINT</span>
<span class="p_add">+		      : : &quot;memory&quot; );</span>
 #endif
 }
 
<span class="p_add">+#define alternative_msr_write(_msr, _val, _feature)		\</span>
<span class="p_add">+	asm volatile(ALTERNATIVE(&quot;&quot;,				\</span>
<span class="p_add">+				 &quot;movl %[msr], %%ecx\n\t&quot;	\</span>
<span class="p_add">+				 &quot;movl %[val], %%eax\n\t&quot;	\</span>
<span class="p_add">+				 &quot;movl $0, %%edx\n\t&quot;		\</span>
<span class="p_add">+				 &quot;wrmsr&quot;,			\</span>
<span class="p_add">+				 _feature)			\</span>
<span class="p_add">+		     : : [msr] &quot;i&quot; (_msr), [val] &quot;i&quot; (_val)	\</span>
<span class="p_add">+		     : &quot;eax&quot;, &quot;ecx&quot;, &quot;edx&quot;, &quot;memory&quot;)</span>
<span class="p_add">+</span>
 static inline void indirect_branch_prediction_barrier(void)
 {
<span class="p_del">-	asm volatile(ALTERNATIVE(&quot;&quot;,</span>
<span class="p_del">-				 &quot;movl %[msr], %%ecx\n\t&quot;</span>
<span class="p_del">-				 &quot;movl %[val], %%eax\n\t&quot;</span>
<span class="p_del">-				 &quot;movl $0, %%edx\n\t&quot;</span>
<span class="p_del">-				 &quot;wrmsr&quot;,</span>
<span class="p_del">-				 X86_FEATURE_USE_IBPB)</span>
<span class="p_del">-		     : : [msr] &quot;i&quot; (MSR_IA32_PRED_CMD),</span>
<span class="p_del">-			 [val] &quot;i&quot; (PRED_CMD_IBPB)</span>
<span class="p_del">-		     : &quot;eax&quot;, &quot;ecx&quot;, &quot;edx&quot;, &quot;memory&quot;);</span>
<span class="p_add">+	alternative_msr_write(MSR_IA32_PRED_CMD, PRED_CMD_IBPB,</span>
<span class="p_add">+			      X86_FEATURE_USE_IBPB);</span>
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * With retpoline, we must use IBRS to restrict branch prediction</span>
<span class="p_add">+ * before calling into firmware.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * (Implemented as CPP macros due to header hell.)</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define firmware_restrict_branch_speculation_start()			\</span>
<span class="p_add">+do {									\</span>
<span class="p_add">+	preempt_disable();						\</span>
<span class="p_add">+	alternative_msr_write(MSR_IA32_SPEC_CTRL, SPEC_CTRL_IBRS,	\</span>
<span class="p_add">+			      X86_FEATURE_USE_IBRS_FW);			\</span>
<span class="p_add">+} while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define firmware_restrict_branch_speculation_end()			\</span>
<span class="p_add">+do {									\</span>
<span class="p_add">+	alternative_msr_write(MSR_IA32_SPEC_CTRL, 0,			\</span>
<span class="p_add">+			      X86_FEATURE_USE_IBRS_FW);			\</span>
<span class="p_add">+	preempt_enable();						\</span>
<span class="p_add">+} while (0)</span>
<span class="p_add">+</span>
 #endif /* __ASSEMBLY__ */
 #endif /* _ASM_X86_NOSPEC_BRANCH_H_ */
<span class="p_header">diff --git a/arch/x86/include/asm/paravirt.h b/arch/x86/include/asm/paravirt.h</span>
<span class="p_header">index 554841fab717..c83a2f418cea 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/paravirt.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/paravirt.h</span>
<span class="p_chunk">@@ -7,6 +7,7 @@</span> <span class="p_context"></span>
 #ifdef CONFIG_PARAVIRT
 #include &lt;asm/pgtable_types.h&gt;
 #include &lt;asm/asm.h&gt;
<span class="p_add">+#include &lt;asm/nospec-branch.h&gt;</span>
 
 #include &lt;asm/paravirt_types.h&gt;
 
<span class="p_chunk">@@ -879,23 +880,27 @@</span> <span class="p_context"> extern void default_banner(void);</span>
 
 #define INTERRUPT_RETURN						\
 	PARA_SITE(PARA_PATCH(pv_cpu_ops, PV_CPU_iret), CLBR_NONE,	\
<span class="p_del">-		  jmp PARA_INDIRECT(pv_cpu_ops+PV_CPU_iret))</span>
<span class="p_add">+		  ANNOTATE_RETPOLINE_SAFE;					\</span>
<span class="p_add">+		  jmp PARA_INDIRECT(pv_cpu_ops+PV_CPU_iret);)</span>
 
 #define DISABLE_INTERRUPTS(clobbers)					\
 	PARA_SITE(PARA_PATCH(pv_irq_ops, PV_IRQ_irq_disable), clobbers, \
 		  PV_SAVE_REGS(clobbers | CLBR_CALLEE_SAVE);		\
<span class="p_add">+		  ANNOTATE_RETPOLINE_SAFE;					\</span>
 		  call PARA_INDIRECT(pv_irq_ops+PV_IRQ_irq_disable);	\
 		  PV_RESTORE_REGS(clobbers | CLBR_CALLEE_SAVE);)
 
 #define ENABLE_INTERRUPTS(clobbers)					\
 	PARA_SITE(PARA_PATCH(pv_irq_ops, PV_IRQ_irq_enable), clobbers,	\
 		  PV_SAVE_REGS(clobbers | CLBR_CALLEE_SAVE);		\
<span class="p_add">+		  ANNOTATE_RETPOLINE_SAFE;					\</span>
 		  call PARA_INDIRECT(pv_irq_ops+PV_IRQ_irq_enable);	\
 		  PV_RESTORE_REGS(clobbers | CLBR_CALLEE_SAVE);)
 
 #ifdef CONFIG_X86_32
 #define GET_CR0_INTO_EAX				\
 	push %ecx; push %edx;				\
<span class="p_add">+	ANNOTATE_RETPOLINE_SAFE;				\</span>
 	call PARA_INDIRECT(pv_cpu_ops+PV_CPU_read_cr0);	\
 	pop %edx; pop %ecx
 #else	/* !CONFIG_X86_32 */
<span class="p_chunk">@@ -917,21 +922,25 @@</span> <span class="p_context"> extern void default_banner(void);</span>
  */
 #define SWAPGS								\
 	PARA_SITE(PARA_PATCH(pv_cpu_ops, PV_CPU_swapgs), CLBR_NONE,	\
<span class="p_del">-		  call PARA_INDIRECT(pv_cpu_ops+PV_CPU_swapgs)		\</span>
<span class="p_add">+		  ANNOTATE_RETPOLINE_SAFE;					\</span>
<span class="p_add">+		  call PARA_INDIRECT(pv_cpu_ops+PV_CPU_swapgs);		\</span>
 		 )
 
 #define GET_CR2_INTO_RAX				\
<span class="p_del">-	call PARA_INDIRECT(pv_mmu_ops+PV_MMU_read_cr2)</span>
<span class="p_add">+	ANNOTATE_RETPOLINE_SAFE;				\</span>
<span class="p_add">+	call PARA_INDIRECT(pv_mmu_ops+PV_MMU_read_cr2);</span>
 
 #define USERGS_SYSRET64							\
 	PARA_SITE(PARA_PATCH(pv_cpu_ops, PV_CPU_usergs_sysret64),	\
 		  CLBR_NONE,						\
<span class="p_del">-		  jmp PARA_INDIRECT(pv_cpu_ops+PV_CPU_usergs_sysret64))</span>
<span class="p_add">+		  ANNOTATE_RETPOLINE_SAFE;					\</span>
<span class="p_add">+		  jmp PARA_INDIRECT(pv_cpu_ops+PV_CPU_usergs_sysret64);)</span>
 
 #ifdef CONFIG_DEBUG_ENTRY
 #define SAVE_FLAGS(clobbers)                                        \
 	PARA_SITE(PARA_PATCH(pv_irq_ops, PV_IRQ_save_fl), clobbers, \
 		  PV_SAVE_REGS(clobbers | CLBR_CALLEE_SAVE);        \
<span class="p_add">+		  ANNOTATE_RETPOLINE_SAFE;				    \</span>
 		  call PARA_INDIRECT(pv_irq_ops+PV_IRQ_save_fl);    \
 		  PV_RESTORE_REGS(clobbers | CLBR_CALLEE_SAVE);)
 #endif
<span class="p_header">diff --git a/arch/x86/include/asm/paravirt_types.h b/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_header">index f624f1f10316..180bc0bff0fb 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_chunk">@@ -43,6 +43,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/desc_defs.h&gt;
 #include &lt;asm/kmap_types.h&gt;
 #include &lt;asm/pgtable_types.h&gt;
<span class="p_add">+#include &lt;asm/nospec-branch.h&gt;</span>
 
 struct page;
 struct thread_struct;
<span class="p_chunk">@@ -392,7 +393,9 @@</span> <span class="p_context"> int paravirt_disable_iospace(void);</span>
  * offset into the paravirt_patch_template structure, and can therefore be
  * freely converted back into a structure offset.
  */
<span class="p_del">-#define PARAVIRT_CALL	&quot;call *%c[paravirt_opptr];&quot;</span>
<span class="p_add">+#define PARAVIRT_CALL					\</span>
<span class="p_add">+	ANNOTATE_RETPOLINE_SAFE				\</span>
<span class="p_add">+	&quot;call *%c[paravirt_opptr];&quot;</span>
 
 /*
  * These macros are intended to wrap calls through one of the paravirt
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">index 63c2552b6b65..b444d83cfc95 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -350,14 +350,14 @@</span> <span class="p_context"> static inline pmd_t pmd_set_flags(pmd_t pmd, pmdval_t set)</span>
 {
 	pmdval_t v = native_pmd_val(pmd);
 
<span class="p_del">-	return __pmd(v | set);</span>
<span class="p_add">+	return native_make_pmd(v | set);</span>
 }
 
 static inline pmd_t pmd_clear_flags(pmd_t pmd, pmdval_t clear)
 {
 	pmdval_t v = native_pmd_val(pmd);
 
<span class="p_del">-	return __pmd(v &amp; ~clear);</span>
<span class="p_add">+	return native_make_pmd(v &amp; ~clear);</span>
 }
 
 static inline pmd_t pmd_mkold(pmd_t pmd)
<span class="p_chunk">@@ -409,14 +409,14 @@</span> <span class="p_context"> static inline pud_t pud_set_flags(pud_t pud, pudval_t set)</span>
 {
 	pudval_t v = native_pud_val(pud);
 
<span class="p_del">-	return __pud(v | set);</span>
<span class="p_add">+	return native_make_pud(v | set);</span>
 }
 
 static inline pud_t pud_clear_flags(pud_t pud, pudval_t clear)
 {
 	pudval_t v = native_pud_val(pud);
 
<span class="p_del">-	return __pud(v &amp; ~clear);</span>
<span class="p_add">+	return native_make_pud(v &amp; ~clear);</span>
 }
 
 static inline pud_t pud_mkold(pud_t pud)
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable_types.h b/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_header">index 3696398a9475..246f15b4e64c 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_chunk">@@ -323,6 +323,11 @@</span> <span class="p_context"> static inline pudval_t native_pud_val(pud_t pud)</span>
 #else
 #include &lt;asm-generic/pgtable-nopud.h&gt;
 
<span class="p_add">+static inline pud_t native_make_pud(pudval_t val)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (pud_t) { .p4d.pgd = native_make_pgd(val) };</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline pudval_t native_pud_val(pud_t pud)
 {
 	return native_pgd_val(pud.p4d.pgd);
<span class="p_chunk">@@ -344,6 +349,11 @@</span> <span class="p_context"> static inline pmdval_t native_pmd_val(pmd_t pmd)</span>
 #else
 #include &lt;asm-generic/pgtable-nopmd.h&gt;
 
<span class="p_add">+static inline pmd_t native_make_pmd(pmdval_t val)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (pmd_t) { .pud.p4d.pgd = native_make_pgd(val) };</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline pmdval_t native_pmd_val(pmd_t pmd)
 {
 	return native_pgd_val(pmd.pud.p4d.pgd);
<span class="p_header">diff --git a/arch/x86/include/asm/processor.h b/arch/x86/include/asm/processor.h</span>
<span class="p_header">index 1bd9ed87606f..b0ccd4847a58 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/processor.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/processor.h</span>
<span class="p_chunk">@@ -977,4 +977,5 @@</span> <span class="p_context"> bool xen_set_default_idle(void);</span>
 
 void stop_this_cpu(void *dummy);
 void df_debug(struct pt_regs *regs, long error_code);
<span class="p_add">+void microcode_check(void);</span>
 #endif /* _ASM_X86_PROCESSOR_H */
<span class="p_header">diff --git a/arch/x86/include/asm/refcount.h b/arch/x86/include/asm/refcount.h</span>
<span class="p_header">index 4e44250e7d0d..d65171120e90 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/refcount.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/refcount.h</span>
<span class="p_chunk">@@ -67,13 +67,13 @@</span> <span class="p_context"> static __always_inline __must_check</span>
 bool refcount_sub_and_test(unsigned int i, refcount_t *r)
 {
 	GEN_BINARY_SUFFIXED_RMWcc(LOCK_PREFIX &quot;subl&quot;, REFCOUNT_CHECK_LT_ZERO,
<span class="p_del">-				  r-&gt;refs.counter, &quot;er&quot;, i, &quot;%0&quot;, e);</span>
<span class="p_add">+				  r-&gt;refs.counter, &quot;er&quot;, i, &quot;%0&quot;, e, &quot;cx&quot;);</span>
 }
 
 static __always_inline __must_check bool refcount_dec_and_test(refcount_t *r)
 {
 	GEN_UNARY_SUFFIXED_RMWcc(LOCK_PREFIX &quot;decl&quot;, REFCOUNT_CHECK_LT_ZERO,
<span class="p_del">-				 r-&gt;refs.counter, &quot;%0&quot;, e);</span>
<span class="p_add">+				 r-&gt;refs.counter, &quot;%0&quot;, e, &quot;cx&quot;);</span>
 }
 
 static __always_inline __must_check
<span class="p_header">diff --git a/arch/x86/include/asm/rmwcc.h b/arch/x86/include/asm/rmwcc.h</span>
<span class="p_header">index f91c365e57c3..4914a3e7c803 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/rmwcc.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/rmwcc.h</span>
<span class="p_chunk">@@ -2,8 +2,7 @@</span> <span class="p_context"></span>
 #ifndef _ASM_X86_RMWcc
 #define _ASM_X86_RMWcc
 
<span class="p_del">-#define __CLOBBERS_MEM		&quot;memory&quot;</span>
<span class="p_del">-#define __CLOBBERS_MEM_CC_CX	&quot;memory&quot;, &quot;cc&quot;, &quot;cx&quot;</span>
<span class="p_add">+#define __CLOBBERS_MEM(clb...)	&quot;memory&quot;, ## clb</span>
 
 #if !defined(__GCC_ASM_FLAG_OUTPUTS__) &amp;&amp; defined(CC_HAVE_ASM_GOTO)
 
<span class="p_chunk">@@ -40,18 +39,19 @@</span> <span class="p_context"> do {									\</span>
 #endif /* defined(__GCC_ASM_FLAG_OUTPUTS__) || !defined(CC_HAVE_ASM_GOTO) */
 
 #define GEN_UNARY_RMWcc(op, var, arg0, cc)				\
<span class="p_del">-	__GEN_RMWcc(op &quot; &quot; arg0, var, cc, __CLOBBERS_MEM)</span>
<span class="p_add">+	__GEN_RMWcc(op &quot; &quot; arg0, var, cc, __CLOBBERS_MEM())</span>
 
<span class="p_del">-#define GEN_UNARY_SUFFIXED_RMWcc(op, suffix, var, arg0, cc)		\</span>
<span class="p_add">+#define GEN_UNARY_SUFFIXED_RMWcc(op, suffix, var, arg0, cc, clobbers...)\</span>
 	__GEN_RMWcc(op &quot; &quot; arg0 &quot;\n\t&quot; suffix, var, cc,			\
<span class="p_del">-		    __CLOBBERS_MEM_CC_CX)</span>
<span class="p_add">+		    __CLOBBERS_MEM(clobbers))</span>
 
 #define GEN_BINARY_RMWcc(op, var, vcon, val, arg0, cc)			\
 	__GEN_RMWcc(op __BINARY_RMWcc_ARG arg0, var, cc,		\
<span class="p_del">-		    __CLOBBERS_MEM, vcon (val))</span>
<span class="p_add">+		    __CLOBBERS_MEM(), vcon (val))</span>
 
<span class="p_del">-#define GEN_BINARY_SUFFIXED_RMWcc(op, suffix, var, vcon, val, arg0, cc)	\</span>
<span class="p_add">+#define GEN_BINARY_SUFFIXED_RMWcc(op, suffix, var, vcon, val, arg0, cc,	\</span>
<span class="p_add">+				  clobbers...)				\</span>
 	__GEN_RMWcc(op __BINARY_RMWcc_ARG arg0 &quot;\n\t&quot; suffix, var, cc,	\
<span class="p_del">-		    __CLOBBERS_MEM_CC_CX, vcon (val))</span>
<span class="p_add">+		    __CLOBBERS_MEM(clobbers), vcon (val))</span>
 
 #endif /* _ASM_X86_RMWcc */
<span class="p_header">diff --git a/arch/x86/kernel/apic/io_apic.c b/arch/x86/kernel/apic/io_apic.c</span>
<span class="p_header">index 8ad2e410974f..7c5538769f7e 100644</span>
<span class="p_header">--- a/arch/x86/kernel/apic/io_apic.c</span>
<span class="p_header">+++ b/arch/x86/kernel/apic/io_apic.c</span>
<span class="p_chunk">@@ -1603,7 +1603,7 @@</span> <span class="p_context"> static void __init delay_with_tsc(void)</span>
 	do {
 		rep_nop();
 		now = rdtsc();
<span class="p_del">-	} while ((now - start) &lt; 40000000000UL / HZ &amp;&amp;</span>
<span class="p_add">+	} while ((now - start) &lt; 40000000000ULL / HZ &amp;&amp;</span>
 		time_before_eq(jiffies, end));
 }
 
<span class="p_header">diff --git a/arch/x86/kernel/cpu/bugs.c b/arch/x86/kernel/cpu/bugs.c</span>
<span class="p_header">index d71c8b54b696..bfca937bdcc3 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/bugs.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/bugs.c</span>
<span class="p_chunk">@@ -300,6 +300,15 @@</span> <span class="p_context"> static void __init spectre_v2_select_mitigation(void)</span>
 		setup_force_cpu_cap(X86_FEATURE_USE_IBPB);
 		pr_info(&quot;Spectre v2 mitigation: Enabling Indirect Branch Prediction Barrier\n&quot;);
 	}
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Retpoline means the kernel is safe because it has no indirect</span>
<span class="p_add">+	 * branches. But firmware isn&#39;t, so use IBRS to protect that.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_IBRS)) {</span>
<span class="p_add">+		setup_force_cpu_cap(X86_FEATURE_USE_IBRS_FW);</span>
<span class="p_add">+		pr_info(&quot;Enabling Restricted Speculation for firmware calls\n&quot;);</span>
<span class="p_add">+	}</span>
 }
 
 #undef pr_fmt
<span class="p_chunk">@@ -326,8 +335,9 @@</span> <span class="p_context"> ssize_t cpu_show_spectre_v2(struct device *dev, struct device_attribute *attr, c</span>
 	if (!boot_cpu_has_bug(X86_BUG_SPECTRE_V2))
 		return sprintf(buf, &quot;Not affected\n&quot;);
 
<span class="p_del">-	return sprintf(buf, &quot;%s%s%s\n&quot;, spectre_v2_strings[spectre_v2_enabled],</span>
<span class="p_add">+	return sprintf(buf, &quot;%s%s%s%s\n&quot;, spectre_v2_strings[spectre_v2_enabled],</span>
 		       boot_cpu_has(X86_FEATURE_USE_IBPB) ? &quot;, IBPB&quot; : &quot;&quot;,
<span class="p_add">+		       boot_cpu_has(X86_FEATURE_USE_IBRS_FW) ? &quot;, IBRS_FW&quot; : &quot;&quot;,</span>
 		       spectre_v2_module_string());
 }
 #endif
<span class="p_header">diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c</span>
<span class="p_header">index 824aee0117bb..348cf4821240 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/common.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/common.c</span>
<span class="p_chunk">@@ -1749,3 +1749,33 @@</span> <span class="p_context"> static int __init init_cpu_syscore(void)</span>
 	return 0;
 }
 core_initcall(init_cpu_syscore);
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * The microcode loader calls this upon late microcode load to recheck features,</span>
<span class="p_add">+ * only when microcode has been updated. Caller holds microcode_mutex and CPU</span>
<span class="p_add">+ * hotplug lock.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void microcode_check(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct cpuinfo_x86 info;</span>
<span class="p_add">+</span>
<span class="p_add">+	perf_check_microcode();</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Reload CPUID max function as it might&#39;ve changed. */</span>
<span class="p_add">+	info.cpuid_level = cpuid_eax(0);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Copy all capability leafs to pick up the synthetic ones so that</span>
<span class="p_add">+	 * memcmp() below doesn&#39;t fail on that. The ones coming from CPUID will</span>
<span class="p_add">+	 * get overwritten in get_cpu_cap().</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	memcpy(&amp;info.x86_capability, &amp;boot_cpu_data.x86_capability, sizeof(info.x86_capability));</span>
<span class="p_add">+</span>
<span class="p_add">+	get_cpu_cap(&amp;info);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!memcmp(&amp;info.x86_capability, &amp;boot_cpu_data.x86_capability, sizeof(info.x86_capability)))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_warn(&quot;x86/CPU: CPU features have changed after loading microcode, but might not take effect.\n&quot;);</span>
<span class="p_add">+	pr_warn(&quot;x86/CPU: Please consider either early loading through initrd/built-in or a potential BIOS update.\n&quot;);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/x86/kernel/cpu/microcode/amd.c b/arch/x86/kernel/cpu/microcode/amd.c</span>
<span class="p_header">index 330b8462d426..a998e1a7d46f 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/microcode/amd.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/microcode/amd.c</span>
<span class="p_chunk">@@ -498,7 +498,7 @@</span> <span class="p_context"> static unsigned int verify_patch_size(u8 family, u32 patch_size,</span>
 	return patch_size;
 }
 
<span class="p_del">-static int apply_microcode_amd(int cpu)</span>
<span class="p_add">+static enum ucode_state apply_microcode_amd(int cpu)</span>
 {
 	struct cpuinfo_x86 *c = &amp;cpu_data(cpu);
 	struct microcode_amd *mc_amd;
<span class="p_chunk">@@ -512,7 +512,7 @@</span> <span class="p_context"> static int apply_microcode_amd(int cpu)</span>
 
 	p = find_patch(cpu);
 	if (!p)
<span class="p_del">-		return 0;</span>
<span class="p_add">+		return UCODE_NFOUND;</span>
 
 	mc_amd  = p-&gt;data;
 	uci-&gt;mc = p-&gt;data;
<span class="p_chunk">@@ -523,13 +523,13 @@</span> <span class="p_context"> static int apply_microcode_amd(int cpu)</span>
 	if (rev &gt;= mc_amd-&gt;hdr.patch_id) {
 		c-&gt;microcode = rev;
 		uci-&gt;cpu_sig.rev = rev;
<span class="p_del">-		return 0;</span>
<span class="p_add">+		return UCODE_OK;</span>
 	}
 
 	if (__apply_microcode_amd(mc_amd)) {
 		pr_err(&quot;CPU%d: update failed for patch_level=0x%08x\n&quot;,
 			cpu, mc_amd-&gt;hdr.patch_id);
<span class="p_del">-		return -1;</span>
<span class="p_add">+		return UCODE_ERROR;</span>
 	}
 	pr_info(&quot;CPU%d: new patch_level=0x%08x\n&quot;, cpu,
 		mc_amd-&gt;hdr.patch_id);
<span class="p_chunk">@@ -537,7 +537,7 @@</span> <span class="p_context"> static int apply_microcode_amd(int cpu)</span>
 	uci-&gt;cpu_sig.rev = mc_amd-&gt;hdr.patch_id;
 	c-&gt;microcode = mc_amd-&gt;hdr.patch_id;
 
<span class="p_del">-	return 0;</span>
<span class="p_add">+	return UCODE_UPDATED;</span>
 }
 
 static int install_equiv_cpu_table(const u8 *buf)
<span class="p_header">diff --git a/arch/x86/kernel/cpu/microcode/core.c b/arch/x86/kernel/cpu/microcode/core.c</span>
<span class="p_header">index 319dd65f98a2..aa1b9a422f2b 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/microcode/core.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/microcode/core.c</span>
<span class="p_chunk">@@ -374,7 +374,7 @@</span> <span class="p_context"> static int collect_cpu_info(int cpu)</span>
 }
 
 struct apply_microcode_ctx {
<span class="p_del">-	int err;</span>
<span class="p_add">+	enum ucode_state err;</span>
 };
 
 static void apply_microcode_local(void *arg)
<span class="p_chunk">@@ -489,31 +489,30 @@</span> <span class="p_context"> static void __exit microcode_dev_exit(void)</span>
 /* fake device for request_firmware */
 static struct platform_device	*microcode_pdev;
 
<span class="p_del">-static int reload_for_cpu(int cpu)</span>
<span class="p_add">+static enum ucode_state reload_for_cpu(int cpu)</span>
 {
 	struct ucode_cpu_info *uci = ucode_cpu_info + cpu;
 	enum ucode_state ustate;
<span class="p_del">-	int err = 0;</span>
 
 	if (!uci-&gt;valid)
<span class="p_del">-		return err;</span>
<span class="p_add">+		return UCODE_OK;</span>
 
 	ustate = microcode_ops-&gt;request_microcode_fw(cpu, &amp;microcode_pdev-&gt;dev, true);
<span class="p_del">-	if (ustate == UCODE_OK)</span>
<span class="p_del">-		apply_microcode_on_target(cpu);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		if (ustate == UCODE_ERROR)</span>
<span class="p_del">-			err = -EINVAL;</span>
<span class="p_del">-	return err;</span>
<span class="p_add">+	if (ustate != UCODE_OK)</span>
<span class="p_add">+		return ustate;</span>
<span class="p_add">+</span>
<span class="p_add">+	return apply_microcode_on_target(cpu);</span>
 }
 
 static ssize_t reload_store(struct device *dev,
 			    struct device_attribute *attr,
 			    const char *buf, size_t size)
 {
<span class="p_add">+	enum ucode_state tmp_ret = UCODE_OK;</span>
<span class="p_add">+	bool do_callback = false;</span>
 	unsigned long val;
<span class="p_add">+	ssize_t ret = 0;</span>
 	int cpu;
<span class="p_del">-	ssize_t ret = 0, tmp_ret;</span>
 
 	ret = kstrtoul(buf, 0, &amp;val);
 	if (ret)
<span class="p_chunk">@@ -526,15 +525,21 @@</span> <span class="p_context"> static ssize_t reload_store(struct device *dev,</span>
 	mutex_lock(&amp;microcode_mutex);
 	for_each_online_cpu(cpu) {
 		tmp_ret = reload_for_cpu(cpu);
<span class="p_del">-		if (tmp_ret != 0)</span>
<span class="p_add">+		if (tmp_ret &gt; UCODE_NFOUND) {</span>
 			pr_warn(&quot;Error reloading microcode on CPU %d\n&quot;, cpu);
 
<span class="p_del">-		/* save retval of the first encountered reload error */</span>
<span class="p_del">-		if (!ret)</span>
<span class="p_del">-			ret = tmp_ret;</span>
<span class="p_add">+			/* set retval for the first encountered reload error */</span>
<span class="p_add">+			if (!ret)</span>
<span class="p_add">+				ret = -EINVAL;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		if (tmp_ret == UCODE_UPDATED)</span>
<span class="p_add">+			do_callback = true;</span>
 	}
<span class="p_del">-	if (!ret)</span>
<span class="p_del">-		perf_check_microcode();</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!ret &amp;&amp; do_callback)</span>
<span class="p_add">+		microcode_check();</span>
<span class="p_add">+</span>
 	mutex_unlock(&amp;microcode_mutex);
 	put_online_cpus();
 
<span class="p_header">diff --git a/arch/x86/kernel/cpu/microcode/intel.c b/arch/x86/kernel/cpu/microcode/intel.c</span>
<span class="p_header">index a15db2b4e0d6..923054a6b760 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/microcode/intel.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/microcode/intel.c</span>
<span class="p_chunk">@@ -772,7 +772,7 @@</span> <span class="p_context"> static int collect_cpu_info(int cpu_num, struct cpu_signature *csig)</span>
 	return 0;
 }
 
<span class="p_del">-static int apply_microcode_intel(int cpu)</span>
<span class="p_add">+static enum ucode_state apply_microcode_intel(int cpu)</span>
 {
 	struct microcode_intel *mc;
 	struct ucode_cpu_info *uci;
<span class="p_chunk">@@ -782,7 +782,7 @@</span> <span class="p_context"> static int apply_microcode_intel(int cpu)</span>
 
 	/* We should bind the task to the CPU */
 	if (WARN_ON(raw_smp_processor_id() != cpu))
<span class="p_del">-		return -1;</span>
<span class="p_add">+		return UCODE_ERROR;</span>
 
 	uci = ucode_cpu_info + cpu;
 	mc = uci-&gt;mc;
<span class="p_chunk">@@ -790,7 +790,7 @@</span> <span class="p_context"> static int apply_microcode_intel(int cpu)</span>
 		/* Look for a newer patch in our cache: */
 		mc = find_patch(uci);
 		if (!mc)
<span class="p_del">-			return 0;</span>
<span class="p_add">+			return UCODE_NFOUND;</span>
 	}
 
 	/* write microcode via MSR 0x79 */
<span class="p_chunk">@@ -801,7 +801,7 @@</span> <span class="p_context"> static int apply_microcode_intel(int cpu)</span>
 	if (rev != mc-&gt;hdr.rev) {
 		pr_err(&quot;CPU%d update to revision 0x%x failed\n&quot;,
 		       cpu, mc-&gt;hdr.rev);
<span class="p_del">-		return -1;</span>
<span class="p_add">+		return UCODE_ERROR;</span>
 	}
 
 	if (rev != prev_rev) {
<span class="p_chunk">@@ -818,7 +818,7 @@</span> <span class="p_context"> static int apply_microcode_intel(int cpu)</span>
 	uci-&gt;cpu_sig.rev = rev;
 	c-&gt;microcode = rev;
 
<span class="p_del">-	return 0;</span>
<span class="p_add">+	return UCODE_UPDATED;</span>
 }
 
 static enum ucode_state generic_load_microcode(int cpu, void *data, size_t size,
<span class="p_header">diff --git a/arch/x86/kernel/head_64.S b/arch/x86/kernel/head_64.S</span>
<span class="p_header">index 04a625f0fcda..0f545b3cf926 100644</span>
<span class="p_header">--- a/arch/x86/kernel/head_64.S</span>
<span class="p_header">+++ b/arch/x86/kernel/head_64.S</span>
<span class="p_chunk">@@ -23,6 +23,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/nops.h&gt;
 #include &quot;../entry/calling.h&quot;
 #include &lt;asm/export.h&gt;
<span class="p_add">+#include &lt;asm/nospec-branch.h&gt;</span>
 
 #ifdef CONFIG_PARAVIRT
 #include &lt;asm/asm-offsets.h&gt;
<span class="p_chunk">@@ -134,6 +135,7 @@</span> <span class="p_context"> ENTRY(secondary_startup_64)</span>
 
 	/* Ensure I am executing from virtual addresses */
 	movq	$1f, %rax
<span class="p_add">+	ANNOTATE_RETPOLINE_SAFE</span>
 	jmp	*%rax
 1:
 	UNWIND_HINT_EMPTY
<span class="p_header">diff --git a/arch/x86/kernel/unwind_orc.c b/arch/x86/kernel/unwind_orc.c</span>
<span class="p_header">index 1f9188f5357c..feb28fee6cea 100644</span>
<span class="p_header">--- a/arch/x86/kernel/unwind_orc.c</span>
<span class="p_header">+++ b/arch/x86/kernel/unwind_orc.c</span>
<span class="p_chunk">@@ -5,7 +5,6 @@</span> <span class="p_context"></span>
 #include &lt;asm/unwind.h&gt;
 #include &lt;asm/orc_types.h&gt;
 #include &lt;asm/orc_lookup.h&gt;
<span class="p_del">-#include &lt;asm/sections.h&gt;</span>
 
 #define orc_warn(fmt, ...) \
 	printk_deferred_once(KERN_WARNING pr_fmt(&quot;WARNING: &quot; fmt), ##__VA_ARGS__)
<span class="p_chunk">@@ -148,7 +147,7 @@</span> <span class="p_context"> static struct orc_entry *orc_find(unsigned long ip)</span>
 	}
 
 	/* vmlinux .init slow lookup: */
<span class="p_del">-	if (ip &gt;= (unsigned long)_sinittext &amp;&amp; ip &lt; (unsigned long)_einittext)</span>
<span class="p_add">+	if (init_kernel_text(ip))</span>
 		return __orc_find(__start_orc_unwind_ip, __start_orc_unwind,
 				  __stop_orc_unwind_ip - __start_orc_unwind_ip, ip);
 
<span class="p_header">diff --git a/arch/x86/kvm/svm.c b/arch/x86/kvm/svm.c</span>
<span class="p_header">index b3e488a74828..24c9521ebc24 100644</span>
<span class="p_header">--- a/arch/x86/kvm/svm.c</span>
<span class="p_header">+++ b/arch/x86/kvm/svm.c</span>
<span class="p_chunk">@@ -49,6 +49,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/debugreg.h&gt;
 #include &lt;asm/kvm_para.h&gt;
 #include &lt;asm/irq_remapping.h&gt;
<span class="p_add">+#include &lt;asm/microcode.h&gt;</span>
 #include &lt;asm/nospec-branch.h&gt;
 
 #include &lt;asm/virtext.h&gt;
<span class="p_chunk">@@ -5355,7 +5356,7 @@</span> <span class="p_context"> static void svm_vcpu_run(struct kvm_vcpu *vcpu)</span>
 	 * being speculatively taken.
 	 */
 	if (svm-&gt;spec_ctrl)
<span class="p_del">-		wrmsrl(MSR_IA32_SPEC_CTRL, svm-&gt;spec_ctrl);</span>
<span class="p_add">+		native_wrmsrl(MSR_IA32_SPEC_CTRL, svm-&gt;spec_ctrl);</span>
 
 	asm volatile (
 		&quot;push %%&quot; _ASM_BP &quot;; \n\t&quot;
<span class="p_chunk">@@ -5464,11 +5465,11 @@</span> <span class="p_context"> static void svm_vcpu_run(struct kvm_vcpu *vcpu)</span>
 	 * If the L02 MSR bitmap does not intercept the MSR, then we need to
 	 * save it.
 	 */
<span class="p_del">-	if (!msr_write_intercepted(vcpu, MSR_IA32_SPEC_CTRL))</span>
<span class="p_del">-		rdmsrl(MSR_IA32_SPEC_CTRL, svm-&gt;spec_ctrl);</span>
<span class="p_add">+	if (unlikely(!msr_write_intercepted(vcpu, MSR_IA32_SPEC_CTRL)))</span>
<span class="p_add">+		svm-&gt;spec_ctrl = native_read_msr(MSR_IA32_SPEC_CTRL);</span>
 
 	if (svm-&gt;spec_ctrl)
<span class="p_del">-		wrmsrl(MSR_IA32_SPEC_CTRL, 0);</span>
<span class="p_add">+		native_wrmsrl(MSR_IA32_SPEC_CTRL, 0);</span>
 
 	/* Eliminate branch target predictions from guest mode */
 	vmexit_fill_RSB();
<span class="p_header">diff --git a/arch/x86/kvm/vmx.c b/arch/x86/kvm/vmx.c</span>
<span class="p_header">index 3dec126aa302..7f8401d05939 100644</span>
<span class="p_header">--- a/arch/x86/kvm/vmx.c</span>
<span class="p_header">+++ b/arch/x86/kvm/vmx.c</span>
<span class="p_chunk">@@ -51,6 +51,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/apic.h&gt;
 #include &lt;asm/irq_remapping.h&gt;
 #include &lt;asm/mmu_context.h&gt;
<span class="p_add">+#include &lt;asm/microcode.h&gt;</span>
 #include &lt;asm/nospec-branch.h&gt;
 
 #include &quot;trace.h&quot;
<span class="p_chunk">@@ -9452,7 +9453,7 @@</span> <span class="p_context"> static void __noclone vmx_vcpu_run(struct kvm_vcpu *vcpu)</span>
 	 * being speculatively taken.
 	 */
 	if (vmx-&gt;spec_ctrl)
<span class="p_del">-		wrmsrl(MSR_IA32_SPEC_CTRL, vmx-&gt;spec_ctrl);</span>
<span class="p_add">+		native_wrmsrl(MSR_IA32_SPEC_CTRL, vmx-&gt;spec_ctrl);</span>
 
 	vmx-&gt;__launched = vmx-&gt;loaded_vmcs-&gt;launched;
 	asm(
<span class="p_chunk">@@ -9587,11 +9588,11 @@</span> <span class="p_context"> static void __noclone vmx_vcpu_run(struct kvm_vcpu *vcpu)</span>
 	 * If the L02 MSR bitmap does not intercept the MSR, then we need to
 	 * save it.
 	 */
<span class="p_del">-	if (!msr_write_intercepted(vcpu, MSR_IA32_SPEC_CTRL))</span>
<span class="p_del">-		rdmsrl(MSR_IA32_SPEC_CTRL, vmx-&gt;spec_ctrl);</span>
<span class="p_add">+	if (unlikely(!msr_write_intercepted(vcpu, MSR_IA32_SPEC_CTRL)))</span>
<span class="p_add">+		vmx-&gt;spec_ctrl = native_read_msr(MSR_IA32_SPEC_CTRL);</span>
 
 	if (vmx-&gt;spec_ctrl)
<span class="p_del">-		wrmsrl(MSR_IA32_SPEC_CTRL, 0);</span>
<span class="p_add">+		native_wrmsrl(MSR_IA32_SPEC_CTRL, 0);</span>
 
 	/* Eliminate branch target predictions from guest mode */
 	vmexit_fill_RSB();
<span class="p_header">diff --git a/arch/x86/lib/Makefile b/arch/x86/lib/Makefile</span>
<span class="p_header">index 91e9700cc6dc..25a972c61b0a 100644</span>
<span class="p_header">--- a/arch/x86/lib/Makefile</span>
<span class="p_header">+++ b/arch/x86/lib/Makefile</span>
<span class="p_chunk">@@ -28,7 +28,6 @@</span> <span class="p_context"> lib-$(CONFIG_INSTRUCTION_DECODER) += insn.o inat.o insn-eval.o</span>
 lib-$(CONFIG_RANDOMIZE_BASE) += kaslr.o
 lib-$(CONFIG_FUNCTION_ERROR_INJECTION)	+= error-inject.o
 lib-$(CONFIG_RETPOLINE) += retpoline.o
<span class="p_del">-OBJECT_FILES_NON_STANDARD_retpoline.o :=y</span>
 
 obj-y += msr.o msr-reg.o msr-reg-export.o hweight.o
 
<span class="p_header">diff --git a/arch/x86/lib/retpoline.S b/arch/x86/lib/retpoline.S</span>
<span class="p_header">index 480edc3a5e03..c909961e678a 100644</span>
<span class="p_header">--- a/arch/x86/lib/retpoline.S</span>
<span class="p_header">+++ b/arch/x86/lib/retpoline.S</span>
<span class="p_chunk">@@ -7,7 +7,6 @@</span> <span class="p_context"></span>
 #include &lt;asm/alternative-asm.h&gt;
 #include &lt;asm/export.h&gt;
 #include &lt;asm/nospec-branch.h&gt;
<span class="p_del">-#include &lt;asm/bitsperlong.h&gt;</span>
 
 .macro THUNK reg
 	.section .text.__x86.indirect_thunk
<span class="p_chunk">@@ -47,58 +46,3 @@</span> <span class="p_context"> GENERATE_THUNK(r13)</span>
 GENERATE_THUNK(r14)
 GENERATE_THUNK(r15)
 #endif
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Fill the CPU return stack buffer.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Each entry in the RSB, if used for a speculative &#39;ret&#39;, contains an</span>
<span class="p_del">- * infinite &#39;pause; lfence; jmp&#39; loop to capture speculative execution.</span>
<span class="p_del">- *</span>
<span class="p_del">- * This is required in various cases for retpoline and IBRS-based</span>
<span class="p_del">- * mitigations for the Spectre variant 2 vulnerability. Sometimes to</span>
<span class="p_del">- * eliminate potentially bogus entries from the RSB, and sometimes</span>
<span class="p_del">- * purely to ensure that it doesn&#39;t get empty, which on some CPUs would</span>
<span class="p_del">- * allow predictions from other (unwanted!) sources to be used.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Google experimented with loop-unrolling and this turned out to be</span>
<span class="p_del">- * the optimal version - two calls, each with their own speculation</span>
<span class="p_del">- * trap should their return address end up getting used, in a loop.</span>
<span class="p_del">- */</span>
<span class="p_del">-.macro STUFF_RSB nr:req sp:req</span>
<span class="p_del">-	mov	$(\nr / 2), %_ASM_BX</span>
<span class="p_del">-	.align 16</span>
<span class="p_del">-771:</span>
<span class="p_del">-	call	772f</span>
<span class="p_del">-773:						/* speculation trap */</span>
<span class="p_del">-	pause</span>
<span class="p_del">-	lfence</span>
<span class="p_del">-	jmp	773b</span>
<span class="p_del">-	.align 16</span>
<span class="p_del">-772:</span>
<span class="p_del">-	call	774f</span>
<span class="p_del">-775:						/* speculation trap */</span>
<span class="p_del">-	pause</span>
<span class="p_del">-	lfence</span>
<span class="p_del">-	jmp	775b</span>
<span class="p_del">-	.align 16</span>
<span class="p_del">-774:</span>
<span class="p_del">-	dec	%_ASM_BX</span>
<span class="p_del">-	jnz	771b</span>
<span class="p_del">-	add	$((BITS_PER_LONG/8) * \nr), \sp</span>
<span class="p_del">-.endm</span>
<span class="p_del">-</span>
<span class="p_del">-#define RSB_FILL_LOOPS		16	/* To avoid underflow */</span>
<span class="p_del">-</span>
<span class="p_del">-ENTRY(__fill_rsb)</span>
<span class="p_del">-	STUFF_RSB RSB_FILL_LOOPS, %_ASM_SP</span>
<span class="p_del">-	ret</span>
<span class="p_del">-END(__fill_rsb)</span>
<span class="p_del">-EXPORT_SYMBOL_GPL(__fill_rsb)</span>
<span class="p_del">-</span>
<span class="p_del">-#define RSB_CLEAR_LOOPS		32	/* To forcibly overwrite all entries */</span>
<span class="p_del">-</span>
<span class="p_del">-ENTRY(__clear_rsb)</span>
<span class="p_del">-	STUFF_RSB RSB_CLEAR_LOOPS, %_ASM_SP</span>
<span class="p_del">-	ret</span>
<span class="p_del">-END(__clear_rsb)</span>
<span class="p_del">-EXPORT_SYMBOL_GPL(__clear_rsb)</span>
<span class="p_header">diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c</span>
<span class="p_header">index 800de815519c..c88573d90f3e 100644</span>
<span class="p_header">--- a/arch/x86/mm/fault.c</span>
<span class="p_header">+++ b/arch/x86/mm/fault.c</span>
<span class="p_chunk">@@ -1248,10 +1248,6 @@</span> <span class="p_context"> __do_page_fault(struct pt_regs *regs, unsigned long error_code,</span>
 	tsk = current;
 	mm = tsk-&gt;mm;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Detect and handle instructions that would cause a page fault for</span>
<span class="p_del">-	 * both a tracked kernel page and a userspace page.</span>
<span class="p_del">-	 */</span>
 	prefetchw(&amp;mm-&gt;mmap_sem);
 
 	if (unlikely(kmmio_fault(regs, address)))
<span class="p_header">diff --git a/arch/x86/mm/mem_encrypt_boot.S b/arch/x86/mm/mem_encrypt_boot.S</span>
<span class="p_header">index 01f682cf77a8..40a6085063d6 100644</span>
<span class="p_header">--- a/arch/x86/mm/mem_encrypt_boot.S</span>
<span class="p_header">+++ b/arch/x86/mm/mem_encrypt_boot.S</span>
<span class="p_chunk">@@ -15,6 +15,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/page.h&gt;
 #include &lt;asm/processor-flags.h&gt;
 #include &lt;asm/msr-index.h&gt;
<span class="p_add">+#include &lt;asm/nospec-branch.h&gt;</span>
 
 	.text
 	.code64
<span class="p_chunk">@@ -59,6 +60,7 @@</span> <span class="p_context"> ENTRY(sme_encrypt_execute)</span>
 	movq	%rax, %r8		/* Workarea encryption routine */
 	addq	$PAGE_SIZE, %r8		/* Workarea intermediate copy buffer */
 
<span class="p_add">+	ANNOTATE_RETPOLINE_SAFE</span>
 	call	*%rax			/* Call the encryption routine */
 
 	pop	%r12
<span class="p_header">diff --git a/arch/x86/realmode/rm/trampoline_64.S b/arch/x86/realmode/rm/trampoline_64.S</span>
<span class="p_header">index de53bd15df5a..24bb7598774e 100644</span>
<span class="p_header">--- a/arch/x86/realmode/rm/trampoline_64.S</span>
<span class="p_header">+++ b/arch/x86/realmode/rm/trampoline_64.S</span>
<span class="p_chunk">@@ -102,7 +102,7 @@</span> <span class="p_context"> ENTRY(startup_32)</span>
 	 * don&#39;t we&#39;ll eventually crash trying to execute encrypted
 	 * instructions.
 	 */
<span class="p_del">-	bt	$TH_FLAGS_SME_ACTIVE_BIT, pa_tr_flags</span>
<span class="p_add">+	btl	$TH_FLAGS_SME_ACTIVE_BIT, pa_tr_flags</span>
 	jnc	.Ldone
 	movl	$MSR_K8_SYSCFG, %ecx
 	rdmsr
<span class="p_header">diff --git a/include/linux/compiler-clang.h b/include/linux/compiler-clang.h</span>
<span class="p_header">index d02a4df3f473..d3f264a5b04d 100644</span>
<span class="p_header">--- a/include/linux/compiler-clang.h</span>
<span class="p_header">+++ b/include/linux/compiler-clang.h</span>
<span class="p_chunk">@@ -27,3 +27,8 @@</span> <span class="p_context"></span>
 #if __has_feature(address_sanitizer)
 #define __SANITIZE_ADDRESS__
 #endif
<span class="p_add">+</span>
<span class="p_add">+/* Clang doesn&#39;t have a way to turn it off per-function, yet. */</span>
<span class="p_add">+#ifdef __noretpoline</span>
<span class="p_add">+#undef __noretpoline</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/include/linux/compiler-gcc.h b/include/linux/compiler-gcc.h</span>
<span class="p_header">index 73bc63e0a1c4..673fbf904fe5 100644</span>
<span class="p_header">--- a/include/linux/compiler-gcc.h</span>
<span class="p_header">+++ b/include/linux/compiler-gcc.h</span>
<span class="p_chunk">@@ -93,6 +93,10 @@</span> <span class="p_context"></span>
 #define __weak		__attribute__((weak))
 #define __alias(symbol)	__attribute__((alias(#symbol)))
 
<span class="p_add">+#ifdef RETPOLINE</span>
<span class="p_add">+#define __noretpoline __attribute__((indirect_branch(&quot;keep&quot;)))</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 /*
  * it doesn&#39;t make sense on ARM (currently the only user of __naked)
  * to trace naked functions because then mcount is called without
<span class="p_header">diff --git a/include/linux/init.h b/include/linux/init.h</span>
<span class="p_header">index 506a98151131..bc27cf03c41e 100644</span>
<span class="p_header">--- a/include/linux/init.h</span>
<span class="p_header">+++ b/include/linux/init.h</span>
<span class="p_chunk">@@ -6,10 +6,10 @@</span> <span class="p_context"></span>
 #include &lt;linux/types.h&gt;
 
 /* Built-in __init functions needn&#39;t be compiled with retpoline */
<span class="p_del">-#if defined(RETPOLINE) &amp;&amp; !defined(MODULE)</span>
<span class="p_del">-#define __noretpoline __attribute__((indirect_branch(&quot;keep&quot;)))</span>
<span class="p_add">+#if defined(__noretpoline) &amp;&amp; !defined(MODULE)</span>
<span class="p_add">+#define __noinitretpoline __noretpoline</span>
 #else
<span class="p_del">-#define __noretpoline</span>
<span class="p_add">+#define __noinitretpoline</span>
 #endif
 
 /* These macros are used to mark some functions or 
<span class="p_chunk">@@ -47,7 +47,7 @@</span> <span class="p_context"></span>
 
 /* These are for everybody (although not all archs will actually
    discard it in modules) */
<span class="p_del">-#define __init		__section(.init.text) __cold  __latent_entropy __noretpoline</span>
<span class="p_add">+#define __init		__section(.init.text) __cold  __latent_entropy __noinitretpoline</span>
 #define __initdata	__section(.init.data)
 #define __initconst	__section(.init.rodata)
 #define __exitdata	__section(.exit.data)
<span class="p_header">diff --git a/include/linux/jump_label.h b/include/linux/jump_label.h</span>
<span class="p_header">index b6a29c126cc4..2168cc6b8b30 100644</span>
<span class="p_header">--- a/include/linux/jump_label.h</span>
<span class="p_header">+++ b/include/linux/jump_label.h</span>
<span class="p_chunk">@@ -151,6 +151,7 @@</span> <span class="p_context"> extern struct jump_entry __start___jump_table[];</span>
 extern struct jump_entry __stop___jump_table[];
 
 extern void jump_label_init(void);
<span class="p_add">+extern void jump_label_invalidate_init(void);</span>
 extern void jump_label_lock(void);
 extern void jump_label_unlock(void);
 extern void arch_jump_label_transform(struct jump_entry *entry,
<span class="p_chunk">@@ -198,6 +199,8 @@</span> <span class="p_context"> static __always_inline void jump_label_init(void)</span>
 	static_key_initialized = true;
 }
 
<span class="p_add">+static inline void jump_label_invalidate_init(void) {}</span>
<span class="p_add">+</span>
 static __always_inline bool static_key_false(struct static_key *key)
 {
 	if (unlikely(static_key_count(key) &gt; 0))
<span class="p_header">diff --git a/include/linux/kernel.h b/include/linux/kernel.h</span>
<span class="p_header">index ce51455e2adf..3fd291503576 100644</span>
<span class="p_header">--- a/include/linux/kernel.h</span>
<span class="p_header">+++ b/include/linux/kernel.h</span>
<span class="p_chunk">@@ -472,6 +472,7 @@</span> <span class="p_context"> extern bool parse_option_str(const char *str, const char *option);</span>
 extern char *next_arg(char *args, char **param, char **val);
 
 extern int core_kernel_text(unsigned long addr);
<span class="p_add">+extern int init_kernel_text(unsigned long addr);</span>
 extern int core_kernel_data(unsigned long addr);
 extern int __kernel_text_address(unsigned long addr);
 extern int kernel_text_address(unsigned long addr);
<span class="p_header">diff --git a/include/linux/nospec.h b/include/linux/nospec.h</span>
<span class="p_header">index fbc98e2c8228..e791ebc65c9c 100644</span>
<span class="p_header">--- a/include/linux/nospec.h</span>
<span class="p_header">+++ b/include/linux/nospec.h</span>
<span class="p_chunk">@@ -5,6 +5,7 @@</span> <span class="p_context"></span>
 
 #ifndef _LINUX_NOSPEC_H
 #define _LINUX_NOSPEC_H
<span class="p_add">+#include &lt;asm/barrier.h&gt;</span>
 
 /**
  * array_index_mask_nospec() - generate a ~0 mask when index &lt; size, 0 otherwise
<span class="p_chunk">@@ -29,26 +30,6 @@</span> <span class="p_context"> static inline unsigned long array_index_mask_nospec(unsigned long index,</span>
 }
 #endif
 
<span class="p_del">-/*</span>
<span class="p_del">- * Warn developers about inappropriate array_index_nospec() usage.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Even if the CPU speculates past the WARN_ONCE branch, the</span>
<span class="p_del">- * sign bit of @index is taken into account when generating the</span>
<span class="p_del">- * mask.</span>
<span class="p_del">- *</span>
<span class="p_del">- * This warning is compiled out when the compiler can infer that</span>
<span class="p_del">- * @index and @size are less than LONG_MAX.</span>
<span class="p_del">- */</span>
<span class="p_del">-#define array_index_mask_nospec_check(index, size)				\</span>
<span class="p_del">-({										\</span>
<span class="p_del">-	if (WARN_ONCE(index &gt; LONG_MAX || size &gt; LONG_MAX,			\</span>
<span class="p_del">-	    &quot;array_index_nospec() limited to range of [0, LONG_MAX]\n&quot;))	\</span>
<span class="p_del">-		_mask = 0;							\</span>
<span class="p_del">-	else									\</span>
<span class="p_del">-		_mask = array_index_mask_nospec(index, size);			\</span>
<span class="p_del">-	_mask;									\</span>
<span class="p_del">-})</span>
<span class="p_del">-</span>
 /*
  * array_index_nospec - sanitize an array index after a bounds check
  *
<span class="p_chunk">@@ -67,12 +48,11 @@</span> <span class="p_context"> static inline unsigned long array_index_mask_nospec(unsigned long index,</span>
 ({									\
 	typeof(index) _i = (index);					\
 	typeof(size) _s = (size);					\
<span class="p_del">-	unsigned long _mask = array_index_mask_nospec_check(_i, _s);	\</span>
<span class="p_add">+	unsigned long _mask = array_index_mask_nospec(_i, _s);		\</span>
 									\
 	BUILD_BUG_ON(sizeof(_i) &gt; sizeof(long));			\
 	BUILD_BUG_ON(sizeof(_s) &gt; sizeof(long));			\
 									\
<span class="p_del">-	_i &amp;= _mask;							\</span>
<span class="p_del">-	_i;								\</span>
<span class="p_add">+	(typeof(_i)) (_i &amp; _mask);					\</span>
 })
 #endif /* _LINUX_NOSPEC_H */
<span class="p_header">diff --git a/init/main.c b/init/main.c</span>
<span class="p_header">index a8100b954839..969eaf140ef0 100644</span>
<span class="p_header">--- a/init/main.c</span>
<span class="p_header">+++ b/init/main.c</span>
<span class="p_chunk">@@ -89,6 +89,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/io.h&gt;
 #include &lt;linux/cache.h&gt;
 #include &lt;linux/rodata_test.h&gt;
<span class="p_add">+#include &lt;linux/jump_label.h&gt;</span>
 
 #include &lt;asm/io.h&gt;
 #include &lt;asm/bugs.h&gt;
<span class="p_chunk">@@ -1000,6 +1001,7 @@</span> <span class="p_context"> static int __ref kernel_init(void *unused)</span>
 	/* need to finish all async __init code before freeing the memory */
 	async_synchronize_full();
 	ftrace_free_init_mem();
<span class="p_add">+	jump_label_invalidate_init();</span>
 	free_initmem();
 	mark_readonly();
 	system_state = SYSTEM_RUNNING;
<span class="p_header">diff --git a/kernel/extable.c b/kernel/extable.c</span>
<span class="p_header">index a17fdb63dc3e..6a5b61ebc66c 100644</span>
<span class="p_header">--- a/kernel/extable.c</span>
<span class="p_header">+++ b/kernel/extable.c</span>
<span class="p_chunk">@@ -64,7 +64,7 @@</span> <span class="p_context"> const struct exception_table_entry *search_exception_tables(unsigned long addr)</span>
 	return e;
 }
 
<span class="p_del">-static inline int init_kernel_text(unsigned long addr)</span>
<span class="p_add">+int init_kernel_text(unsigned long addr)</span>
 {
 	if (addr &gt;= (unsigned long)_sinittext &amp;&amp;
 	    addr &lt; (unsigned long)_einittext)
<span class="p_header">diff --git a/kernel/jump_label.c b/kernel/jump_label.c</span>
<span class="p_header">index b4517095db6a..52a0a7af8640 100644</span>
<span class="p_header">--- a/kernel/jump_label.c</span>
<span class="p_header">+++ b/kernel/jump_label.c</span>
<span class="p_chunk">@@ -366,12 +366,15 @@</span> <span class="p_context"> static void __jump_label_update(struct static_key *key,</span>
 {
 	for (; (entry &lt; stop) &amp;&amp; (jump_entry_key(entry) == key); entry++) {
 		/*
<span class="p_del">-		 * entry-&gt;code set to 0 invalidates module init text sections</span>
<span class="p_del">-		 * kernel_text_address() verifies we are not in core kernel</span>
<span class="p_del">-		 * init code, see jump_label_invalidate_module_init().</span>
<span class="p_add">+		 * An entry-&gt;code of 0 indicates an entry which has been</span>
<span class="p_add">+		 * disabled because it was in an init text area.</span>
 		 */
<span class="p_del">-		if (entry-&gt;code &amp;&amp; kernel_text_address(entry-&gt;code))</span>
<span class="p_del">-			arch_jump_label_transform(entry, jump_label_type(entry));</span>
<span class="p_add">+		if (entry-&gt;code) {</span>
<span class="p_add">+			if (kernel_text_address(entry-&gt;code))</span>
<span class="p_add">+				arch_jump_label_transform(entry, jump_label_type(entry));</span>
<span class="p_add">+			else</span>
<span class="p_add">+				WARN_ONCE(1, &quot;can&#39;t patch jump_label at %pS&quot;, (void *)entry-&gt;code);</span>
<span class="p_add">+		}</span>
 	}
 }
 
<span class="p_chunk">@@ -417,6 +420,19 @@</span> <span class="p_context"> void __init jump_label_init(void)</span>
 	cpus_read_unlock();
 }
 
<span class="p_add">+/* Disable any jump label entries in __init code */</span>
<span class="p_add">+void __init jump_label_invalidate_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct jump_entry *iter_start = __start___jump_table;</span>
<span class="p_add">+	struct jump_entry *iter_stop = __stop___jump_table;</span>
<span class="p_add">+	struct jump_entry *iter;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (iter = iter_start; iter &lt; iter_stop; iter++) {</span>
<span class="p_add">+		if (init_kernel_text(iter-&gt;code))</span>
<span class="p_add">+			iter-&gt;code = 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #ifdef CONFIG_MODULES
 
 static enum jump_label_type jump_label_init_type(struct jump_entry *entry)
<span class="p_chunk">@@ -633,6 +649,7 @@</span> <span class="p_context"> static void jump_label_del_module(struct module *mod)</span>
 	}
 }
 
<span class="p_add">+/* Disable any jump label entries in module init code */</span>
 static void jump_label_invalidate_module_init(struct module *mod)
 {
 	struct jump_entry *iter_start = mod-&gt;jump_entries;
<span class="p_header">diff --git a/scripts/Makefile.build b/scripts/Makefile.build</span>
<span class="p_header">index 47cddf32aeba..4f2b25d43ec9 100644</span>
<span class="p_header">--- a/scripts/Makefile.build</span>
<span class="p_header">+++ b/scripts/Makefile.build</span>
<span class="p_chunk">@@ -256,6 +256,8 @@</span> <span class="p_context"> __objtool_obj := $(objtree)/tools/objtool/objtool</span>
 
 objtool_args = $(if $(CONFIG_UNWINDER_ORC),orc generate,check)
 
<span class="p_add">+objtool_args += $(if $(part-of-module), --module,)</span>
<span class="p_add">+</span>
 ifndef CONFIG_FRAME_POINTER
 objtool_args += --no-fp
 endif
<span class="p_chunk">@@ -264,6 +266,12 @@</span> <span class="p_context"> objtool_args += --no-unreachable</span>
 else
 objtool_args += $(call cc-ifversion, -lt, 0405, --no-unreachable)
 endif
<span class="p_add">+ifdef CONFIG_RETPOLINE</span>
<span class="p_add">+ifneq ($(RETPOLINE_CFLAGS),)</span>
<span class="p_add">+  objtool_args += --retpoline</span>
<span class="p_add">+endif</span>
<span class="p_add">+endif</span>
<span class="p_add">+</span>
 
 ifdef CONFIG_MODVERSIONS
 objtool_o = $(@D)/.tmp_$(@F)
<span class="p_header">diff --git a/tools/objtool/builtin-check.c b/tools/objtool/builtin-check.c</span>
<span class="p_header">index 57254f5b2779..694abc628e9b 100644</span>
<span class="p_header">--- a/tools/objtool/builtin-check.c</span>
<span class="p_header">+++ b/tools/objtool/builtin-check.c</span>
<span class="p_chunk">@@ -29,7 +29,7 @@</span> <span class="p_context"></span>
 #include &quot;builtin.h&quot;
 #include &quot;check.h&quot;
 
<span class="p_del">-bool no_fp, no_unreachable;</span>
<span class="p_add">+bool no_fp, no_unreachable, retpoline, module;</span>
 
 static const char * const check_usage[] = {
 	&quot;objtool check [&lt;options&gt;] file.o&quot;,
<span class="p_chunk">@@ -39,6 +39,8 @@</span> <span class="p_context"> static const char * const check_usage[] = {</span>
 const struct option check_options[] = {
 	OPT_BOOLEAN(&#39;f&#39;, &quot;no-fp&quot;, &amp;no_fp, &quot;Skip frame pointer validation&quot;),
 	OPT_BOOLEAN(&#39;u&#39;, &quot;no-unreachable&quot;, &amp;no_unreachable, &quot;Skip &#39;unreachable instruction&#39; warnings&quot;),
<span class="p_add">+	OPT_BOOLEAN(&#39;r&#39;, &quot;retpoline&quot;, &amp;retpoline, &quot;Validate retpoline assumptions&quot;),</span>
<span class="p_add">+	OPT_BOOLEAN(&#39;m&#39;, &quot;module&quot;, &amp;module, &quot;Indicates the object will be part of a kernel module&quot;),</span>
 	OPT_END(),
 };
 
<span class="p_chunk">@@ -53,5 +55,5 @@</span> <span class="p_context"> int cmd_check(int argc, const char **argv)</span>
 
 	objname = argv[0];
 
<span class="p_del">-	return check(objname, no_fp, no_unreachable, false);</span>
<span class="p_add">+	return check(objname, false);</span>
 }
<span class="p_header">diff --git a/tools/objtool/builtin-orc.c b/tools/objtool/builtin-orc.c</span>
<span class="p_header">index 91e8e19ff5e0..77ea2b97117d 100644</span>
<span class="p_header">--- a/tools/objtool/builtin-orc.c</span>
<span class="p_header">+++ b/tools/objtool/builtin-orc.c</span>
<span class="p_chunk">@@ -25,7 +25,6 @@</span> <span class="p_context"></span>
  */
 
 #include &lt;string.h&gt;
<span class="p_del">-#include &lt;subcmd/parse-options.h&gt;</span>
 #include &quot;builtin.h&quot;
 #include &quot;check.h&quot;
 
<span class="p_chunk">@@ -36,9 +35,6 @@</span> <span class="p_context"> static const char *orc_usage[] = {</span>
 	NULL,
 };
 
<span class="p_del">-extern const struct option check_options[];</span>
<span class="p_del">-extern bool no_fp, no_unreachable;</span>
<span class="p_del">-</span>
 int cmd_orc(int argc, const char **argv)
 {
 	const char *objname;
<span class="p_chunk">@@ -54,7 +50,7 @@</span> <span class="p_context"> int cmd_orc(int argc, const char **argv)</span>
 
 		objname = argv[0];
 
<span class="p_del">-		return check(objname, no_fp, no_unreachable, true);</span>
<span class="p_add">+		return check(objname, true);</span>
 	}
 
 	if (!strcmp(argv[0], &quot;dump&quot;)) {
<span class="p_header">diff --git a/tools/objtool/builtin.h b/tools/objtool/builtin.h</span>
<span class="p_header">index dd526067fed5..28ff40e19a14 100644</span>
<span class="p_header">--- a/tools/objtool/builtin.h</span>
<span class="p_header">+++ b/tools/objtool/builtin.h</span>
<span class="p_chunk">@@ -17,6 +17,11 @@</span> <span class="p_context"></span>
 #ifndef _BUILTIN_H
 #define _BUILTIN_H
 
<span class="p_add">+#include &lt;subcmd/parse-options.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+extern const struct option check_options[];</span>
<span class="p_add">+extern bool no_fp, no_unreachable, retpoline, module;</span>
<span class="p_add">+</span>
 extern int cmd_check(int argc, const char **argv);
 extern int cmd_orc(int argc, const char **argv);
 
<span class="p_header">diff --git a/tools/objtool/check.c b/tools/objtool/check.c</span>
<span class="p_header">index a8cb69a26576..472e64e95891 100644</span>
<span class="p_header">--- a/tools/objtool/check.c</span>
<span class="p_header">+++ b/tools/objtool/check.c</span>
<span class="p_chunk">@@ -18,6 +18,7 @@</span> <span class="p_context"></span>
 #include &lt;string.h&gt;
 #include &lt;stdlib.h&gt;
 
<span class="p_add">+#include &quot;builtin.h&quot;</span>
 #include &quot;check.h&quot;
 #include &quot;elf.h&quot;
 #include &quot;special.h&quot;
<span class="p_chunk">@@ -33,7 +34,6 @@</span> <span class="p_context"> struct alternative {</span>
 };
 
 const char *objname;
<span class="p_del">-static bool no_fp;</span>
 struct cfi_state initial_func_cfi;
 
 struct instruction *find_insn(struct objtool_file *file,
<span class="p_chunk">@@ -497,6 +497,7 @@</span> <span class="p_context"> static int add_jump_destinations(struct objtool_file *file)</span>
 			 * disguise, so convert them accordingly.
 			 */
 			insn-&gt;type = INSN_JUMP_DYNAMIC;
<span class="p_add">+			insn-&gt;retpoline_safe = true;</span>
 			continue;
 		} else {
 			/* sibling call */
<span class="p_chunk">@@ -548,7 +549,8 @@</span> <span class="p_context"> static int add_call_destinations(struct objtool_file *file)</span>
 			if (!insn-&gt;call_dest &amp;&amp; !insn-&gt;ignore) {
 				WARN_FUNC(&quot;unsupported intra-function call&quot;,
 					  insn-&gt;sec, insn-&gt;offset);
<span class="p_del">-				WARN(&quot;If this is a retpoline, please patch it in with alternatives and annotate it with ANNOTATE_NOSPEC_ALTERNATIVE.&quot;);</span>
<span class="p_add">+				if (retpoline)</span>
<span class="p_add">+					WARN(&quot;If this is a retpoline, please patch it in with alternatives and annotate it with ANNOTATE_NOSPEC_ALTERNATIVE.&quot;);</span>
 				return -1;
 			}
 
<span class="p_chunk">@@ -1108,6 +1110,54 @@</span> <span class="p_context"> static int read_unwind_hints(struct objtool_file *file)</span>
 	return 0;
 }
 
<span class="p_add">+static int read_retpoline_hints(struct objtool_file *file)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct section *sec, *relasec;</span>
<span class="p_add">+	struct instruction *insn;</span>
<span class="p_add">+	struct rela *rela;</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	sec = find_section_by_name(file-&gt;elf, &quot;.discard.retpoline_safe&quot;);</span>
<span class="p_add">+	if (!sec)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	relasec = sec-&gt;rela;</span>
<span class="p_add">+	if (!relasec) {</span>
<span class="p_add">+		WARN(&quot;missing .rela.discard.retpoline_safe section&quot;);</span>
<span class="p_add">+		return -1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sec-&gt;len % sizeof(unsigned long)) {</span>
<span class="p_add">+		WARN(&quot;retpoline_safe size mismatch: %d %ld&quot;, sec-&gt;len, sizeof(unsigned long));</span>
<span class="p_add">+		return -1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; sec-&gt;len / sizeof(unsigned long); i++) {</span>
<span class="p_add">+		rela = find_rela_by_dest(sec, i * sizeof(unsigned long));</span>
<span class="p_add">+		if (!rela) {</span>
<span class="p_add">+			WARN(&quot;can&#39;t find rela for retpoline_safe[%d]&quot;, i);</span>
<span class="p_add">+			return -1;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		insn = find_insn(file, rela-&gt;sym-&gt;sec, rela-&gt;addend);</span>
<span class="p_add">+		if (!insn) {</span>
<span class="p_add">+			WARN(&quot;can&#39;t find insn for retpoline_safe[%d]&quot;, i);</span>
<span class="p_add">+			return -1;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		if (insn-&gt;type != INSN_JUMP_DYNAMIC &amp;&amp;</span>
<span class="p_add">+		    insn-&gt;type != INSN_CALL_DYNAMIC) {</span>
<span class="p_add">+			WARN_FUNC(&quot;retpoline_safe hint not a indirect jump/call&quot;,</span>
<span class="p_add">+				  insn-&gt;sec, insn-&gt;offset);</span>
<span class="p_add">+			return -1;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		insn-&gt;retpoline_safe = true;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int decode_sections(struct objtool_file *file)
 {
 	int ret;
<span class="p_chunk">@@ -1146,6 +1196,10 @@</span> <span class="p_context"> static int decode_sections(struct objtool_file *file)</span>
 	if (ret)
 		return ret;
 
<span class="p_add">+	ret = read_retpoline_hints(file);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -1891,6 +1945,38 @@</span> <span class="p_context"> static int validate_unwind_hints(struct objtool_file *file)</span>
 	return warnings;
 }
 
<span class="p_add">+static int validate_retpoline(struct objtool_file *file)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct instruction *insn;</span>
<span class="p_add">+	int warnings = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	for_each_insn(file, insn) {</span>
<span class="p_add">+		if (insn-&gt;type != INSN_JUMP_DYNAMIC &amp;&amp;</span>
<span class="p_add">+		    insn-&gt;type != INSN_CALL_DYNAMIC)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (insn-&gt;retpoline_safe)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * .init.text code is ran before userspace and thus doesn&#39;t</span>
<span class="p_add">+		 * strictly need retpolines, except for modules which are</span>
<span class="p_add">+		 * loaded late, they very much do need retpoline in their</span>
<span class="p_add">+		 * .init.text</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (!strcmp(insn-&gt;sec-&gt;name, &quot;.init.text&quot;) &amp;&amp; !module)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		WARN_FUNC(&quot;indirect %s found in RETPOLINE build&quot;,</span>
<span class="p_add">+			  insn-&gt;sec, insn-&gt;offset,</span>
<span class="p_add">+			  insn-&gt;type == INSN_JUMP_DYNAMIC ? &quot;jump&quot; : &quot;call&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+		warnings++;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return warnings;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static bool is_kasan_insn(struct instruction *insn)
 {
 	return (insn-&gt;type == INSN_CALL &amp;&amp;
<span class="p_chunk">@@ -2022,13 +2108,12 @@</span> <span class="p_context"> static void cleanup(struct objtool_file *file)</span>
 	elf_close(file-&gt;elf);
 }
 
<span class="p_del">-int check(const char *_objname, bool _no_fp, bool no_unreachable, bool orc)</span>
<span class="p_add">+int check(const char *_objname, bool orc)</span>
 {
 	struct objtool_file file;
 	int ret, warnings = 0;
 
 	objname = _objname;
<span class="p_del">-	no_fp = _no_fp;</span>
 
 	file.elf = elf_open(objname, orc ? O_RDWR : O_RDONLY);
 	if (!file.elf)
<span class="p_chunk">@@ -2052,6 +2137,13 @@</span> <span class="p_context"> int check(const char *_objname, bool _no_fp, bool no_unreachable, bool orc)</span>
 	if (list_empty(&amp;file.insn_list))
 		goto out;
 
<span class="p_add">+	if (retpoline) {</span>
<span class="p_add">+		ret = validate_retpoline(&amp;file);</span>
<span class="p_add">+		if (ret &lt; 0)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+		warnings += ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	ret = validate_functions(&amp;file);
 	if (ret &lt; 0)
 		goto out;
<span class="p_header">diff --git a/tools/objtool/check.h b/tools/objtool/check.h</span>
<span class="p_header">index 23a1d065cae1..c6b68fcb926f 100644</span>
<span class="p_header">--- a/tools/objtool/check.h</span>
<span class="p_header">+++ b/tools/objtool/check.h</span>
<span class="p_chunk">@@ -45,6 +45,7 @@</span> <span class="p_context"> struct instruction {</span>
 	unsigned char type;
 	unsigned long immediate;
 	bool alt_group, visited, dead_end, ignore, hint, save, restore, ignore_alts;
<span class="p_add">+	bool retpoline_safe;</span>
 	struct symbol *call_dest;
 	struct instruction *jump_dest;
 	struct instruction *first_jump_src;
<span class="p_chunk">@@ -63,7 +64,7 @@</span> <span class="p_context"> struct objtool_file {</span>
 	bool ignore_unreachables, c_file, hints;
 };
 
<span class="p_del">-int check(const char *objname, bool no_fp, bool no_unreachable, bool orc);</span>
<span class="p_add">+int check(const char *objname, bool orc);</span>
 
 struct instruction *find_insn(struct objtool_file *file,
 			      struct section *sec, unsigned long offset);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



