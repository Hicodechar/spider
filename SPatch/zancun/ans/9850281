
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[11/17] lib/interval_tree: fast overlap detection - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [11/17] lib/interval_tree: fast overlap detection</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=106071">Davidlohr Bueso</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>July 19, 2017, 1:45 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170719014603.19029-12-dave@stgolabs.net&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9850281/mbox/"
   >mbox</a>
|
   <a href="/patch/9850281/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9850281/">/patch/9850281/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	2F7A560392 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 19 Jul 2017 01:47:26 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 18C4B285EE
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 19 Jul 2017 01:47:26 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 0BB2B28606; Wed, 19 Jul 2017 01:47:26 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id B1A07285F2
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 19 Jul 2017 01:47:23 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753034AbdGSBrV (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 18 Jul 2017 21:47:21 -0400
Received: from smtp2.provo.novell.com ([137.65.250.81]:56870 &quot;EHLO
	smtp2.provo.novell.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752739AbdGSBrR (ORCPT
	&lt;rfc822;groupwise-linux-kernel@vger.kernel.org:0:0&gt;);
	Tue, 18 Jul 2017 21:47:17 -0400
Received: from linux-80c1.suse (prv-ext-foundry1int.gns.novell.com
	[137.65.251.240])
	by smtp2.provo.novell.com with ESMTP (TLS encrypted);
	Tue, 18 Jul 2017 19:47:08 -0600
From: Davidlohr Bueso &lt;dave@stgolabs.net&gt;
To: akpm@linux-foundation.org
Cc: mingo@kernel.org, peterz@infradead.org, jack@suse.cz,
	torvalds@linux-foundation.org, kirill.shutemov@linux.intel.com,
	hch@infradead.org, ldufour@linux.vnet.ibm.com, mhocko@suse.com,
	mgorman@techsingularity.net, dave@stgolabs.net,
	linux-kernel@vger.kernel.org, David Airlie &lt;airlied@linux.ie&gt;,
	dri-devel@lists.freedesktop.org, &quot;Michael S. Tsirkin&quot; &lt;mst@redhat.com&gt;,
	Jason Wang &lt;jasowang@redhat.com&gt;, Doug Ledford &lt;dledford@redhat.com&gt;,
	Christian Benvenuti &lt;benve@cisco.com&gt;,
	linux-rdma@vger.kernel.org, Davidlohr Bueso &lt;dbueso@suse.de&gt;
Subject: [PATCH 11/17] lib/interval_tree: fast overlap detection
Date: Tue, 18 Jul 2017 18:45:57 -0700
Message-Id: &lt;20170719014603.19029-12-dave@stgolabs.net&gt;
X-Mailer: git-send-email 2.12.0
In-Reply-To: &lt;20170719014603.19029-1-dave@stgolabs.net&gt;
References: &lt;20170719014603.19029-1-dave@stgolabs.net&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=106071">Davidlohr Bueso</a> - July 19, 2017, 1:45 a.m.</div>
<pre class="content">
Allow interval trees to quickly check for overlaps to avoid
unnecesary tree lookups in interval_tree_iter_first().

As of this patch, all interval tree flavors will require
using a &#39;rb_root_cached&#39; such that we can have the leftmost
node easily available. While most users will make use of this
feature, those with special functions (in addition to the generic
insert, delete, search calls) will avoid using the cached
option as they can do funky things with insertions -- for example,
vma_interval_tree_insert_after().

Cc: David Airlie &lt;airlied@linux.ie&gt;
Cc: dri-devel@lists.freedesktop.org
Cc: &quot;Michael S. Tsirkin&quot; &lt;mst@redhat.com&gt;
Cc: Jason Wang &lt;jasowang@redhat.com&gt;
Cc: Doug Ledford &lt;dledford@redhat.com&gt;
Cc: Christian Benvenuti &lt;benve@cisco.com&gt;
Cc: linux-rdma@vger.kernel.org
<span class="acked-by">Acked-by: Christian König &lt;christian.koenig@amd.com&gt;</span>
<span class="acked-by">Acked-by: Peter Zijlstra (Intel) &lt;peterz@infradead.org&gt;</span>
<span class="signed-off-by">Signed-off-by: Davidlohr Bueso &lt;dbueso@suse.de&gt;</span>
---
 drivers/gpu/drm/amd/amdgpu/amdgpu_mn.c             |  8 ++--
 drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c             |  7 ++--
 drivers/gpu/drm/amd/amdgpu/amdgpu_vm.h             |  2 +-
 drivers/gpu/drm/drm_mm.c                           | 19 +++++----
 drivers/gpu/drm/drm_vma_manager.c                  |  2 +-
 drivers/gpu/drm/i915/i915_gem_userptr.c            |  6 +--
 drivers/gpu/drm/radeon/radeon.h                    |  2 +-
 drivers/gpu/drm/radeon/radeon_mn.c                 |  8 ++--
 drivers/gpu/drm/radeon/radeon_vm.c                 |  7 ++--
 drivers/infiniband/core/umem_rbtree.c              |  4 +-
 drivers/infiniband/core/uverbs_cmd.c               |  2 +-
 drivers/infiniband/hw/hfi1/mmu_rb.c                | 10 ++---
 drivers/infiniband/hw/usnic/usnic_uiom.c           |  6 +--
 drivers/infiniband/hw/usnic/usnic_uiom.h           |  2 +-
 .../infiniband/hw/usnic/usnic_uiom_interval_tree.c | 15 +++----
 .../infiniband/hw/usnic/usnic_uiom_interval_tree.h | 12 +++---
 drivers/vhost/vhost.c                              |  2 +-
 drivers/vhost/vhost.h                              |  2 +-
 fs/hugetlbfs/inode.c                               |  6 +--
 fs/inode.c                                         |  2 +-
 include/drm/drm_mm.h                               |  2 +-
 include/linux/fs.h                                 |  4 +-
 include/linux/interval_tree.h                      |  8 ++--
 include/linux/interval_tree_generic.h              | 46 +++++++++++++++++-----
 include/linux/mm.h                                 | 17 ++++----
 include/linux/rmap.h                               |  4 +-
 include/rdma/ib_umem_odp.h                         | 11 ++++--
 include/rdma/ib_verbs.h                            |  2 +-
 lib/interval_tree_test.c                           |  4 +-
 mm/interval_tree.c                                 | 10 ++---
 mm/memory.c                                        |  4 +-
 mm/mmap.c                                          | 10 ++---
 mm/rmap.c                                          |  4 +-
 33 files changed, 145 insertions(+), 105 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2717">Doug Ledford</a> - July 22, 2017, 5:52 p.m.</div>
<pre class="content">
On 7/18/2017 9:45 PM, Davidlohr Bueso wrote:
<span class="quote">&gt; Allow interval trees to quickly check for overlaps to avoid</span>
<span class="quote">&gt; unnecesary tree lookups in interval_tree_iter_first().</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; As of this patch, all interval tree flavors will require</span>
<span class="quote">&gt; using a &#39;rb_root_cached&#39; such that we can have the leftmost</span>
<span class="quote">&gt; node easily available. While most users will make use of this</span>
<span class="quote">&gt; feature, those with special functions (in addition to the generic</span>
<span class="quote">&gt; insert, delete, search calls) will avoid using the cached</span>
<span class="quote">&gt; option as they can do funky things with insertions -- for example,</span>
<span class="quote">&gt; vma_interval_tree_insert_after().</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: David Airlie &lt;airlied@linux.ie&gt;</span>
<span class="quote">&gt; Cc: dri-devel@lists.freedesktop.org</span>
<span class="quote">&gt; Cc: &quot;Michael S. Tsirkin&quot; &lt;mst@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Jason Wang &lt;jasowang@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Doug Ledford &lt;dledford@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Christian Benvenuti &lt;benve@cisco.com&gt;</span>
<span class="quote">&gt; Cc: linux-rdma@vger.kernel.org</span>
<span class="quote">&gt; Acked-by: Christian König &lt;christian.koenig@amd.com&gt;</span>
<span class="quote">&gt; Acked-by: Peter Zijlstra (Intel) &lt;peterz@infradead.org&gt;</span>
<span class="quote">&gt; Signed-off-by: Davidlohr Bueso &lt;dbueso@suse.de&gt;</span>

Ack for the RDMA parts.
<span class="acked-by">
Acked-by: Doug Ledford &lt;dledford@redhat.com&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=1984">Michael S. Tsirkin</a> - Aug. 1, 2017, 5:16 p.m.</div>
<pre class="content">
On Tue, Jul 18, 2017 at 06:45:57PM -0700, Davidlohr Bueso wrote:
<span class="quote">&gt; Allow interval trees to quickly check for overlaps to avoid</span>
<span class="quote">&gt; unnecesary tree lookups in interval_tree_iter_first().</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; As of this patch, all interval tree flavors will require</span>
<span class="quote">&gt; using a &#39;rb_root_cached&#39; such that we can have the leftmost</span>
<span class="quote">&gt; node easily available. While most users will make use of this</span>
<span class="quote">&gt; feature, those with special functions (in addition to the generic</span>
<span class="quote">&gt; insert, delete, search calls) will avoid using the cached</span>
<span class="quote">&gt; option as they can do funky things with insertions -- for example,</span>
<span class="quote">&gt; vma_interval_tree_insert_after().</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: David Airlie &lt;airlied@linux.ie&gt;</span>
<span class="quote">&gt; Cc: dri-devel@lists.freedesktop.org</span>
<span class="quote">&gt; Cc: &quot;Michael S. Tsirkin&quot; &lt;mst@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Jason Wang &lt;jasowang@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Doug Ledford &lt;dledford@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Christian Benvenuti &lt;benve@cisco.com&gt;</span>
<span class="quote">&gt; Cc: linux-rdma@vger.kernel.org</span>
<span class="quote">&gt; Acked-by: Christian König &lt;christian.koenig@amd.com&gt;</span>
<span class="quote">&gt; Acked-by: Peter Zijlstra (Intel) &lt;peterz@infradead.org&gt;</span>
<span class="quote">&gt; Signed-off-by: Davidlohr Bueso &lt;dbueso@suse.de&gt;</span>

For vhost bits:
<span class="acked-by">
Acked-by: Michael S. Tsirkin &lt;mst@redhat.com&gt;</span>
<span class="quote">

&gt; ---</span>
<span class="quote">&gt;  drivers/gpu/drm/amd/amdgpu/amdgpu_mn.c             |  8 ++--</span>
<span class="quote">&gt;  drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c             |  7 ++--</span>
<span class="quote">&gt;  drivers/gpu/drm/amd/amdgpu/amdgpu_vm.h             |  2 +-</span>
<span class="quote">&gt;  drivers/gpu/drm/drm_mm.c                           | 19 +++++----</span>
<span class="quote">&gt;  drivers/gpu/drm/drm_vma_manager.c                  |  2 +-</span>
<span class="quote">&gt;  drivers/gpu/drm/i915/i915_gem_userptr.c            |  6 +--</span>
<span class="quote">&gt;  drivers/gpu/drm/radeon/radeon.h                    |  2 +-</span>
<span class="quote">&gt;  drivers/gpu/drm/radeon/radeon_mn.c                 |  8 ++--</span>
<span class="quote">&gt;  drivers/gpu/drm/radeon/radeon_vm.c                 |  7 ++--</span>
<span class="quote">&gt;  drivers/infiniband/core/umem_rbtree.c              |  4 +-</span>
<span class="quote">&gt;  drivers/infiniband/core/uverbs_cmd.c               |  2 +-</span>
<span class="quote">&gt;  drivers/infiniband/hw/hfi1/mmu_rb.c                | 10 ++---</span>
<span class="quote">&gt;  drivers/infiniband/hw/usnic/usnic_uiom.c           |  6 +--</span>
<span class="quote">&gt;  drivers/infiniband/hw/usnic/usnic_uiom.h           |  2 +-</span>
<span class="quote">&gt;  .../infiniband/hw/usnic/usnic_uiom_interval_tree.c | 15 +++----</span>
<span class="quote">&gt;  .../infiniband/hw/usnic/usnic_uiom_interval_tree.h | 12 +++---</span>
<span class="quote">&gt;  drivers/vhost/vhost.c                              |  2 +-</span>
<span class="quote">&gt;  drivers/vhost/vhost.h                              |  2 +-</span>
<span class="quote">&gt;  fs/hugetlbfs/inode.c                               |  6 +--</span>
<span class="quote">&gt;  fs/inode.c                                         |  2 +-</span>
<span class="quote">&gt;  include/drm/drm_mm.h                               |  2 +-</span>
<span class="quote">&gt;  include/linux/fs.h                                 |  4 +-</span>
<span class="quote">&gt;  include/linux/interval_tree.h                      |  8 ++--</span>
<span class="quote">&gt;  include/linux/interval_tree_generic.h              | 46 +++++++++++++++++-----</span>
<span class="quote">&gt;  include/linux/mm.h                                 | 17 ++++----</span>
<span class="quote">&gt;  include/linux/rmap.h                               |  4 +-</span>
<span class="quote">&gt;  include/rdma/ib_umem_odp.h                         | 11 ++++--</span>
<span class="quote">&gt;  include/rdma/ib_verbs.h                            |  2 +-</span>
<span class="quote">&gt;  lib/interval_tree_test.c                           |  4 +-</span>
<span class="quote">&gt;  mm/interval_tree.c                                 | 10 ++---</span>
<span class="quote">&gt;  mm/memory.c                                        |  4 +-</span>
<span class="quote">&gt;  mm/mmap.c                                          | 10 ++---</span>
<span class="quote">&gt;  mm/rmap.c                                          |  4 +-</span>
<span class="quote">&gt;  33 files changed, 145 insertions(+), 105 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_mn.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_mn.c</span>
<span class="quote">&gt; index 38f739fb727b..3f8aef21b9a6 100644</span>
<span class="quote">&gt; --- a/drivers/gpu/drm/amd/amdgpu/amdgpu_mn.c</span>
<span class="quote">&gt; +++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_mn.c</span>
<span class="quote">&gt; @@ -51,7 +51,7 @@ struct amdgpu_mn {</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* objects protected by lock */</span>
<span class="quote">&gt;  	struct mutex		lock;</span>
<span class="quote">&gt; -	struct rb_root		objects;</span>
<span class="quote">&gt; +	struct rb_root_cached	objects;</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  struct amdgpu_mn_node {</span>
<span class="quote">&gt; @@ -76,8 +76,8 @@ static void amdgpu_mn_destroy(struct work_struct *work)</span>
<span class="quote">&gt;  	mutex_lock(&amp;adev-&gt;mn_lock);</span>
<span class="quote">&gt;  	mutex_lock(&amp;rmn-&gt;lock);</span>
<span class="quote">&gt;  	hash_del(&amp;rmn-&gt;node);</span>
<span class="quote">&gt; -	rbtree_postorder_for_each_entry_safe(node, next_node, &amp;rmn-&gt;objects,</span>
<span class="quote">&gt; -					     it.rb) {</span>
<span class="quote">&gt; +	rbtree_postorder_for_each_entry_safe(node, next_node,</span>
<span class="quote">&gt; +					     &amp;rmn-&gt;objects.rb_root, it.rb) {</span>
<span class="quote">&gt;  		list_for_each_entry_safe(bo, next_bo, &amp;node-&gt;bos, mn_list) {</span>
<span class="quote">&gt;  			bo-&gt;mn = NULL;</span>
<span class="quote">&gt;  			list_del_init(&amp;bo-&gt;mn_list);</span>
<span class="quote">&gt; @@ -252,7 +252,7 @@ static struct amdgpu_mn *amdgpu_mn_get(struct amdgpu_device *adev)</span>
<span class="quote">&gt;  	rmn-&gt;mm = mm;</span>
<span class="quote">&gt;  	rmn-&gt;mn.ops = &amp;amdgpu_mn_ops;</span>
<span class="quote">&gt;  	mutex_init(&amp;rmn-&gt;lock);</span>
<span class="quote">&gt; -	rmn-&gt;objects = RB_ROOT;</span>
<span class="quote">&gt; +	rmn-&gt;objects = RB_ROOT_CACHED;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	r = __mmu_notifier_register(&amp;rmn-&gt;mn, mm);</span>
<span class="quote">&gt;  	if (r)</span>
<span class="quote">&gt; diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c</span>
<span class="quote">&gt; index 5795f81369f0..f872e2179bbd 100644</span>
<span class="quote">&gt; --- a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c</span>
<span class="quote">&gt; +++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c</span>
<span class="quote">&gt; @@ -2405,7 +2405,7 @@ int amdgpu_vm_init(struct amdgpu_device *adev, struct amdgpu_vm *vm,</span>
<span class="quote">&gt;  	int r, i;</span>
<span class="quote">&gt;  	u64 flags;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	vm-&gt;va = RB_ROOT;</span>
<span class="quote">&gt; +	vm-&gt;va = RB_ROOT_CACHED;</span>
<span class="quote">&gt;  	vm-&gt;client_id = atomic64_inc_return(&amp;adev-&gt;vm_manager.client_counter);</span>
<span class="quote">&gt;  	for (i = 0; i &lt; AMDGPU_MAX_VMHUBS; i++)</span>
<span class="quote">&gt;  		vm-&gt;reserved_vmid[i] = NULL;</span>
<span class="quote">&gt; @@ -2512,10 +2512,11 @@ void amdgpu_vm_fini(struct amdgpu_device *adev, struct amdgpu_vm *vm)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	amd_sched_entity_fini(vm-&gt;entity.sched, &amp;vm-&gt;entity);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (!RB_EMPTY_ROOT(&amp;vm-&gt;va)) {</span>
<span class="quote">&gt; +	if (!RB_EMPTY_ROOT(&amp;vm-&gt;va.rb_root)) {</span>
<span class="quote">&gt;  		dev_err(adev-&gt;dev, &quot;still active bo inside vm\n&quot;);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; -	rbtree_postorder_for_each_entry_safe(mapping, tmp, &amp;vm-&gt;va, rb) {</span>
<span class="quote">&gt; +	rbtree_postorder_for_each_entry_safe(mapping, tmp,</span>
<span class="quote">&gt; +					     &amp;vm-&gt;va.rb_root, rb) {</span>
<span class="quote">&gt;  		list_del(&amp;mapping-&gt;list);</span>
<span class="quote">&gt;  		amdgpu_vm_it_remove(mapping, &amp;vm-&gt;va);</span>
<span class="quote">&gt;  		kfree(mapping);</span>
<span class="quote">&gt; diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.h b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.h</span>
<span class="quote">&gt; index 936f158bc5ec..ebffc1253f85 100644</span>
<span class="quote">&gt; --- a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.h</span>
<span class="quote">&gt; +++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.h</span>
<span class="quote">&gt; @@ -106,7 +106,7 @@ struct amdgpu_vm_pt {</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  struct amdgpu_vm {</span>
<span class="quote">&gt;  	/* tree of virtual addresses mapped */</span>
<span class="quote">&gt; -	struct rb_root		va;</span>
<span class="quote">&gt; +	struct rb_root_cached	va;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* protecting invalidated */</span>
<span class="quote">&gt;  	spinlock_t		status_lock;</span>
<span class="quote">&gt; diff --git a/drivers/gpu/drm/drm_mm.c b/drivers/gpu/drm/drm_mm.c</span>
<span class="quote">&gt; index f794089d30ac..61a1c8ea74bc 100644</span>
<span class="quote">&gt; --- a/drivers/gpu/drm/drm_mm.c</span>
<span class="quote">&gt; +++ b/drivers/gpu/drm/drm_mm.c</span>
<span class="quote">&gt; @@ -169,7 +169,7 @@ INTERVAL_TREE_DEFINE(struct drm_mm_node, rb,</span>
<span class="quote">&gt;  struct drm_mm_node *</span>
<span class="quote">&gt;  __drm_mm_interval_first(const struct drm_mm *mm, u64 start, u64 last)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	return drm_mm_interval_tree_iter_first((struct rb_root *)&amp;mm-&gt;interval_tree,</span>
<span class="quote">&gt; +	return drm_mm_interval_tree_iter_first((struct rb_root_cached *)&amp;mm-&gt;interval_tree,</span>
<span class="quote">&gt;  					       start, last) ?: (struct drm_mm_node *)&amp;mm-&gt;head_node;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  EXPORT_SYMBOL(__drm_mm_interval_first);</span>
<span class="quote">&gt; @@ -180,6 +180,7 @@ static void drm_mm_interval_tree_add_node(struct drm_mm_node *hole_node,</span>
<span class="quote">&gt;  	struct drm_mm *mm = hole_node-&gt;mm;</span>
<span class="quote">&gt;  	struct rb_node **link, *rb;</span>
<span class="quote">&gt;  	struct drm_mm_node *parent;</span>
<span class="quote">&gt; +	bool leftmost = true;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	node-&gt;__subtree_last = LAST(node);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -196,9 +197,10 @@ static void drm_mm_interval_tree_add_node(struct drm_mm_node *hole_node,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		rb = &amp;hole_node-&gt;rb;</span>
<span class="quote">&gt;  		link = &amp;hole_node-&gt;rb.rb_right;</span>
<span class="quote">&gt; +		leftmost = false;</span>
<span class="quote">&gt;  	} else {</span>
<span class="quote">&gt;  		rb = NULL;</span>
<span class="quote">&gt; -		link = &amp;mm-&gt;interval_tree.rb_node;</span>
<span class="quote">&gt; +		link = &amp;mm-&gt;interval_tree.rb_root.rb_node;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	while (*link) {</span>
<span class="quote">&gt; @@ -208,14 +210,15 @@ static void drm_mm_interval_tree_add_node(struct drm_mm_node *hole_node,</span>
<span class="quote">&gt;  			parent-&gt;__subtree_last = node-&gt;__subtree_last;</span>
<span class="quote">&gt;  		if (node-&gt;start &lt; parent-&gt;start)</span>
<span class="quote">&gt;  			link = &amp;parent-&gt;rb.rb_left;</span>
<span class="quote">&gt; -		else</span>
<span class="quote">&gt; +		else {</span>
<span class="quote">&gt;  			link = &amp;parent-&gt;rb.rb_right;</span>
<span class="quote">&gt; +			leftmost = true;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	rb_link_node(&amp;node-&gt;rb, rb, link);</span>
<span class="quote">&gt; -	rb_insert_augmented(&amp;node-&gt;rb,</span>
<span class="quote">&gt; -			    &amp;mm-&gt;interval_tree,</span>
<span class="quote">&gt; -			    &amp;drm_mm_interval_tree_augment);</span>
<span class="quote">&gt; +	rb_insert_augmented_cached(&amp;node-&gt;rb, &amp;mm-&gt;interval_tree, leftmost,</span>
<span class="quote">&gt; +				   &amp;drm_mm_interval_tree_augment);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #define RB_INSERT(root, member, expr) do { \</span>
<span class="quote">&gt; @@ -577,7 +580,7 @@ void drm_mm_replace_node(struct drm_mm_node *old, struct drm_mm_node *new)</span>
<span class="quote">&gt;  	*new = *old;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	list_replace(&amp;old-&gt;node_list, &amp;new-&gt;node_list);</span>
<span class="quote">&gt; -	rb_replace_node(&amp;old-&gt;rb, &amp;new-&gt;rb, &amp;old-&gt;mm-&gt;interval_tree);</span>
<span class="quote">&gt; +	rb_replace_node(&amp;old-&gt;rb, &amp;new-&gt;rb, &amp;old-&gt;mm-&gt;interval_tree.rb_root);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (drm_mm_hole_follows(old)) {</span>
<span class="quote">&gt;  		list_replace(&amp;old-&gt;hole_stack, &amp;new-&gt;hole_stack);</span>
<span class="quote">&gt; @@ -863,7 +866,7 @@ void drm_mm_init(struct drm_mm *mm, u64 start, u64 size)</span>
<span class="quote">&gt;  	mm-&gt;color_adjust = NULL;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	INIT_LIST_HEAD(&amp;mm-&gt;hole_stack);</span>
<span class="quote">&gt; -	mm-&gt;interval_tree = RB_ROOT;</span>
<span class="quote">&gt; +	mm-&gt;interval_tree = RB_ROOT_CACHED;</span>
<span class="quote">&gt;  	mm-&gt;holes_size = RB_ROOT;</span>
<span class="quote">&gt;  	mm-&gt;holes_addr = RB_ROOT;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/drivers/gpu/drm/drm_vma_manager.c b/drivers/gpu/drm/drm_vma_manager.c</span>
<span class="quote">&gt; index d9100b565198..28f1226576f8 100644</span>
<span class="quote">&gt; --- a/drivers/gpu/drm/drm_vma_manager.c</span>
<span class="quote">&gt; +++ b/drivers/gpu/drm/drm_vma_manager.c</span>
<span class="quote">&gt; @@ -147,7 +147,7 @@ struct drm_vma_offset_node *drm_vma_offset_lookup_locked(struct drm_vma_offset_m</span>
<span class="quote">&gt;  	struct rb_node *iter;</span>
<span class="quote">&gt;  	unsigned long offset;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	iter = mgr-&gt;vm_addr_space_mm.interval_tree.rb_node;</span>
<span class="quote">&gt; +	iter = mgr-&gt;vm_addr_space_mm.interval_tree.rb_root.rb_node;</span>
<span class="quote">&gt;  	best = NULL;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	while (likely(iter)) {</span>
<span class="quote">&gt; diff --git a/drivers/gpu/drm/i915/i915_gem_userptr.c b/drivers/gpu/drm/i915/i915_gem_userptr.c</span>
<span class="quote">&gt; index ccd09e8419f5..71dddf66baaa 100644</span>
<span class="quote">&gt; --- a/drivers/gpu/drm/i915/i915_gem_userptr.c</span>
<span class="quote">&gt; +++ b/drivers/gpu/drm/i915/i915_gem_userptr.c</span>
<span class="quote">&gt; @@ -49,7 +49,7 @@ struct i915_mmu_notifier {</span>
<span class="quote">&gt;  	spinlock_t lock;</span>
<span class="quote">&gt;  	struct hlist_node node;</span>
<span class="quote">&gt;  	struct mmu_notifier mn;</span>
<span class="quote">&gt; -	struct rb_root objects;</span>
<span class="quote">&gt; +	struct rb_root_cached objects;</span>
<span class="quote">&gt;  	struct workqueue_struct *wq;</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -123,7 +123,7 @@ static void i915_gem_userptr_mn_invalidate_range_start(struct mmu_notifier *_mn,</span>
<span class="quote">&gt;  	struct interval_tree_node *it;</span>
<span class="quote">&gt;  	LIST_HEAD(cancelled);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (RB_EMPTY_ROOT(&amp;mn-&gt;objects))</span>
<span class="quote">&gt; +	if (RB_EMPTY_ROOT(&amp;mn-&gt;objects.rb_root))</span>
<span class="quote">&gt;  		return;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* interval ranges are inclusive, but invalidate range is exclusive */</span>
<span class="quote">&gt; @@ -172,7 +172,7 @@ i915_mmu_notifier_create(struct mm_struct *mm)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	spin_lock_init(&amp;mn-&gt;lock);</span>
<span class="quote">&gt;  	mn-&gt;mn.ops = &amp;i915_gem_userptr_notifier;</span>
<span class="quote">&gt; -	mn-&gt;objects = RB_ROOT;</span>
<span class="quote">&gt; +	mn-&gt;objects = RB_ROOT_CACHED;</span>
<span class="quote">&gt;  	mn-&gt;wq = alloc_workqueue(&quot;i915-userptr-release&quot;, WQ_UNBOUND, 0);</span>
<span class="quote">&gt;  	if (mn-&gt;wq == NULL) {</span>
<span class="quote">&gt;  		kfree(mn);</span>
<span class="quote">&gt; diff --git a/drivers/gpu/drm/radeon/radeon.h b/drivers/gpu/drm/radeon/radeon.h</span>
<span class="quote">&gt; index 5008f3d4cccc..10d0dd146808 100644</span>
<span class="quote">&gt; --- a/drivers/gpu/drm/radeon/radeon.h</span>
<span class="quote">&gt; +++ b/drivers/gpu/drm/radeon/radeon.h</span>
<span class="quote">&gt; @@ -924,7 +924,7 @@ struct radeon_vm_id {</span>
<span class="quote">&gt;  struct radeon_vm {</span>
<span class="quote">&gt;  	struct mutex		mutex;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	struct rb_root		va;</span>
<span class="quote">&gt; +	struct rb_root_cached	va;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* protecting invalidated and freed */</span>
<span class="quote">&gt;  	spinlock_t		status_lock;</span>
<span class="quote">&gt; diff --git a/drivers/gpu/drm/radeon/radeon_mn.c b/drivers/gpu/drm/radeon/radeon_mn.c</span>
<span class="quote">&gt; index 896f2cf51e4e..1d62288b7ee3 100644</span>
<span class="quote">&gt; --- a/drivers/gpu/drm/radeon/radeon_mn.c</span>
<span class="quote">&gt; +++ b/drivers/gpu/drm/radeon/radeon_mn.c</span>
<span class="quote">&gt; @@ -50,7 +50,7 @@ struct radeon_mn {</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* objects protected by lock */</span>
<span class="quote">&gt;  	struct mutex		lock;</span>
<span class="quote">&gt; -	struct rb_root		objects;</span>
<span class="quote">&gt; +	struct rb_root_cached	objects;</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  struct radeon_mn_node {</span>
<span class="quote">&gt; @@ -75,8 +75,8 @@ static void radeon_mn_destroy(struct work_struct *work)</span>
<span class="quote">&gt;  	mutex_lock(&amp;rdev-&gt;mn_lock);</span>
<span class="quote">&gt;  	mutex_lock(&amp;rmn-&gt;lock);</span>
<span class="quote">&gt;  	hash_del(&amp;rmn-&gt;node);</span>
<span class="quote">&gt; -	rbtree_postorder_for_each_entry_safe(node, next_node, &amp;rmn-&gt;objects,</span>
<span class="quote">&gt; -					     it.rb) {</span>
<span class="quote">&gt; +	rbtree_postorder_for_each_entry_safe(node, next_node,</span>
<span class="quote">&gt; +					     &amp;rmn-&gt;objects.rb_root, it.rb) {</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		interval_tree_remove(&amp;node-&gt;it, &amp;rmn-&gt;objects);</span>
<span class="quote">&gt;  		list_for_each_entry_safe(bo, next_bo, &amp;node-&gt;bos, mn_list) {</span>
<span class="quote">&gt; @@ -205,7 +205,7 @@ static struct radeon_mn *radeon_mn_get(struct radeon_device *rdev)</span>
<span class="quote">&gt;  	rmn-&gt;mm = mm;</span>
<span class="quote">&gt;  	rmn-&gt;mn.ops = &amp;radeon_mn_ops;</span>
<span class="quote">&gt;  	mutex_init(&amp;rmn-&gt;lock);</span>
<span class="quote">&gt; -	rmn-&gt;objects = RB_ROOT;</span>
<span class="quote">&gt; +	rmn-&gt;objects = RB_ROOT_CACHED;</span>
<span class="quote">&gt;  	</span>
<span class="quote">&gt;  	r = __mmu_notifier_register(&amp;rmn-&gt;mn, mm);</span>
<span class="quote">&gt;  	if (r)</span>
<span class="quote">&gt; diff --git a/drivers/gpu/drm/radeon/radeon_vm.c b/drivers/gpu/drm/radeon/radeon_vm.c</span>
<span class="quote">&gt; index 5f68245579a3..f44777a6c2e8 100644</span>
<span class="quote">&gt; --- a/drivers/gpu/drm/radeon/radeon_vm.c</span>
<span class="quote">&gt; +++ b/drivers/gpu/drm/radeon/radeon_vm.c</span>
<span class="quote">&gt; @@ -1185,7 +1185,7 @@ int radeon_vm_init(struct radeon_device *rdev, struct radeon_vm *vm)</span>
<span class="quote">&gt;  		vm-&gt;ids[i].last_id_use = NULL;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	mutex_init(&amp;vm-&gt;mutex);</span>
<span class="quote">&gt; -	vm-&gt;va = RB_ROOT;</span>
<span class="quote">&gt; +	vm-&gt;va = RB_ROOT_CACHED;</span>
<span class="quote">&gt;  	spin_lock_init(&amp;vm-&gt;status_lock);</span>
<span class="quote">&gt;  	INIT_LIST_HEAD(&amp;vm-&gt;invalidated);</span>
<span class="quote">&gt;  	INIT_LIST_HEAD(&amp;vm-&gt;freed);</span>
<span class="quote">&gt; @@ -1232,10 +1232,11 @@ void radeon_vm_fini(struct radeon_device *rdev, struct radeon_vm *vm)</span>
<span class="quote">&gt;  	struct radeon_bo_va *bo_va, *tmp;</span>
<span class="quote">&gt;  	int i, r;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (!RB_EMPTY_ROOT(&amp;vm-&gt;va)) {</span>
<span class="quote">&gt; +	if (!RB_EMPTY_ROOT(&amp;vm-&gt;va.rb_root)) {</span>
<span class="quote">&gt;  		dev_err(rdev-&gt;dev, &quot;still active bo inside vm\n&quot;);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; -	rbtree_postorder_for_each_entry_safe(bo_va, tmp, &amp;vm-&gt;va, it.rb) {</span>
<span class="quote">&gt; +	rbtree_postorder_for_each_entry_safe(bo_va, tmp,</span>
<span class="quote">&gt; +					     &amp;vm-&gt;va.rb_root, it.rb) {</span>
<span class="quote">&gt;  		interval_tree_remove(&amp;bo_va-&gt;it, &amp;vm-&gt;va);</span>
<span class="quote">&gt;  		r = radeon_bo_reserve(bo_va-&gt;bo, false);</span>
<span class="quote">&gt;  		if (!r) {</span>
<span class="quote">&gt; diff --git a/drivers/infiniband/core/umem_rbtree.c b/drivers/infiniband/core/umem_rbtree.c</span>
<span class="quote">&gt; index d176597b4d78..fc801920e341 100644</span>
<span class="quote">&gt; --- a/drivers/infiniband/core/umem_rbtree.c</span>
<span class="quote">&gt; +++ b/drivers/infiniband/core/umem_rbtree.c</span>
<span class="quote">&gt; @@ -72,7 +72,7 @@ INTERVAL_TREE_DEFINE(struct umem_odp_node, rb, u64, __subtree_last,</span>
<span class="quote">&gt;  /* @last is not a part of the interval. See comment for function</span>
<span class="quote">&gt;   * node_last.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; -int rbt_ib_umem_for_each_in_range(struct rb_root *root,</span>
<span class="quote">&gt; +int rbt_ib_umem_for_each_in_range(struct rb_root_cached *root,</span>
<span class="quote">&gt;  				  u64 start, u64 last,</span>
<span class="quote">&gt;  				  umem_call_back cb,</span>
<span class="quote">&gt;  				  void *cookie)</span>
<span class="quote">&gt; @@ -95,7 +95,7 @@ int rbt_ib_umem_for_each_in_range(struct rb_root *root,</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  EXPORT_SYMBOL(rbt_ib_umem_for_each_in_range);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -struct ib_umem_odp *rbt_ib_umem_lookup(struct rb_root *root,</span>
<span class="quote">&gt; +struct ib_umem_odp *rbt_ib_umem_lookup(struct rb_root_cached *root,</span>
<span class="quote">&gt;  				       u64 addr, u64 length)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct umem_odp_node *node;</span>
<span class="quote">&gt; diff --git a/drivers/infiniband/core/uverbs_cmd.c b/drivers/infiniband/core/uverbs_cmd.c</span>
<span class="quote">&gt; index 3f55d18a3791..5321c6ae2c0c 100644</span>
<span class="quote">&gt; --- a/drivers/infiniband/core/uverbs_cmd.c</span>
<span class="quote">&gt; +++ b/drivers/infiniband/core/uverbs_cmd.c</span>
<span class="quote">&gt; @@ -117,7 +117,7 @@ ssize_t ib_uverbs_get_context(struct ib_uverbs_file *file,</span>
<span class="quote">&gt;  	ucontext-&gt;closing = 0;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING</span>
<span class="quote">&gt; -	ucontext-&gt;umem_tree = RB_ROOT;</span>
<span class="quote">&gt; +	ucontext-&gt;umem_tree = RB_ROOT_CACHED;</span>
<span class="quote">&gt;  	init_rwsem(&amp;ucontext-&gt;umem_rwsem);</span>
<span class="quote">&gt;  	ucontext-&gt;odp_mrs_count = 0;</span>
<span class="quote">&gt;  	INIT_LIST_HEAD(&amp;ucontext-&gt;no_private_counters);</span>
<span class="quote">&gt; diff --git a/drivers/infiniband/hw/hfi1/mmu_rb.c b/drivers/infiniband/hw/hfi1/mmu_rb.c</span>
<span class="quote">&gt; index d41fd87a39f2..5b6626f8feb6 100644</span>
<span class="quote">&gt; --- a/drivers/infiniband/hw/hfi1/mmu_rb.c</span>
<span class="quote">&gt; +++ b/drivers/infiniband/hw/hfi1/mmu_rb.c</span>
<span class="quote">&gt; @@ -54,7 +54,7 @@</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  struct mmu_rb_handler {</span>
<span class="quote">&gt;  	struct mmu_notifier mn;</span>
<span class="quote">&gt; -	struct rb_root root;</span>
<span class="quote">&gt; +	struct rb_root_cached root;</span>
<span class="quote">&gt;  	void *ops_arg;</span>
<span class="quote">&gt;  	spinlock_t lock;        /* protect the RB tree */</span>
<span class="quote">&gt;  	struct mmu_rb_ops *ops;</span>
<span class="quote">&gt; @@ -111,7 +111,7 @@ int hfi1_mmu_rb_register(void *ops_arg, struct mm_struct *mm,</span>
<span class="quote">&gt;  	if (!handlr)</span>
<span class="quote">&gt;  		return -ENOMEM;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	handlr-&gt;root = RB_ROOT;</span>
<span class="quote">&gt; +	handlr-&gt;root = RB_ROOT_CACHED;</span>
<span class="quote">&gt;  	handlr-&gt;ops = ops;</span>
<span class="quote">&gt;  	handlr-&gt;ops_arg = ops_arg;</span>
<span class="quote">&gt;  	INIT_HLIST_NODE(&amp;handlr-&gt;mn.hlist);</span>
<span class="quote">&gt; @@ -152,9 +152,9 @@ void hfi1_mmu_rb_unregister(struct mmu_rb_handler *handler)</span>
<span class="quote">&gt;  	INIT_LIST_HEAD(&amp;del_list);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	spin_lock_irqsave(&amp;handler-&gt;lock, flags);</span>
<span class="quote">&gt; -	while ((node = rb_first(&amp;handler-&gt;root))) {</span>
<span class="quote">&gt; +	while ((node = rb_first_cached(&amp;handler-&gt;root))) {</span>
<span class="quote">&gt;  		rbnode = rb_entry(node, struct mmu_rb_node, node);</span>
<span class="quote">&gt; -		rb_erase(node, &amp;handler-&gt;root);</span>
<span class="quote">&gt; +		rb_erase_cached(node, &amp;handler-&gt;root);</span>
<span class="quote">&gt;  		/* move from LRU list to delete list */</span>
<span class="quote">&gt;  		list_move(&amp;rbnode-&gt;list, &amp;del_list);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; @@ -311,7 +311,7 @@ static void mmu_notifier_mem_invalidate(struct mmu_notifier *mn,</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct mmu_rb_handler *handler =</span>
<span class="quote">&gt;  		container_of(mn, struct mmu_rb_handler, mn);</span>
<span class="quote">&gt; -	struct rb_root *root = &amp;handler-&gt;root;</span>
<span class="quote">&gt; +	struct rb_root_cached *root = &amp;handler-&gt;root;</span>
<span class="quote">&gt;  	struct mmu_rb_node *node, *ptr = NULL;</span>
<span class="quote">&gt;  	unsigned long flags;</span>
<span class="quote">&gt;  	bool added = false;</span>
<span class="quote">&gt; diff --git a/drivers/infiniband/hw/usnic/usnic_uiom.c b/drivers/infiniband/hw/usnic/usnic_uiom.c</span>
<span class="quote">&gt; index c49db7c33979..4381c0a9a873 100644</span>
<span class="quote">&gt; --- a/drivers/infiniband/hw/usnic/usnic_uiom.c</span>
<span class="quote">&gt; +++ b/drivers/infiniband/hw/usnic/usnic_uiom.c</span>
<span class="quote">&gt; @@ -227,7 +227,7 @@ static void __usnic_uiom_reg_release(struct usnic_uiom_pd *pd,</span>
<span class="quote">&gt;  	vpn_last = vpn_start + npages - 1;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	spin_lock(&amp;pd-&gt;lock);</span>
<span class="quote">&gt; -	usnic_uiom_remove_interval(&amp;pd-&gt;rb_root, vpn_start,</span>
<span class="quote">&gt; +	usnic_uiom_remove_interval(&amp;pd-&gt;root, vpn_start,</span>
<span class="quote">&gt;  					vpn_last, &amp;rm_intervals);</span>
<span class="quote">&gt;  	usnic_uiom_unmap_sorted_intervals(&amp;rm_intervals, pd);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -379,7 +379,7 @@ struct usnic_uiom_reg *usnic_uiom_reg_get(struct usnic_uiom_pd *pd,</span>
<span class="quote">&gt;  	err = usnic_uiom_get_intervals_diff(vpn_start, vpn_last,</span>
<span class="quote">&gt;  						(writable) ? IOMMU_WRITE : 0,</span>
<span class="quote">&gt;  						IOMMU_WRITE,</span>
<span class="quote">&gt; -						&amp;pd-&gt;rb_root,</span>
<span class="quote">&gt; +						&amp;pd-&gt;root,</span>
<span class="quote">&gt;  						&amp;sorted_diff_intervals);</span>
<span class="quote">&gt;  	if (err) {</span>
<span class="quote">&gt;  		usnic_err(&quot;Failed disjoint interval vpn [0x%lx,0x%lx] err %d\n&quot;,</span>
<span class="quote">&gt; @@ -395,7 +395,7 @@ struct usnic_uiom_reg *usnic_uiom_reg_get(struct usnic_uiom_pd *pd,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	err = usnic_uiom_insert_interval(&amp;pd-&gt;rb_root, vpn_start, vpn_last,</span>
<span class="quote">&gt; +	err = usnic_uiom_insert_interval(&amp;pd-&gt;root, vpn_start, vpn_last,</span>
<span class="quote">&gt;  					(writable) ? IOMMU_WRITE : 0);</span>
<span class="quote">&gt;  	if (err) {</span>
<span class="quote">&gt;  		usnic_err(&quot;Failed insert interval vpn [0x%lx,0x%lx] err %d\n&quot;,</span>
<span class="quote">&gt; diff --git a/drivers/infiniband/hw/usnic/usnic_uiom.h b/drivers/infiniband/hw/usnic/usnic_uiom.h</span>
<span class="quote">&gt; index 45ca7c1613a7..431efe4143f4 100644</span>
<span class="quote">&gt; --- a/drivers/infiniband/hw/usnic/usnic_uiom.h</span>
<span class="quote">&gt; +++ b/drivers/infiniband/hw/usnic/usnic_uiom.h</span>
<span class="quote">&gt; @@ -55,7 +55,7 @@ struct usnic_uiom_dev {</span>
<span class="quote">&gt;  struct usnic_uiom_pd {</span>
<span class="quote">&gt;  	struct iommu_domain		*domain;</span>
<span class="quote">&gt;  	spinlock_t			lock;</span>
<span class="quote">&gt; -	struct rb_root			rb_root;</span>
<span class="quote">&gt; +	struct rb_root_cached		root;</span>
<span class="quote">&gt;  	struct list_head		devs;</span>
<span class="quote">&gt;  	int				dev_cnt;</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt; diff --git a/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.c b/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.c</span>
<span class="quote">&gt; index 42b4b4c4e452..d399523206c7 100644</span>
<span class="quote">&gt; --- a/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.c</span>
<span class="quote">&gt; +++ b/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.c</span>
<span class="quote">&gt; @@ -100,9 +100,9 @@ static int interval_cmp(void *priv, struct list_head *a, struct list_head *b)</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void</span>
<span class="quote">&gt; -find_intervals_intersection_sorted(struct rb_root *root, unsigned long start,</span>
<span class="quote">&gt; -					unsigned long last,</span>
<span class="quote">&gt; -					struct list_head *list)</span>
<span class="quote">&gt; +find_intervals_intersection_sorted(struct rb_root_cached *root,</span>
<span class="quote">&gt; +				   unsigned long start, unsigned long last,</span>
<span class="quote">&gt; +				   struct list_head *list)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct usnic_uiom_interval_node *node;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -118,7 +118,7 @@ find_intervals_intersection_sorted(struct rb_root *root, unsigned long start,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  int usnic_uiom_get_intervals_diff(unsigned long start, unsigned long last,</span>
<span class="quote">&gt;  					int flags, int flag_mask,</span>
<span class="quote">&gt; -					struct rb_root *root,</span>
<span class="quote">&gt; +					struct rb_root_cached *root,</span>
<span class="quote">&gt;  					struct list_head *diff_set)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct usnic_uiom_interval_node *interval, *tmp;</span>
<span class="quote">&gt; @@ -175,7 +175,7 @@ void usnic_uiom_put_interval_set(struct list_head *intervals)</span>
<span class="quote">&gt;  		kfree(interval);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -int usnic_uiom_insert_interval(struct rb_root *root, unsigned long start,</span>
<span class="quote">&gt; +int usnic_uiom_insert_interval(struct rb_root_cached *root, unsigned long start,</span>
<span class="quote">&gt;  				unsigned long last, int flags)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct usnic_uiom_interval_node *interval, *tmp;</span>
<span class="quote">&gt; @@ -246,8 +246,9 @@ int usnic_uiom_insert_interval(struct rb_root *root, unsigned long start,</span>
<span class="quote">&gt;  	return err;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -void usnic_uiom_remove_interval(struct rb_root *root, unsigned long start,</span>
<span class="quote">&gt; -				unsigned long last, struct list_head *removed)</span>
<span class="quote">&gt; +void usnic_uiom_remove_interval(struct rb_root_cached *root,</span>
<span class="quote">&gt; +				unsigned long start, unsigned long last,</span>
<span class="quote">&gt; +				struct list_head *removed)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct usnic_uiom_interval_node *interval;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.h b/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.h</span>
<span class="quote">&gt; index c0b0b876ab90..1d7fc3226bca 100644</span>
<span class="quote">&gt; --- a/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.h</span>
<span class="quote">&gt; +++ b/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.h</span>
<span class="quote">&gt; @@ -48,12 +48,12 @@ struct usnic_uiom_interval_node {</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern void</span>
<span class="quote">&gt;  usnic_uiom_interval_tree_insert(struct usnic_uiom_interval_node *node,</span>
<span class="quote">&gt; -					struct rb_root *root);</span>
<span class="quote">&gt; +					struct rb_root_cached *root);</span>
<span class="quote">&gt;  extern void</span>
<span class="quote">&gt;  usnic_uiom_interval_tree_remove(struct usnic_uiom_interval_node *node,</span>
<span class="quote">&gt; -					struct rb_root *root);</span>
<span class="quote">&gt; +					struct rb_root_cached *root);</span>
<span class="quote">&gt;  extern struct usnic_uiom_interval_node *</span>
<span class="quote">&gt; -usnic_uiom_interval_tree_iter_first(struct rb_root *root,</span>
<span class="quote">&gt; +usnic_uiom_interval_tree_iter_first(struct rb_root_cached *root,</span>
<span class="quote">&gt;  					unsigned long start,</span>
<span class="quote">&gt;  					unsigned long last);</span>
<span class="quote">&gt;  extern struct usnic_uiom_interval_node *</span>
<span class="quote">&gt; @@ -63,7 +63,7 @@ usnic_uiom_interval_tree_iter_next(struct usnic_uiom_interval_node *node,</span>
<span class="quote">&gt;   * Inserts {start...last} into {root}.  If there are overlaps,</span>
<span class="quote">&gt;   * nodes will be broken up and merged</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; -int usnic_uiom_insert_interval(struct rb_root *root,</span>
<span class="quote">&gt; +int usnic_uiom_insert_interval(struct rb_root_cached *root,</span>
<span class="quote">&gt;  				unsigned long start, unsigned long last,</span>
<span class="quote">&gt;  				int flags);</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt; @@ -71,7 +71,7 @@ int usnic_uiom_insert_interval(struct rb_root *root,</span>
<span class="quote">&gt;   * &#39;removed.&#39; The caller is responsibile for freeing memory of nodes in</span>
<span class="quote">&gt;   * &#39;removed.&#39;</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; -void usnic_uiom_remove_interval(struct rb_root *root,</span>
<span class="quote">&gt; +void usnic_uiom_remove_interval(struct rb_root_cached *root,</span>
<span class="quote">&gt;  				unsigned long start, unsigned long last,</span>
<span class="quote">&gt;  				struct list_head *removed);</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt; @@ -81,7 +81,7 @@ void usnic_uiom_remove_interval(struct rb_root *root,</span>
<span class="quote">&gt;  int usnic_uiom_get_intervals_diff(unsigned long start,</span>
<span class="quote">&gt;  					unsigned long last, int flags,</span>
<span class="quote">&gt;  					int flag_mask,</span>
<span class="quote">&gt; -					struct rb_root *root,</span>
<span class="quote">&gt; +					struct rb_root_cached *root,</span>
<span class="quote">&gt;  					struct list_head *diff_set);</span>
<span class="quote">&gt;  /* Call this to free diff_set returned by usnic_uiom_get_intervals_diff */</span>
<span class="quote">&gt;  void usnic_uiom_put_interval_set(struct list_head *intervals);</span>
<span class="quote">&gt; diff --git a/drivers/vhost/vhost.c b/drivers/vhost/vhost.c</span>
<span class="quote">&gt; index e4613a3c362d..88dc214de068 100644</span>
<span class="quote">&gt; --- a/drivers/vhost/vhost.c</span>
<span class="quote">&gt; +++ b/drivers/vhost/vhost.c</span>
<span class="quote">&gt; @@ -1272,7 +1272,7 @@ static struct vhost_umem *vhost_umem_alloc(void)</span>
<span class="quote">&gt;  	if (!umem)</span>
<span class="quote">&gt;  		return NULL;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	umem-&gt;umem_tree = RB_ROOT;</span>
<span class="quote">&gt; +	umem-&gt;umem_tree = RB_ROOT_CACHED;</span>
<span class="quote">&gt;  	umem-&gt;numem = 0;</span>
<span class="quote">&gt;  	INIT_LIST_HEAD(&amp;umem-&gt;umem_list);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/drivers/vhost/vhost.h b/drivers/vhost/vhost.h</span>
<span class="quote">&gt; index f72095868b93..a0278ba6a8b4 100644</span>
<span class="quote">&gt; --- a/drivers/vhost/vhost.h</span>
<span class="quote">&gt; +++ b/drivers/vhost/vhost.h</span>
<span class="quote">&gt; @@ -71,7 +71,7 @@ struct vhost_umem_node {</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  struct vhost_umem {</span>
<span class="quote">&gt; -	struct rb_root umem_tree;</span>
<span class="quote">&gt; +	struct rb_root_cached umem_tree;</span>
<span class="quote">&gt;  	struct list_head umem_list;</span>
<span class="quote">&gt;  	int numem;</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt; diff --git a/fs/hugetlbfs/inode.c b/fs/hugetlbfs/inode.c</span>
<span class="quote">&gt; index 28d2753be094..e61b91e6adf4 100644</span>
<span class="quote">&gt; --- a/fs/hugetlbfs/inode.c</span>
<span class="quote">&gt; +++ b/fs/hugetlbfs/inode.c</span>
<span class="quote">&gt; @@ -334,7 +334,7 @@ static void remove_huge_page(struct page *page)</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void</span>
<span class="quote">&gt; -hugetlb_vmdelete_list(struct rb_root *root, pgoff_t start, pgoff_t end)</span>
<span class="quote">&gt; +hugetlb_vmdelete_list(struct rb_root_cached *root, pgoff_t start, pgoff_t end)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct vm_area_struct *vma;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -514,7 +514,7 @@ static int hugetlb_vmtruncate(struct inode *inode, loff_t offset)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	i_size_write(inode, offset);</span>
<span class="quote">&gt;  	i_mmap_lock_write(mapping);</span>
<span class="quote">&gt; -	if (!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap))</span>
<span class="quote">&gt; +	if (!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap.rb_root))</span>
<span class="quote">&gt;  		hugetlb_vmdelete_list(&amp;mapping-&gt;i_mmap, pgoff, 0);</span>
<span class="quote">&gt;  	i_mmap_unlock_write(mapping);</span>
<span class="quote">&gt;  	remove_inode_hugepages(inode, offset, LLONG_MAX);</span>
<span class="quote">&gt; @@ -539,7 +539,7 @@ static long hugetlbfs_punch_hole(struct inode *inode, loff_t offset, loff_t len)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		inode_lock(inode);</span>
<span class="quote">&gt;  		i_mmap_lock_write(mapping);</span>
<span class="quote">&gt; -		if (!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap))</span>
<span class="quote">&gt; +		if (!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap.rb_root))</span>
<span class="quote">&gt;  			hugetlb_vmdelete_list(&amp;mapping-&gt;i_mmap,</span>
<span class="quote">&gt;  						hole_start &gt;&gt; PAGE_SHIFT,</span>
<span class="quote">&gt;  						hole_end  &gt;&gt; PAGE_SHIFT);</span>
<span class="quote">&gt; diff --git a/fs/inode.c b/fs/inode.c</span>
<span class="quote">&gt; index 50370599e371..5ddb808ea934 100644</span>
<span class="quote">&gt; --- a/fs/inode.c</span>
<span class="quote">&gt; +++ b/fs/inode.c</span>
<span class="quote">&gt; @@ -353,7 +353,7 @@ void address_space_init_once(struct address_space *mapping)</span>
<span class="quote">&gt;  	init_rwsem(&amp;mapping-&gt;i_mmap_rwsem);</span>
<span class="quote">&gt;  	INIT_LIST_HEAD(&amp;mapping-&gt;private_list);</span>
<span class="quote">&gt;  	spin_lock_init(&amp;mapping-&gt;private_lock);</span>
<span class="quote">&gt; -	mapping-&gt;i_mmap = RB_ROOT;</span>
<span class="quote">&gt; +	mapping-&gt;i_mmap = RB_ROOT_CACHED;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  EXPORT_SYMBOL(address_space_init_once);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/include/drm/drm_mm.h b/include/drm/drm_mm.h</span>
<span class="quote">&gt; index 49b292e98fec..8d10fc97801c 100644</span>
<span class="quote">&gt; --- a/include/drm/drm_mm.h</span>
<span class="quote">&gt; +++ b/include/drm/drm_mm.h</span>
<span class="quote">&gt; @@ -172,7 +172,7 @@ struct drm_mm {</span>
<span class="quote">&gt;  	 * according to the (increasing) start address of the memory node. */</span>
<span class="quote">&gt;  	struct drm_mm_node head_node;</span>
<span class="quote">&gt;  	/* Keep an interval_tree for fast lookup of drm_mm_nodes by address. */</span>
<span class="quote">&gt; -	struct rb_root interval_tree;</span>
<span class="quote">&gt; +	struct rb_root_cached interval_tree;</span>
<span class="quote">&gt;  	struct rb_root holes_size;</span>
<span class="quote">&gt;  	struct rb_root holes_addr;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/include/linux/fs.h b/include/linux/fs.h</span>
<span class="quote">&gt; index ed8798255872..d1d521c5025b 100644</span>
<span class="quote">&gt; --- a/include/linux/fs.h</span>
<span class="quote">&gt; +++ b/include/linux/fs.h</span>
<span class="quote">&gt; @@ -392,7 +392,7 @@ struct address_space {</span>
<span class="quote">&gt;  	struct radix_tree_root	page_tree;	/* radix tree of all pages */</span>
<span class="quote">&gt;  	spinlock_t		tree_lock;	/* and lock protecting it */</span>
<span class="quote">&gt;  	atomic_t		i_mmap_writable;/* count VM_SHARED mappings */</span>
<span class="quote">&gt; -	struct rb_root		i_mmap;		/* tree of private and shared mappings */</span>
<span class="quote">&gt; +	struct rb_root_cached	i_mmap;		/* tree of private and shared mappings */</span>
<span class="quote">&gt;  	struct rw_semaphore	i_mmap_rwsem;	/* protect tree, count, list */</span>
<span class="quote">&gt;  	/* Protected by tree_lock together with the radix tree */</span>
<span class="quote">&gt;  	unsigned long		nrpages;	/* number of total pages */</span>
<span class="quote">&gt; @@ -486,7 +486,7 @@ static inline void i_mmap_unlock_read(struct address_space *mapping)</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static inline int mapping_mapped(struct address_space *mapping)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	return	!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap);</span>
<span class="quote">&gt; +	return	!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap.rb_root);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt; diff --git a/include/linux/interval_tree.h b/include/linux/interval_tree.h</span>
<span class="quote">&gt; index 724556aa3c95..202ee1283f4b 100644</span>
<span class="quote">&gt; --- a/include/linux/interval_tree.h</span>
<span class="quote">&gt; +++ b/include/linux/interval_tree.h</span>
<span class="quote">&gt; @@ -11,13 +11,15 @@ struct interval_tree_node {</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern void</span>
<span class="quote">&gt; -interval_tree_insert(struct interval_tree_node *node, struct rb_root *root);</span>
<span class="quote">&gt; +interval_tree_insert(struct interval_tree_node *node,</span>
<span class="quote">&gt; +		     struct rb_root_cached *root);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern void</span>
<span class="quote">&gt; -interval_tree_remove(struct interval_tree_node *node, struct rb_root *root);</span>
<span class="quote">&gt; +interval_tree_remove(struct interval_tree_node *node,</span>
<span class="quote">&gt; +		     struct rb_root_cached *root);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern struct interval_tree_node *</span>
<span class="quote">&gt; -interval_tree_iter_first(struct rb_root *root,</span>
<span class="quote">&gt; +interval_tree_iter_first(struct rb_root_cached *root,</span>
<span class="quote">&gt;  			 unsigned long start, unsigned long last);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern struct interval_tree_node *</span>
<span class="quote">&gt; diff --git a/include/linux/interval_tree_generic.h b/include/linux/interval_tree_generic.h</span>
<span class="quote">&gt; index 58370e1862ad..f096423c8cbd 100644</span>
<span class="quote">&gt; --- a/include/linux/interval_tree_generic.h</span>
<span class="quote">&gt; +++ b/include/linux/interval_tree_generic.h</span>
<span class="quote">&gt; @@ -65,11 +65,13 @@ RB_DECLARE_CALLBACKS(static, ITPREFIX ## _augment, ITSTRUCT, ITRB,	      \</span>
<span class="quote">&gt;  									      \</span>
<span class="quote">&gt;  /* Insert / remove interval nodes from the tree */			      \</span>
<span class="quote">&gt;  									      \</span>
<span class="quote">&gt; -ITSTATIC void ITPREFIX ## _insert(ITSTRUCT *node, struct rb_root *root)	      \</span>
<span class="quote">&gt; +ITSTATIC void ITPREFIX ## _insert(ITSTRUCT *node,			      \</span>
<span class="quote">&gt; +				  struct rb_root_cached *root)	 	      \</span>
<span class="quote">&gt;  {									      \</span>
<span class="quote">&gt; -	struct rb_node **link = &amp;root-&gt;rb_node, *rb_parent = NULL;	      \</span>
<span class="quote">&gt; +	struct rb_node **link = &amp;root-&gt;rb_root.rb_node, *rb_parent = NULL;    \</span>
<span class="quote">&gt;  	ITTYPE start = ITSTART(node), last = ITLAST(node);		      \</span>
<span class="quote">&gt;  	ITSTRUCT *parent;						      \</span>
<span class="quote">&gt; +	bool leftmost = true;						      \</span>
<span class="quote">&gt;  									      \</span>
<span class="quote">&gt;  	while (*link) {							      \</span>
<span class="quote">&gt;  		rb_parent = *link;					      \</span>
<span class="quote">&gt; @@ -78,18 +80,22 @@ ITSTATIC void ITPREFIX ## _insert(ITSTRUCT *node, struct rb_root *root)	      \</span>
<span class="quote">&gt;  			parent-&gt;ITSUBTREE = last;			      \</span>
<span class="quote">&gt;  		if (start &lt; ITSTART(parent))				      \</span>
<span class="quote">&gt;  			link = &amp;parent-&gt;ITRB.rb_left;			      \</span>
<span class="quote">&gt; -		else							      \</span>
<span class="quote">&gt; +		else {							      \</span>
<span class="quote">&gt;  			link = &amp;parent-&gt;ITRB.rb_right;			      \</span>
<span class="quote">&gt; +			leftmost = false;				      \</span>
<span class="quote">&gt; +		}							      \</span>
<span class="quote">&gt;  	}								      \</span>
<span class="quote">&gt;  									      \</span>
<span class="quote">&gt;  	node-&gt;ITSUBTREE = last;						      \</span>
<span class="quote">&gt;  	rb_link_node(&amp;node-&gt;ITRB, rb_parent, link);			      \</span>
<span class="quote">&gt; -	rb_insert_augmented(&amp;node-&gt;ITRB, root, &amp;ITPREFIX ## _augment);	      \</span>
<span class="quote">&gt; +	rb_insert_augmented_cached(&amp;node-&gt;ITRB, root,			      \</span>
<span class="quote">&gt; +				   leftmost, &amp;ITPREFIX ## _augment);	      \</span>
<span class="quote">&gt;  }									      \</span>
<span class="quote">&gt;  									      \</span>
<span class="quote">&gt; -ITSTATIC void ITPREFIX ## _remove(ITSTRUCT *node, struct rb_root *root)	      \</span>
<span class="quote">&gt; +ITSTATIC void ITPREFIX ## _remove(ITSTRUCT *node,			      \</span>
<span class="quote">&gt; +				  struct rb_root_cached *root)		      \</span>
<span class="quote">&gt;  {									      \</span>
<span class="quote">&gt; -	rb_erase_augmented(&amp;node-&gt;ITRB, root, &amp;ITPREFIX ## _augment);	      \</span>
<span class="quote">&gt; +	rb_erase_augmented_cached(&amp;node-&gt;ITRB, root, &amp;ITPREFIX ## _augment);  \</span>
<span class="quote">&gt;  }									      \</span>
<span class="quote">&gt;  									      \</span>
<span class="quote">&gt;  /*									      \</span>
<span class="quote">&gt; @@ -140,15 +146,35 @@ ITPREFIX ## _subtree_search(ITSTRUCT *node, ITTYPE start, ITTYPE last)	      \</span>
<span class="quote">&gt;  }									      \</span>
<span class="quote">&gt;  									      \</span>
<span class="quote">&gt;  ITSTATIC ITSTRUCT *							      \</span>
<span class="quote">&gt; -ITPREFIX ## _iter_first(struct rb_root *root, ITTYPE start, ITTYPE last)      \</span>
<span class="quote">&gt; +ITPREFIX ## _iter_first(struct rb_root_cached *root,			      \</span>
<span class="quote">&gt; +			ITTYPE start, ITTYPE last)			      \</span>
<span class="quote">&gt;  {									      \</span>
<span class="quote">&gt; -	ITSTRUCT *node;							      \</span>
<span class="quote">&gt; +	ITSTRUCT *node, *leftmost;					      \</span>
<span class="quote">&gt;  									      \</span>
<span class="quote">&gt; -	if (!root-&gt;rb_node)						      \</span>
<span class="quote">&gt; +	if (!root-&gt;rb_root.rb_node)					      \</span>
<span class="quote">&gt;  		return NULL;						      \</span>
<span class="quote">&gt; -	node = rb_entry(root-&gt;rb_node, ITSTRUCT, ITRB);			      \</span>
<span class="quote">&gt; +									      \</span>
<span class="quote">&gt; +	/*								      \</span>
<span class="quote">&gt; +	 * Fastpath range intersection/overlap between A: [a0, a1] and	      \</span>
<span class="quote">&gt; +	 * B: [b0, b1] is given by:					      \</span>
<span class="quote">&gt; +	 *								      \</span>
<span class="quote">&gt; +	 *         a0 &lt;= b1 &amp;&amp; b0 &lt;= a1					      \</span>
<span class="quote">&gt; +	 *								      \</span>
<span class="quote">&gt; +	 *  ... where A holds the lock range and B holds the smallest	      \</span>
<span class="quote">&gt; +	 * &#39;start&#39; and largest &#39;last&#39; in the tree. For the later, we	      \</span>
<span class="quote">&gt; +	 * rely on the root node, which by augmented interval tree	      \</span>
<span class="quote">&gt; +	 * property, holds the largest value in its last-in-subtree.	      \</span>
<span class="quote">&gt; +	 * This allows mitigating some of the tree walk overhead for	      \</span>
<span class="quote">&gt; +	 * for non-intersecting ranges, maintained and consulted in O(1).     \</span>
<span class="quote">&gt; +	 */								      \</span>
<span class="quote">&gt; +	node = rb_entry(root-&gt;rb_root.rb_node, ITSTRUCT, ITRB);		      \</span>
<span class="quote">&gt;  	if (node-&gt;ITSUBTREE &lt; start)					      \</span>
<span class="quote">&gt;  		return NULL;						      \</span>
<span class="quote">&gt; +									      \</span>
<span class="quote">&gt; +	leftmost = rb_entry(root-&gt;rb_leftmost, ITSTRUCT, ITRB);		      \</span>
<span class="quote">&gt; +	if (ITSTART(leftmost) &gt; last)					      \</span>
<span class="quote">&gt; +		return NULL;						      \</span>
<span class="quote">&gt; +									      \</span>
<span class="quote">&gt;  	return ITPREFIX ## _subtree_search(node, start, last);		      \</span>
<span class="quote">&gt;  }									      \</span>
<span class="quote">&gt;  									      \</span>
<span class="quote">&gt; diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="quote">&gt; index 46b9ac5e8569..3a2652efbbfb 100644</span>
<span class="quote">&gt; --- a/include/linux/mm.h</span>
<span class="quote">&gt; +++ b/include/linux/mm.h</span>
<span class="quote">&gt; @@ -1992,13 +1992,13 @@ extern int nommu_shrink_inode_mappings(struct inode *, size_t, size_t);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /* interval_tree.c */</span>
<span class="quote">&gt;  void vma_interval_tree_insert(struct vm_area_struct *node,</span>
<span class="quote">&gt; -			      struct rb_root *root);</span>
<span class="quote">&gt; +			      struct rb_root_cached *root);</span>
<span class="quote">&gt;  void vma_interval_tree_insert_after(struct vm_area_struct *node,</span>
<span class="quote">&gt;  				    struct vm_area_struct *prev,</span>
<span class="quote">&gt; -				    struct rb_root *root);</span>
<span class="quote">&gt; +				    struct rb_root_cached *root);</span>
<span class="quote">&gt;  void vma_interval_tree_remove(struct vm_area_struct *node,</span>
<span class="quote">&gt; -			      struct rb_root *root);</span>
<span class="quote">&gt; -struct vm_area_struct *vma_interval_tree_iter_first(struct rb_root *root,</span>
<span class="quote">&gt; +			      struct rb_root_cached *root);</span>
<span class="quote">&gt; +struct vm_area_struct *vma_interval_tree_iter_first(struct rb_root_cached *root,</span>
<span class="quote">&gt;  				unsigned long start, unsigned long last);</span>
<span class="quote">&gt;  struct vm_area_struct *vma_interval_tree_iter_next(struct vm_area_struct *node,</span>
<span class="quote">&gt;  				unsigned long start, unsigned long last);</span>
<span class="quote">&gt; @@ -2008,11 +2008,12 @@ struct vm_area_struct *vma_interval_tree_iter_next(struct vm_area_struct *node,</span>
<span class="quote">&gt;  	     vma; vma = vma_interval_tree_iter_next(vma, start, last))</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void anon_vma_interval_tree_insert(struct anon_vma_chain *node,</span>
<span class="quote">&gt; -				   struct rb_root *root);</span>
<span class="quote">&gt; +				   struct rb_root_cached *root);</span>
<span class="quote">&gt;  void anon_vma_interval_tree_remove(struct anon_vma_chain *node,</span>
<span class="quote">&gt; -				   struct rb_root *root);</span>
<span class="quote">&gt; -struct anon_vma_chain *anon_vma_interval_tree_iter_first(</span>
<span class="quote">&gt; -	struct rb_root *root, unsigned long start, unsigned long last);</span>
<span class="quote">&gt; +				   struct rb_root_cached *root);</span>
<span class="quote">&gt; +struct anon_vma_chain *</span>
<span class="quote">&gt; +anon_vma_interval_tree_iter_first(struct rb_root_cached *root,</span>
<span class="quote">&gt; +				  unsigned long start, unsigned long last);</span>
<span class="quote">&gt;  struct anon_vma_chain *anon_vma_interval_tree_iter_next(</span>
<span class="quote">&gt;  	struct anon_vma_chain *node, unsigned long start, unsigned long last);</span>
<span class="quote">&gt;  #ifdef CONFIG_DEBUG_VM_RB</span>
<span class="quote">&gt; diff --git a/include/linux/rmap.h b/include/linux/rmap.h</span>
<span class="quote">&gt; index 43ef2c30cb0f..22c298c6cc26 100644</span>
<span class="quote">&gt; --- a/include/linux/rmap.h</span>
<span class="quote">&gt; +++ b/include/linux/rmap.h</span>
<span class="quote">&gt; @@ -55,7 +55,9 @@ struct anon_vma {</span>
<span class="quote">&gt;  	 * is serialized by a system wide lock only visible to</span>
<span class="quote">&gt;  	 * mm_take_all_locks() (mm_all_locks_mutex).</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt; -	struct rb_root rb_root;	/* Interval tree of private &quot;related&quot; vmas */</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* Interval tree of private &quot;related&quot; vmas */</span>
<span class="quote">&gt; +	struct rb_root_cached rb_root;</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt; diff --git a/include/rdma/ib_umem_odp.h b/include/rdma/ib_umem_odp.h</span>
<span class="quote">&gt; index fb67554aabd6..5eb7f5bc8248 100644</span>
<span class="quote">&gt; --- a/include/rdma/ib_umem_odp.h</span>
<span class="quote">&gt; +++ b/include/rdma/ib_umem_odp.h</span>
<span class="quote">&gt; @@ -111,22 +111,25 @@ int ib_umem_odp_map_dma_pages(struct ib_umem *umem, u64 start_offset, u64 bcnt,</span>
<span class="quote">&gt;  void ib_umem_odp_unmap_dma_pages(struct ib_umem *umem, u64 start_offset,</span>
<span class="quote">&gt;  				 u64 bound);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -void rbt_ib_umem_insert(struct umem_odp_node *node, struct rb_root *root);</span>
<span class="quote">&gt; -void rbt_ib_umem_remove(struct umem_odp_node *node, struct rb_root *root);</span>
<span class="quote">&gt; +void rbt_ib_umem_insert(struct umem_odp_node *node,</span>
<span class="quote">&gt; +			struct rb_root_cached *root);</span>
<span class="quote">&gt; +void rbt_ib_umem_remove(struct umem_odp_node *node,</span>
<span class="quote">&gt; +			struct rb_root_cached *root);</span>
<span class="quote">&gt;  typedef int (*umem_call_back)(struct ib_umem *item, u64 start, u64 end,</span>
<span class="quote">&gt;  			      void *cookie);</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Call the callback on each ib_umem in the range. Returns the logical or of</span>
<span class="quote">&gt;   * the return values of the functions called.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; -int rbt_ib_umem_for_each_in_range(struct rb_root *root, u64 start, u64 end,</span>
<span class="quote">&gt; +int rbt_ib_umem_for_each_in_range(struct rb_root_cached *root,</span>
<span class="quote">&gt; +				  u64 start, u64 end,</span>
<span class="quote">&gt;  				  umem_call_back cb, void *cookie);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Find first region intersecting with address range.</span>
<span class="quote">&gt;   * Return NULL if not found</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; -struct ib_umem_odp *rbt_ib_umem_lookup(struct rb_root *root,</span>
<span class="quote">&gt; +struct ib_umem_odp *rbt_ib_umem_lookup(struct rb_root_cached *root,</span>
<span class="quote">&gt;  				       u64 addr, u64 length);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline int ib_umem_mmu_notifier_retry(struct ib_umem *item,</span>
<span class="quote">&gt; diff --git a/include/rdma/ib_verbs.h b/include/rdma/ib_verbs.h</span>
<span class="quote">&gt; index 593ad2640d2f..81665480a4ab 100644</span>
<span class="quote">&gt; --- a/include/rdma/ib_verbs.h</span>
<span class="quote">&gt; +++ b/include/rdma/ib_verbs.h</span>
<span class="quote">&gt; @@ -1420,7 +1420,7 @@ struct ib_ucontext {</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	struct pid             *tgid;</span>
<span class="quote">&gt;  #ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING</span>
<span class="quote">&gt; -	struct rb_root      umem_tree;</span>
<span class="quote">&gt; +	struct rb_root_cached   umem_tree;</span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * Protects .umem_rbroot and tree, as well as odp_mrs_count and</span>
<span class="quote">&gt;  	 * mmu notifiers registration.</span>
<span class="quote">&gt; diff --git a/lib/interval_tree_test.c b/lib/interval_tree_test.c</span>
<span class="quote">&gt; index df495fe81421..0e343fd29570 100644</span>
<span class="quote">&gt; --- a/lib/interval_tree_test.c</span>
<span class="quote">&gt; +++ b/lib/interval_tree_test.c</span>
<span class="quote">&gt; @@ -19,14 +19,14 @@ __param(bool, search_all, false, &quot;Searches will iterate all nodes in the tree&quot;);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  __param(uint, max_endpoint, ~0, &quot;Largest value for the interval&#39;s endpoint&quot;);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static struct rb_root root = RB_ROOT;</span>
<span class="quote">&gt; +static struct rb_root_cached root = RB_ROOT_CACHED;</span>
<span class="quote">&gt;  static struct interval_tree_node *nodes = NULL;</span>
<span class="quote">&gt;  static u32 *queries = NULL;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static struct rnd_state rnd;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline unsigned long</span>
<span class="quote">&gt; -search(struct rb_root *root, unsigned long start, unsigned long last)</span>
<span class="quote">&gt; +search(struct rb_root_cached *root, unsigned long start, unsigned long last)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct interval_tree_node *node;</span>
<span class="quote">&gt;  	unsigned long results = 0;</span>
<span class="quote">&gt; diff --git a/mm/interval_tree.c b/mm/interval_tree.c</span>
<span class="quote">&gt; index f2c2492681bf..b47664358796 100644</span>
<span class="quote">&gt; --- a/mm/interval_tree.c</span>
<span class="quote">&gt; +++ b/mm/interval_tree.c</span>
<span class="quote">&gt; @@ -28,7 +28,7 @@ INTERVAL_TREE_DEFINE(struct vm_area_struct, shared.rb,</span>
<span class="quote">&gt;  /* Insert node immediately after prev in the interval tree */</span>
<span class="quote">&gt;  void vma_interval_tree_insert_after(struct vm_area_struct *node,</span>
<span class="quote">&gt;  				    struct vm_area_struct *prev,</span>
<span class="quote">&gt; -				    struct rb_root *root)</span>
<span class="quote">&gt; +				    struct rb_root_cached *root)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct rb_node **link;</span>
<span class="quote">&gt;  	struct vm_area_struct *parent;</span>
<span class="quote">&gt; @@ -55,7 +55,7 @@ void vma_interval_tree_insert_after(struct vm_area_struct *node,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	node-&gt;shared.rb_subtree_last = last;</span>
<span class="quote">&gt;  	rb_link_node(&amp;node-&gt;shared.rb, &amp;parent-&gt;shared.rb, link);</span>
<span class="quote">&gt; -	rb_insert_augmented(&amp;node-&gt;shared.rb, root,</span>
<span class="quote">&gt; +	rb_insert_augmented(&amp;node-&gt;shared.rb, &amp;root-&gt;rb_root,</span>
<span class="quote">&gt;  			    &amp;vma_interval_tree_augment);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -74,7 +74,7 @@ INTERVAL_TREE_DEFINE(struct anon_vma_chain, rb, unsigned long, rb_subtree_last,</span>
<span class="quote">&gt;  		     static inline, __anon_vma_interval_tree)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void anon_vma_interval_tree_insert(struct anon_vma_chain *node,</span>
<span class="quote">&gt; -				   struct rb_root *root)</span>
<span class="quote">&gt; +				   struct rb_root_cached *root)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  #ifdef CONFIG_DEBUG_VM_RB</span>
<span class="quote">&gt;  	node-&gt;cached_vma_start = avc_start_pgoff(node);</span>
<span class="quote">&gt; @@ -84,13 +84,13 @@ void anon_vma_interval_tree_insert(struct anon_vma_chain *node,</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void anon_vma_interval_tree_remove(struct anon_vma_chain *node,</span>
<span class="quote">&gt; -				   struct rb_root *root)</span>
<span class="quote">&gt; +				   struct rb_root_cached *root)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	__anon_vma_interval_tree_remove(node, root);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  struct anon_vma_chain *</span>
<span class="quote">&gt; -anon_vma_interval_tree_iter_first(struct rb_root *root,</span>
<span class="quote">&gt; +anon_vma_interval_tree_iter_first(struct rb_root_cached *root,</span>
<span class="quote">&gt;  				  unsigned long first, unsigned long last)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return __anon_vma_interval_tree_iter_first(root, first, last);</span>
<span class="quote">&gt; diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="quote">&gt; index 0e517be91a89..33cb79f73394 100644</span>
<span class="quote">&gt; --- a/mm/memory.c</span>
<span class="quote">&gt; +++ b/mm/memory.c</span>
<span class="quote">&gt; @@ -2593,7 +2593,7 @@ static void unmap_mapping_range_vma(struct vm_area_struct *vma,</span>
<span class="quote">&gt;  	zap_page_range_single(vma, start_addr, end_addr - start_addr, details);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static inline void unmap_mapping_range_tree(struct rb_root *root,</span>
<span class="quote">&gt; +static inline void unmap_mapping_range_tree(struct rb_root_cached *root,</span>
<span class="quote">&gt;  					    struct zap_details *details)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct vm_area_struct *vma;</span>
<span class="quote">&gt; @@ -2657,7 +2657,7 @@ void unmap_mapping_range(struct address_space *mapping,</span>
<span class="quote">&gt;  		details.last_index = ULONG_MAX;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	i_mmap_lock_write(mapping);</span>
<span class="quote">&gt; -	if (unlikely(!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap)))</span>
<span class="quote">&gt; +	if (unlikely(!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap.rb_root)))</span>
<span class="quote">&gt;  		unmap_mapping_range_tree(&amp;mapping-&gt;i_mmap, &amp;details);</span>
<span class="quote">&gt;  	i_mmap_unlock_write(mapping);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; diff --git a/mm/mmap.c b/mm/mmap.c</span>
<span class="quote">&gt; index f19efcf75418..8121c70df96f 100644</span>
<span class="quote">&gt; --- a/mm/mmap.c</span>
<span class="quote">&gt; +++ b/mm/mmap.c</span>
<span class="quote">&gt; @@ -684,7 +684,7 @@ int __vma_adjust(struct vm_area_struct *vma, unsigned long start,</span>
<span class="quote">&gt;  	struct mm_struct *mm = vma-&gt;vm_mm;</span>
<span class="quote">&gt;  	struct vm_area_struct *next = vma-&gt;vm_next, *orig_vma = vma;</span>
<span class="quote">&gt;  	struct address_space *mapping = NULL;</span>
<span class="quote">&gt; -	struct rb_root *root = NULL;</span>
<span class="quote">&gt; +	struct rb_root_cached *root = NULL;</span>
<span class="quote">&gt;  	struct anon_vma *anon_vma = NULL;</span>
<span class="quote">&gt;  	struct file *file = vma-&gt;vm_file;</span>
<span class="quote">&gt;  	bool start_changed = false, end_changed = false;</span>
<span class="quote">&gt; @@ -3314,7 +3314,7 @@ static DEFINE_MUTEX(mm_all_locks_mutex);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void vm_lock_anon_vma(struct mm_struct *mm, struct anon_vma *anon_vma)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	if (!test_bit(0, (unsigned long *) &amp;anon_vma-&gt;root-&gt;rb_root.rb_node)) {</span>
<span class="quote">&gt; +	if (!test_bit(0, (unsigned long *) &amp;anon_vma-&gt;rb_root.rb_root.rb_node)) {</span>
<span class="quote">&gt;  		/*</span>
<span class="quote">&gt;  		 * The LSB of head.next can&#39;t change from under us</span>
<span class="quote">&gt;  		 * because we hold the mm_all_locks_mutex.</span>
<span class="quote">&gt; @@ -3330,7 +3330,7 @@ static void vm_lock_anon_vma(struct mm_struct *mm, struct anon_vma *anon_vma)</span>
<span class="quote">&gt;  		 * anon_vma-&gt;root-&gt;rwsem.</span>
<span class="quote">&gt;  		 */</span>
<span class="quote">&gt;  		if (__test_and_set_bit(0, (unsigned long *)</span>
<span class="quote">&gt; -				       &amp;anon_vma-&gt;root-&gt;rb_root.rb_node))</span>
<span class="quote">&gt; +				       &amp;anon_vma-&gt;root-&gt;rb_root.rb_root.rb_node))</span>
<span class="quote">&gt;  			BUG();</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -3432,7 +3432,7 @@ int mm_take_all_locks(struct mm_struct *mm)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void vm_unlock_anon_vma(struct anon_vma *anon_vma)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	if (test_bit(0, (unsigned long *) &amp;anon_vma-&gt;root-&gt;rb_root.rb_node)) {</span>
<span class="quote">&gt; +	if (test_bit(0, (unsigned long *) &amp;anon_vma-&gt;root-&gt;rb_root.rb_root.rb_node)) {</span>
<span class="quote">&gt;  		/*</span>
<span class="quote">&gt;  		 * The LSB of head.next can&#39;t change to 0 from under</span>
<span class="quote">&gt;  		 * us because we hold the mm_all_locks_mutex.</span>
<span class="quote">&gt; @@ -3446,7 +3446,7 @@ static void vm_unlock_anon_vma(struct anon_vma *anon_vma)</span>
<span class="quote">&gt;  		 * anon_vma-&gt;root-&gt;rwsem.</span>
<span class="quote">&gt;  		 */</span>
<span class="quote">&gt;  		if (!__test_and_clear_bit(0, (unsigned long *)</span>
<span class="quote">&gt; -					  &amp;anon_vma-&gt;root-&gt;rb_root.rb_node))</span>
<span class="quote">&gt; +					  &amp;anon_vma-&gt;root-&gt;rb_root.rb_root.rb_node))</span>
<span class="quote">&gt;  			BUG();</span>
<span class="quote">&gt;  		anon_vma_unlock_write(anon_vma);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="quote">&gt; index ced14f1af6dc..ad479e5e081d 100644</span>
<span class="quote">&gt; --- a/mm/rmap.c</span>
<span class="quote">&gt; +++ b/mm/rmap.c</span>
<span class="quote">&gt; @@ -390,7 +390,7 @@ void unlink_anon_vmas(struct vm_area_struct *vma)</span>
<span class="quote">&gt;  		 * Leave empty anon_vmas on the list - we&#39;ll need</span>
<span class="quote">&gt;  		 * to free them outside the lock.</span>
<span class="quote">&gt;  		 */</span>
<span class="quote">&gt; -		if (RB_EMPTY_ROOT(&amp;anon_vma-&gt;rb_root)) {</span>
<span class="quote">&gt; +		if (RB_EMPTY_ROOT(&amp;anon_vma-&gt;rb_root.rb_root)) {</span>
<span class="quote">&gt;  			anon_vma-&gt;parent-&gt;degree--;</span>
<span class="quote">&gt;  			continue;</span>
<span class="quote">&gt;  		}</span>
<span class="quote">&gt; @@ -424,7 +424,7 @@ static void anon_vma_ctor(void *data)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	init_rwsem(&amp;anon_vma-&gt;rwsem);</span>
<span class="quote">&gt;  	atomic_set(&amp;anon_vma-&gt;refcount, 0);</span>
<span class="quote">&gt; -	anon_vma-&gt;rb_root = RB_ROOT;</span>
<span class="quote">&gt; +	anon_vma-&gt;rb_root = RB_ROOT_CACHED;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void __init anon_vma_init(void)</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.12.0</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_mn.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_mn.c</span>
<span class="p_header">index 38f739fb727b..3f8aef21b9a6 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_mn.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_mn.c</span>
<span class="p_chunk">@@ -51,7 +51,7 @@</span> <span class="p_context"> struct amdgpu_mn {</span>
 
 	/* objects protected by lock */
 	struct mutex		lock;
<span class="p_del">-	struct rb_root		objects;</span>
<span class="p_add">+	struct rb_root_cached	objects;</span>
 };
 
 struct amdgpu_mn_node {
<span class="p_chunk">@@ -76,8 +76,8 @@</span> <span class="p_context"> static void amdgpu_mn_destroy(struct work_struct *work)</span>
 	mutex_lock(&amp;adev-&gt;mn_lock);
 	mutex_lock(&amp;rmn-&gt;lock);
 	hash_del(&amp;rmn-&gt;node);
<span class="p_del">-	rbtree_postorder_for_each_entry_safe(node, next_node, &amp;rmn-&gt;objects,</span>
<span class="p_del">-					     it.rb) {</span>
<span class="p_add">+	rbtree_postorder_for_each_entry_safe(node, next_node,</span>
<span class="p_add">+					     &amp;rmn-&gt;objects.rb_root, it.rb) {</span>
 		list_for_each_entry_safe(bo, next_bo, &amp;node-&gt;bos, mn_list) {
 			bo-&gt;mn = NULL;
 			list_del_init(&amp;bo-&gt;mn_list);
<span class="p_chunk">@@ -252,7 +252,7 @@</span> <span class="p_context"> static struct amdgpu_mn *amdgpu_mn_get(struct amdgpu_device *adev)</span>
 	rmn-&gt;mm = mm;
 	rmn-&gt;mn.ops = &amp;amdgpu_mn_ops;
 	mutex_init(&amp;rmn-&gt;lock);
<span class="p_del">-	rmn-&gt;objects = RB_ROOT;</span>
<span class="p_add">+	rmn-&gt;objects = RB_ROOT_CACHED;</span>
 
 	r = __mmu_notifier_register(&amp;rmn-&gt;mn, mm);
 	if (r)
<span class="p_header">diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c</span>
<span class="p_header">index 5795f81369f0..f872e2179bbd 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.c</span>
<span class="p_chunk">@@ -2405,7 +2405,7 @@</span> <span class="p_context"> int amdgpu_vm_init(struct amdgpu_device *adev, struct amdgpu_vm *vm,</span>
 	int r, i;
 	u64 flags;
 
<span class="p_del">-	vm-&gt;va = RB_ROOT;</span>
<span class="p_add">+	vm-&gt;va = RB_ROOT_CACHED;</span>
 	vm-&gt;client_id = atomic64_inc_return(&amp;adev-&gt;vm_manager.client_counter);
 	for (i = 0; i &lt; AMDGPU_MAX_VMHUBS; i++)
 		vm-&gt;reserved_vmid[i] = NULL;
<span class="p_chunk">@@ -2512,10 +2512,11 @@</span> <span class="p_context"> void amdgpu_vm_fini(struct amdgpu_device *adev, struct amdgpu_vm *vm)</span>
 
 	amd_sched_entity_fini(vm-&gt;entity.sched, &amp;vm-&gt;entity);
 
<span class="p_del">-	if (!RB_EMPTY_ROOT(&amp;vm-&gt;va)) {</span>
<span class="p_add">+	if (!RB_EMPTY_ROOT(&amp;vm-&gt;va.rb_root)) {</span>
 		dev_err(adev-&gt;dev, &quot;still active bo inside vm\n&quot;);
 	}
<span class="p_del">-	rbtree_postorder_for_each_entry_safe(mapping, tmp, &amp;vm-&gt;va, rb) {</span>
<span class="p_add">+	rbtree_postorder_for_each_entry_safe(mapping, tmp,</span>
<span class="p_add">+					     &amp;vm-&gt;va.rb_root, rb) {</span>
 		list_del(&amp;mapping-&gt;list);
 		amdgpu_vm_it_remove(mapping, &amp;vm-&gt;va);
 		kfree(mapping);
<span class="p_header">diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.h b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.h</span>
<span class="p_header">index 936f158bc5ec..ebffc1253f85 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_vm.h</span>
<span class="p_chunk">@@ -106,7 +106,7 @@</span> <span class="p_context"> struct amdgpu_vm_pt {</span>
 
 struct amdgpu_vm {
 	/* tree of virtual addresses mapped */
<span class="p_del">-	struct rb_root		va;</span>
<span class="p_add">+	struct rb_root_cached	va;</span>
 
 	/* protecting invalidated */
 	spinlock_t		status_lock;
<span class="p_header">diff --git a/drivers/gpu/drm/drm_mm.c b/drivers/gpu/drm/drm_mm.c</span>
<span class="p_header">index f794089d30ac..61a1c8ea74bc 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/drm_mm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/drm_mm.c</span>
<span class="p_chunk">@@ -169,7 +169,7 @@</span> <span class="p_context"> INTERVAL_TREE_DEFINE(struct drm_mm_node, rb,</span>
 struct drm_mm_node *
 __drm_mm_interval_first(const struct drm_mm *mm, u64 start, u64 last)
 {
<span class="p_del">-	return drm_mm_interval_tree_iter_first((struct rb_root *)&amp;mm-&gt;interval_tree,</span>
<span class="p_add">+	return drm_mm_interval_tree_iter_first((struct rb_root_cached *)&amp;mm-&gt;interval_tree,</span>
 					       start, last) ?: (struct drm_mm_node *)&amp;mm-&gt;head_node;
 }
 EXPORT_SYMBOL(__drm_mm_interval_first);
<span class="p_chunk">@@ -180,6 +180,7 @@</span> <span class="p_context"> static void drm_mm_interval_tree_add_node(struct drm_mm_node *hole_node,</span>
 	struct drm_mm *mm = hole_node-&gt;mm;
 	struct rb_node **link, *rb;
 	struct drm_mm_node *parent;
<span class="p_add">+	bool leftmost = true;</span>
 
 	node-&gt;__subtree_last = LAST(node);
 
<span class="p_chunk">@@ -196,9 +197,10 @@</span> <span class="p_context"> static void drm_mm_interval_tree_add_node(struct drm_mm_node *hole_node,</span>
 
 		rb = &amp;hole_node-&gt;rb;
 		link = &amp;hole_node-&gt;rb.rb_right;
<span class="p_add">+		leftmost = false;</span>
 	} else {
 		rb = NULL;
<span class="p_del">-		link = &amp;mm-&gt;interval_tree.rb_node;</span>
<span class="p_add">+		link = &amp;mm-&gt;interval_tree.rb_root.rb_node;</span>
 	}
 
 	while (*link) {
<span class="p_chunk">@@ -208,14 +210,15 @@</span> <span class="p_context"> static void drm_mm_interval_tree_add_node(struct drm_mm_node *hole_node,</span>
 			parent-&gt;__subtree_last = node-&gt;__subtree_last;
 		if (node-&gt;start &lt; parent-&gt;start)
 			link = &amp;parent-&gt;rb.rb_left;
<span class="p_del">-		else</span>
<span class="p_add">+		else {</span>
 			link = &amp;parent-&gt;rb.rb_right;
<span class="p_add">+			leftmost = true;</span>
<span class="p_add">+		}</span>
 	}
 
 	rb_link_node(&amp;node-&gt;rb, rb, link);
<span class="p_del">-	rb_insert_augmented(&amp;node-&gt;rb,</span>
<span class="p_del">-			    &amp;mm-&gt;interval_tree,</span>
<span class="p_del">-			    &amp;drm_mm_interval_tree_augment);</span>
<span class="p_add">+	rb_insert_augmented_cached(&amp;node-&gt;rb, &amp;mm-&gt;interval_tree, leftmost,</span>
<span class="p_add">+				   &amp;drm_mm_interval_tree_augment);</span>
 }
 
 #define RB_INSERT(root, member, expr) do { \
<span class="p_chunk">@@ -577,7 +580,7 @@</span> <span class="p_context"> void drm_mm_replace_node(struct drm_mm_node *old, struct drm_mm_node *new)</span>
 	*new = *old;
 
 	list_replace(&amp;old-&gt;node_list, &amp;new-&gt;node_list);
<span class="p_del">-	rb_replace_node(&amp;old-&gt;rb, &amp;new-&gt;rb, &amp;old-&gt;mm-&gt;interval_tree);</span>
<span class="p_add">+	rb_replace_node(&amp;old-&gt;rb, &amp;new-&gt;rb, &amp;old-&gt;mm-&gt;interval_tree.rb_root);</span>
 
 	if (drm_mm_hole_follows(old)) {
 		list_replace(&amp;old-&gt;hole_stack, &amp;new-&gt;hole_stack);
<span class="p_chunk">@@ -863,7 +866,7 @@</span> <span class="p_context"> void drm_mm_init(struct drm_mm *mm, u64 start, u64 size)</span>
 	mm-&gt;color_adjust = NULL;
 
 	INIT_LIST_HEAD(&amp;mm-&gt;hole_stack);
<span class="p_del">-	mm-&gt;interval_tree = RB_ROOT;</span>
<span class="p_add">+	mm-&gt;interval_tree = RB_ROOT_CACHED;</span>
 	mm-&gt;holes_size = RB_ROOT;
 	mm-&gt;holes_addr = RB_ROOT;
 
<span class="p_header">diff --git a/drivers/gpu/drm/drm_vma_manager.c b/drivers/gpu/drm/drm_vma_manager.c</span>
<span class="p_header">index d9100b565198..28f1226576f8 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/drm_vma_manager.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/drm_vma_manager.c</span>
<span class="p_chunk">@@ -147,7 +147,7 @@</span> <span class="p_context"> struct drm_vma_offset_node *drm_vma_offset_lookup_locked(struct drm_vma_offset_m</span>
 	struct rb_node *iter;
 	unsigned long offset;
 
<span class="p_del">-	iter = mgr-&gt;vm_addr_space_mm.interval_tree.rb_node;</span>
<span class="p_add">+	iter = mgr-&gt;vm_addr_space_mm.interval_tree.rb_root.rb_node;</span>
 	best = NULL;
 
 	while (likely(iter)) {
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_gem_userptr.c b/drivers/gpu/drm/i915/i915_gem_userptr.c</span>
<span class="p_header">index ccd09e8419f5..71dddf66baaa 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_gem_userptr.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_gem_userptr.c</span>
<span class="p_chunk">@@ -49,7 +49,7 @@</span> <span class="p_context"> struct i915_mmu_notifier {</span>
 	spinlock_t lock;
 	struct hlist_node node;
 	struct mmu_notifier mn;
<span class="p_del">-	struct rb_root objects;</span>
<span class="p_add">+	struct rb_root_cached objects;</span>
 	struct workqueue_struct *wq;
 };
 
<span class="p_chunk">@@ -123,7 +123,7 @@</span> <span class="p_context"> static void i915_gem_userptr_mn_invalidate_range_start(struct mmu_notifier *_mn,</span>
 	struct interval_tree_node *it;
 	LIST_HEAD(cancelled);
 
<span class="p_del">-	if (RB_EMPTY_ROOT(&amp;mn-&gt;objects))</span>
<span class="p_add">+	if (RB_EMPTY_ROOT(&amp;mn-&gt;objects.rb_root))</span>
 		return;
 
 	/* interval ranges are inclusive, but invalidate range is exclusive */
<span class="p_chunk">@@ -172,7 +172,7 @@</span> <span class="p_context"> i915_mmu_notifier_create(struct mm_struct *mm)</span>
 
 	spin_lock_init(&amp;mn-&gt;lock);
 	mn-&gt;mn.ops = &amp;i915_gem_userptr_notifier;
<span class="p_del">-	mn-&gt;objects = RB_ROOT;</span>
<span class="p_add">+	mn-&gt;objects = RB_ROOT_CACHED;</span>
 	mn-&gt;wq = alloc_workqueue(&quot;i915-userptr-release&quot;, WQ_UNBOUND, 0);
 	if (mn-&gt;wq == NULL) {
 		kfree(mn);
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon.h b/drivers/gpu/drm/radeon/radeon.h</span>
<span class="p_header">index 5008f3d4cccc..10d0dd146808 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon.h</span>
<span class="p_chunk">@@ -924,7 +924,7 @@</span> <span class="p_context"> struct radeon_vm_id {</span>
 struct radeon_vm {
 	struct mutex		mutex;
 
<span class="p_del">-	struct rb_root		va;</span>
<span class="p_add">+	struct rb_root_cached	va;</span>
 
 	/* protecting invalidated and freed */
 	spinlock_t		status_lock;
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon_mn.c b/drivers/gpu/drm/radeon/radeon_mn.c</span>
<span class="p_header">index 896f2cf51e4e..1d62288b7ee3 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon_mn.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon_mn.c</span>
<span class="p_chunk">@@ -50,7 +50,7 @@</span> <span class="p_context"> struct radeon_mn {</span>
 
 	/* objects protected by lock */
 	struct mutex		lock;
<span class="p_del">-	struct rb_root		objects;</span>
<span class="p_add">+	struct rb_root_cached	objects;</span>
 };
 
 struct radeon_mn_node {
<span class="p_chunk">@@ -75,8 +75,8 @@</span> <span class="p_context"> static void radeon_mn_destroy(struct work_struct *work)</span>
 	mutex_lock(&amp;rdev-&gt;mn_lock);
 	mutex_lock(&amp;rmn-&gt;lock);
 	hash_del(&amp;rmn-&gt;node);
<span class="p_del">-	rbtree_postorder_for_each_entry_safe(node, next_node, &amp;rmn-&gt;objects,</span>
<span class="p_del">-					     it.rb) {</span>
<span class="p_add">+	rbtree_postorder_for_each_entry_safe(node, next_node,</span>
<span class="p_add">+					     &amp;rmn-&gt;objects.rb_root, it.rb) {</span>
 
 		interval_tree_remove(&amp;node-&gt;it, &amp;rmn-&gt;objects);
 		list_for_each_entry_safe(bo, next_bo, &amp;node-&gt;bos, mn_list) {
<span class="p_chunk">@@ -205,7 +205,7 @@</span> <span class="p_context"> static struct radeon_mn *radeon_mn_get(struct radeon_device *rdev)</span>
 	rmn-&gt;mm = mm;
 	rmn-&gt;mn.ops = &amp;radeon_mn_ops;
 	mutex_init(&amp;rmn-&gt;lock);
<span class="p_del">-	rmn-&gt;objects = RB_ROOT;</span>
<span class="p_add">+	rmn-&gt;objects = RB_ROOT_CACHED;</span>
 	
 	r = __mmu_notifier_register(&amp;rmn-&gt;mn, mm);
 	if (r)
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon_vm.c b/drivers/gpu/drm/radeon/radeon_vm.c</span>
<span class="p_header">index 5f68245579a3..f44777a6c2e8 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon_vm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon_vm.c</span>
<span class="p_chunk">@@ -1185,7 +1185,7 @@</span> <span class="p_context"> int radeon_vm_init(struct radeon_device *rdev, struct radeon_vm *vm)</span>
 		vm-&gt;ids[i].last_id_use = NULL;
 	}
 	mutex_init(&amp;vm-&gt;mutex);
<span class="p_del">-	vm-&gt;va = RB_ROOT;</span>
<span class="p_add">+	vm-&gt;va = RB_ROOT_CACHED;</span>
 	spin_lock_init(&amp;vm-&gt;status_lock);
 	INIT_LIST_HEAD(&amp;vm-&gt;invalidated);
 	INIT_LIST_HEAD(&amp;vm-&gt;freed);
<span class="p_chunk">@@ -1232,10 +1232,11 @@</span> <span class="p_context"> void radeon_vm_fini(struct radeon_device *rdev, struct radeon_vm *vm)</span>
 	struct radeon_bo_va *bo_va, *tmp;
 	int i, r;
 
<span class="p_del">-	if (!RB_EMPTY_ROOT(&amp;vm-&gt;va)) {</span>
<span class="p_add">+	if (!RB_EMPTY_ROOT(&amp;vm-&gt;va.rb_root)) {</span>
 		dev_err(rdev-&gt;dev, &quot;still active bo inside vm\n&quot;);
 	}
<span class="p_del">-	rbtree_postorder_for_each_entry_safe(bo_va, tmp, &amp;vm-&gt;va, it.rb) {</span>
<span class="p_add">+	rbtree_postorder_for_each_entry_safe(bo_va, tmp,</span>
<span class="p_add">+					     &amp;vm-&gt;va.rb_root, it.rb) {</span>
 		interval_tree_remove(&amp;bo_va-&gt;it, &amp;vm-&gt;va);
 		r = radeon_bo_reserve(bo_va-&gt;bo, false);
 		if (!r) {
<span class="p_header">diff --git a/drivers/infiniband/core/umem_rbtree.c b/drivers/infiniband/core/umem_rbtree.c</span>
<span class="p_header">index d176597b4d78..fc801920e341 100644</span>
<span class="p_header">--- a/drivers/infiniband/core/umem_rbtree.c</span>
<span class="p_header">+++ b/drivers/infiniband/core/umem_rbtree.c</span>
<span class="p_chunk">@@ -72,7 +72,7 @@</span> <span class="p_context"> INTERVAL_TREE_DEFINE(struct umem_odp_node, rb, u64, __subtree_last,</span>
 /* @last is not a part of the interval. See comment for function
  * node_last.
  */
<span class="p_del">-int rbt_ib_umem_for_each_in_range(struct rb_root *root,</span>
<span class="p_add">+int rbt_ib_umem_for_each_in_range(struct rb_root_cached *root,</span>
 				  u64 start, u64 last,
 				  umem_call_back cb,
 				  void *cookie)
<span class="p_chunk">@@ -95,7 +95,7 @@</span> <span class="p_context"> int rbt_ib_umem_for_each_in_range(struct rb_root *root,</span>
 }
 EXPORT_SYMBOL(rbt_ib_umem_for_each_in_range);
 
<span class="p_del">-struct ib_umem_odp *rbt_ib_umem_lookup(struct rb_root *root,</span>
<span class="p_add">+struct ib_umem_odp *rbt_ib_umem_lookup(struct rb_root_cached *root,</span>
 				       u64 addr, u64 length)
 {
 	struct umem_odp_node *node;
<span class="p_header">diff --git a/drivers/infiniband/core/uverbs_cmd.c b/drivers/infiniband/core/uverbs_cmd.c</span>
<span class="p_header">index 3f55d18a3791..5321c6ae2c0c 100644</span>
<span class="p_header">--- a/drivers/infiniband/core/uverbs_cmd.c</span>
<span class="p_header">+++ b/drivers/infiniband/core/uverbs_cmd.c</span>
<span class="p_chunk">@@ -117,7 +117,7 @@</span> <span class="p_context"> ssize_t ib_uverbs_get_context(struct ib_uverbs_file *file,</span>
 	ucontext-&gt;closing = 0;
 
 #ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
<span class="p_del">-	ucontext-&gt;umem_tree = RB_ROOT;</span>
<span class="p_add">+	ucontext-&gt;umem_tree = RB_ROOT_CACHED;</span>
 	init_rwsem(&amp;ucontext-&gt;umem_rwsem);
 	ucontext-&gt;odp_mrs_count = 0;
 	INIT_LIST_HEAD(&amp;ucontext-&gt;no_private_counters);
<span class="p_header">diff --git a/drivers/infiniband/hw/hfi1/mmu_rb.c b/drivers/infiniband/hw/hfi1/mmu_rb.c</span>
<span class="p_header">index d41fd87a39f2..5b6626f8feb6 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/hfi1/mmu_rb.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/hfi1/mmu_rb.c</span>
<span class="p_chunk">@@ -54,7 +54,7 @@</span> <span class="p_context"></span>
 
 struct mmu_rb_handler {
 	struct mmu_notifier mn;
<span class="p_del">-	struct rb_root root;</span>
<span class="p_add">+	struct rb_root_cached root;</span>
 	void *ops_arg;
 	spinlock_t lock;        /* protect the RB tree */
 	struct mmu_rb_ops *ops;
<span class="p_chunk">@@ -111,7 +111,7 @@</span> <span class="p_context"> int hfi1_mmu_rb_register(void *ops_arg, struct mm_struct *mm,</span>
 	if (!handlr)
 		return -ENOMEM;
 
<span class="p_del">-	handlr-&gt;root = RB_ROOT;</span>
<span class="p_add">+	handlr-&gt;root = RB_ROOT_CACHED;</span>
 	handlr-&gt;ops = ops;
 	handlr-&gt;ops_arg = ops_arg;
 	INIT_HLIST_NODE(&amp;handlr-&gt;mn.hlist);
<span class="p_chunk">@@ -152,9 +152,9 @@</span> <span class="p_context"> void hfi1_mmu_rb_unregister(struct mmu_rb_handler *handler)</span>
 	INIT_LIST_HEAD(&amp;del_list);
 
 	spin_lock_irqsave(&amp;handler-&gt;lock, flags);
<span class="p_del">-	while ((node = rb_first(&amp;handler-&gt;root))) {</span>
<span class="p_add">+	while ((node = rb_first_cached(&amp;handler-&gt;root))) {</span>
 		rbnode = rb_entry(node, struct mmu_rb_node, node);
<span class="p_del">-		rb_erase(node, &amp;handler-&gt;root);</span>
<span class="p_add">+		rb_erase_cached(node, &amp;handler-&gt;root);</span>
 		/* move from LRU list to delete list */
 		list_move(&amp;rbnode-&gt;list, &amp;del_list);
 	}
<span class="p_chunk">@@ -311,7 +311,7 @@</span> <span class="p_context"> static void mmu_notifier_mem_invalidate(struct mmu_notifier *mn,</span>
 {
 	struct mmu_rb_handler *handler =
 		container_of(mn, struct mmu_rb_handler, mn);
<span class="p_del">-	struct rb_root *root = &amp;handler-&gt;root;</span>
<span class="p_add">+	struct rb_root_cached *root = &amp;handler-&gt;root;</span>
 	struct mmu_rb_node *node, *ptr = NULL;
 	unsigned long flags;
 	bool added = false;
<span class="p_header">diff --git a/drivers/infiniband/hw/usnic/usnic_uiom.c b/drivers/infiniband/hw/usnic/usnic_uiom.c</span>
<span class="p_header">index c49db7c33979..4381c0a9a873 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/usnic/usnic_uiom.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/usnic/usnic_uiom.c</span>
<span class="p_chunk">@@ -227,7 +227,7 @@</span> <span class="p_context"> static void __usnic_uiom_reg_release(struct usnic_uiom_pd *pd,</span>
 	vpn_last = vpn_start + npages - 1;
 
 	spin_lock(&amp;pd-&gt;lock);
<span class="p_del">-	usnic_uiom_remove_interval(&amp;pd-&gt;rb_root, vpn_start,</span>
<span class="p_add">+	usnic_uiom_remove_interval(&amp;pd-&gt;root, vpn_start,</span>
 					vpn_last, &amp;rm_intervals);
 	usnic_uiom_unmap_sorted_intervals(&amp;rm_intervals, pd);
 
<span class="p_chunk">@@ -379,7 +379,7 @@</span> <span class="p_context"> struct usnic_uiom_reg *usnic_uiom_reg_get(struct usnic_uiom_pd *pd,</span>
 	err = usnic_uiom_get_intervals_diff(vpn_start, vpn_last,
 						(writable) ? IOMMU_WRITE : 0,
 						IOMMU_WRITE,
<span class="p_del">-						&amp;pd-&gt;rb_root,</span>
<span class="p_add">+						&amp;pd-&gt;root,</span>
 						&amp;sorted_diff_intervals);
 	if (err) {
 		usnic_err(&quot;Failed disjoint interval vpn [0x%lx,0x%lx] err %d\n&quot;,
<span class="p_chunk">@@ -395,7 +395,7 @@</span> <span class="p_context"> struct usnic_uiom_reg *usnic_uiom_reg_get(struct usnic_uiom_pd *pd,</span>
 
 	}
 
<span class="p_del">-	err = usnic_uiom_insert_interval(&amp;pd-&gt;rb_root, vpn_start, vpn_last,</span>
<span class="p_add">+	err = usnic_uiom_insert_interval(&amp;pd-&gt;root, vpn_start, vpn_last,</span>
 					(writable) ? IOMMU_WRITE : 0);
 	if (err) {
 		usnic_err(&quot;Failed insert interval vpn [0x%lx,0x%lx] err %d\n&quot;,
<span class="p_header">diff --git a/drivers/infiniband/hw/usnic/usnic_uiom.h b/drivers/infiniband/hw/usnic/usnic_uiom.h</span>
<span class="p_header">index 45ca7c1613a7..431efe4143f4 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/usnic/usnic_uiom.h</span>
<span class="p_header">+++ b/drivers/infiniband/hw/usnic/usnic_uiom.h</span>
<span class="p_chunk">@@ -55,7 +55,7 @@</span> <span class="p_context"> struct usnic_uiom_dev {</span>
 struct usnic_uiom_pd {
 	struct iommu_domain		*domain;
 	spinlock_t			lock;
<span class="p_del">-	struct rb_root			rb_root;</span>
<span class="p_add">+	struct rb_root_cached		root;</span>
 	struct list_head		devs;
 	int				dev_cnt;
 };
<span class="p_header">diff --git a/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.c b/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.c</span>
<span class="p_header">index 42b4b4c4e452..d399523206c7 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.c</span>
<span class="p_chunk">@@ -100,9 +100,9 @@</span> <span class="p_context"> static int interval_cmp(void *priv, struct list_head *a, struct list_head *b)</span>
 }
 
 static void
<span class="p_del">-find_intervals_intersection_sorted(struct rb_root *root, unsigned long start,</span>
<span class="p_del">-					unsigned long last,</span>
<span class="p_del">-					struct list_head *list)</span>
<span class="p_add">+find_intervals_intersection_sorted(struct rb_root_cached *root,</span>
<span class="p_add">+				   unsigned long start, unsigned long last,</span>
<span class="p_add">+				   struct list_head *list)</span>
 {
 	struct usnic_uiom_interval_node *node;
 
<span class="p_chunk">@@ -118,7 +118,7 @@</span> <span class="p_context"> find_intervals_intersection_sorted(struct rb_root *root, unsigned long start,</span>
 
 int usnic_uiom_get_intervals_diff(unsigned long start, unsigned long last,
 					int flags, int flag_mask,
<span class="p_del">-					struct rb_root *root,</span>
<span class="p_add">+					struct rb_root_cached *root,</span>
 					struct list_head *diff_set)
 {
 	struct usnic_uiom_interval_node *interval, *tmp;
<span class="p_chunk">@@ -175,7 +175,7 @@</span> <span class="p_context"> void usnic_uiom_put_interval_set(struct list_head *intervals)</span>
 		kfree(interval);
 }
 
<span class="p_del">-int usnic_uiom_insert_interval(struct rb_root *root, unsigned long start,</span>
<span class="p_add">+int usnic_uiom_insert_interval(struct rb_root_cached *root, unsigned long start,</span>
 				unsigned long last, int flags)
 {
 	struct usnic_uiom_interval_node *interval, *tmp;
<span class="p_chunk">@@ -246,8 +246,9 @@</span> <span class="p_context"> int usnic_uiom_insert_interval(struct rb_root *root, unsigned long start,</span>
 	return err;
 }
 
<span class="p_del">-void usnic_uiom_remove_interval(struct rb_root *root, unsigned long start,</span>
<span class="p_del">-				unsigned long last, struct list_head *removed)</span>
<span class="p_add">+void usnic_uiom_remove_interval(struct rb_root_cached *root,</span>
<span class="p_add">+				unsigned long start, unsigned long last,</span>
<span class="p_add">+				struct list_head *removed)</span>
 {
 	struct usnic_uiom_interval_node *interval;
 
<span class="p_header">diff --git a/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.h b/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.h</span>
<span class="p_header">index c0b0b876ab90..1d7fc3226bca 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.h</span>
<span class="p_header">+++ b/drivers/infiniband/hw/usnic/usnic_uiom_interval_tree.h</span>
<span class="p_chunk">@@ -48,12 +48,12 @@</span> <span class="p_context"> struct usnic_uiom_interval_node {</span>
 
 extern void
 usnic_uiom_interval_tree_insert(struct usnic_uiom_interval_node *node,
<span class="p_del">-					struct rb_root *root);</span>
<span class="p_add">+					struct rb_root_cached *root);</span>
 extern void
 usnic_uiom_interval_tree_remove(struct usnic_uiom_interval_node *node,
<span class="p_del">-					struct rb_root *root);</span>
<span class="p_add">+					struct rb_root_cached *root);</span>
 extern struct usnic_uiom_interval_node *
<span class="p_del">-usnic_uiom_interval_tree_iter_first(struct rb_root *root,</span>
<span class="p_add">+usnic_uiom_interval_tree_iter_first(struct rb_root_cached *root,</span>
 					unsigned long start,
 					unsigned long last);
 extern struct usnic_uiom_interval_node *
<span class="p_chunk">@@ -63,7 +63,7 @@</span> <span class="p_context"> usnic_uiom_interval_tree_iter_next(struct usnic_uiom_interval_node *node,</span>
  * Inserts {start...last} into {root}.  If there are overlaps,
  * nodes will be broken up and merged
  */
<span class="p_del">-int usnic_uiom_insert_interval(struct rb_root *root,</span>
<span class="p_add">+int usnic_uiom_insert_interval(struct rb_root_cached *root,</span>
 				unsigned long start, unsigned long last,
 				int flags);
 /*
<span class="p_chunk">@@ -71,7 +71,7 @@</span> <span class="p_context"> int usnic_uiom_insert_interval(struct rb_root *root,</span>
  * &#39;removed.&#39; The caller is responsibile for freeing memory of nodes in
  * &#39;removed.&#39;
  */
<span class="p_del">-void usnic_uiom_remove_interval(struct rb_root *root,</span>
<span class="p_add">+void usnic_uiom_remove_interval(struct rb_root_cached *root,</span>
 				unsigned long start, unsigned long last,
 				struct list_head *removed);
 /*
<span class="p_chunk">@@ -81,7 +81,7 @@</span> <span class="p_context"> void usnic_uiom_remove_interval(struct rb_root *root,</span>
 int usnic_uiom_get_intervals_diff(unsigned long start,
 					unsigned long last, int flags,
 					int flag_mask,
<span class="p_del">-					struct rb_root *root,</span>
<span class="p_add">+					struct rb_root_cached *root,</span>
 					struct list_head *diff_set);
 /* Call this to free diff_set returned by usnic_uiom_get_intervals_diff */
 void usnic_uiom_put_interval_set(struct list_head *intervals);
<span class="p_header">diff --git a/drivers/vhost/vhost.c b/drivers/vhost/vhost.c</span>
<span class="p_header">index e4613a3c362d..88dc214de068 100644</span>
<span class="p_header">--- a/drivers/vhost/vhost.c</span>
<span class="p_header">+++ b/drivers/vhost/vhost.c</span>
<span class="p_chunk">@@ -1272,7 +1272,7 @@</span> <span class="p_context"> static struct vhost_umem *vhost_umem_alloc(void)</span>
 	if (!umem)
 		return NULL;
 
<span class="p_del">-	umem-&gt;umem_tree = RB_ROOT;</span>
<span class="p_add">+	umem-&gt;umem_tree = RB_ROOT_CACHED;</span>
 	umem-&gt;numem = 0;
 	INIT_LIST_HEAD(&amp;umem-&gt;umem_list);
 
<span class="p_header">diff --git a/drivers/vhost/vhost.h b/drivers/vhost/vhost.h</span>
<span class="p_header">index f72095868b93..a0278ba6a8b4 100644</span>
<span class="p_header">--- a/drivers/vhost/vhost.h</span>
<span class="p_header">+++ b/drivers/vhost/vhost.h</span>
<span class="p_chunk">@@ -71,7 +71,7 @@</span> <span class="p_context"> struct vhost_umem_node {</span>
 };
 
 struct vhost_umem {
<span class="p_del">-	struct rb_root umem_tree;</span>
<span class="p_add">+	struct rb_root_cached umem_tree;</span>
 	struct list_head umem_list;
 	int numem;
 };
<span class="p_header">diff --git a/fs/hugetlbfs/inode.c b/fs/hugetlbfs/inode.c</span>
<span class="p_header">index 28d2753be094..e61b91e6adf4 100644</span>
<span class="p_header">--- a/fs/hugetlbfs/inode.c</span>
<span class="p_header">+++ b/fs/hugetlbfs/inode.c</span>
<span class="p_chunk">@@ -334,7 +334,7 @@</span> <span class="p_context"> static void remove_huge_page(struct page *page)</span>
 }
 
 static void
<span class="p_del">-hugetlb_vmdelete_list(struct rb_root *root, pgoff_t start, pgoff_t end)</span>
<span class="p_add">+hugetlb_vmdelete_list(struct rb_root_cached *root, pgoff_t start, pgoff_t end)</span>
 {
 	struct vm_area_struct *vma;
 
<span class="p_chunk">@@ -514,7 +514,7 @@</span> <span class="p_context"> static int hugetlb_vmtruncate(struct inode *inode, loff_t offset)</span>
 
 	i_size_write(inode, offset);
 	i_mmap_lock_write(mapping);
<span class="p_del">-	if (!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap))</span>
<span class="p_add">+	if (!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap.rb_root))</span>
 		hugetlb_vmdelete_list(&amp;mapping-&gt;i_mmap, pgoff, 0);
 	i_mmap_unlock_write(mapping);
 	remove_inode_hugepages(inode, offset, LLONG_MAX);
<span class="p_chunk">@@ -539,7 +539,7 @@</span> <span class="p_context"> static long hugetlbfs_punch_hole(struct inode *inode, loff_t offset, loff_t len)</span>
 
 		inode_lock(inode);
 		i_mmap_lock_write(mapping);
<span class="p_del">-		if (!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap))</span>
<span class="p_add">+		if (!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap.rb_root))</span>
 			hugetlb_vmdelete_list(&amp;mapping-&gt;i_mmap,
 						hole_start &gt;&gt; PAGE_SHIFT,
 						hole_end  &gt;&gt; PAGE_SHIFT);
<span class="p_header">diff --git a/fs/inode.c b/fs/inode.c</span>
<span class="p_header">index 50370599e371..5ddb808ea934 100644</span>
<span class="p_header">--- a/fs/inode.c</span>
<span class="p_header">+++ b/fs/inode.c</span>
<span class="p_chunk">@@ -353,7 +353,7 @@</span> <span class="p_context"> void address_space_init_once(struct address_space *mapping)</span>
 	init_rwsem(&amp;mapping-&gt;i_mmap_rwsem);
 	INIT_LIST_HEAD(&amp;mapping-&gt;private_list);
 	spin_lock_init(&amp;mapping-&gt;private_lock);
<span class="p_del">-	mapping-&gt;i_mmap = RB_ROOT;</span>
<span class="p_add">+	mapping-&gt;i_mmap = RB_ROOT_CACHED;</span>
 }
 EXPORT_SYMBOL(address_space_init_once);
 
<span class="p_header">diff --git a/include/drm/drm_mm.h b/include/drm/drm_mm.h</span>
<span class="p_header">index 49b292e98fec..8d10fc97801c 100644</span>
<span class="p_header">--- a/include/drm/drm_mm.h</span>
<span class="p_header">+++ b/include/drm/drm_mm.h</span>
<span class="p_chunk">@@ -172,7 +172,7 @@</span> <span class="p_context"> struct drm_mm {</span>
 	 * according to the (increasing) start address of the memory node. */
 	struct drm_mm_node head_node;
 	/* Keep an interval_tree for fast lookup of drm_mm_nodes by address. */
<span class="p_del">-	struct rb_root interval_tree;</span>
<span class="p_add">+	struct rb_root_cached interval_tree;</span>
 	struct rb_root holes_size;
 	struct rb_root holes_addr;
 
<span class="p_header">diff --git a/include/linux/fs.h b/include/linux/fs.h</span>
<span class="p_header">index ed8798255872..d1d521c5025b 100644</span>
<span class="p_header">--- a/include/linux/fs.h</span>
<span class="p_header">+++ b/include/linux/fs.h</span>
<span class="p_chunk">@@ -392,7 +392,7 @@</span> <span class="p_context"> struct address_space {</span>
 	struct radix_tree_root	page_tree;	/* radix tree of all pages */
 	spinlock_t		tree_lock;	/* and lock protecting it */
 	atomic_t		i_mmap_writable;/* count VM_SHARED mappings */
<span class="p_del">-	struct rb_root		i_mmap;		/* tree of private and shared mappings */</span>
<span class="p_add">+	struct rb_root_cached	i_mmap;		/* tree of private and shared mappings */</span>
 	struct rw_semaphore	i_mmap_rwsem;	/* protect tree, count, list */
 	/* Protected by tree_lock together with the radix tree */
 	unsigned long		nrpages;	/* number of total pages */
<span class="p_chunk">@@ -486,7 +486,7 @@</span> <span class="p_context"> static inline void i_mmap_unlock_read(struct address_space *mapping)</span>
  */
 static inline int mapping_mapped(struct address_space *mapping)
 {
<span class="p_del">-	return	!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap);</span>
<span class="p_add">+	return	!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap.rb_root);</span>
 }
 
 /*
<span class="p_header">diff --git a/include/linux/interval_tree.h b/include/linux/interval_tree.h</span>
<span class="p_header">index 724556aa3c95..202ee1283f4b 100644</span>
<span class="p_header">--- a/include/linux/interval_tree.h</span>
<span class="p_header">+++ b/include/linux/interval_tree.h</span>
<span class="p_chunk">@@ -11,13 +11,15 @@</span> <span class="p_context"> struct interval_tree_node {</span>
 };
 
 extern void
<span class="p_del">-interval_tree_insert(struct interval_tree_node *node, struct rb_root *root);</span>
<span class="p_add">+interval_tree_insert(struct interval_tree_node *node,</span>
<span class="p_add">+		     struct rb_root_cached *root);</span>
 
 extern void
<span class="p_del">-interval_tree_remove(struct interval_tree_node *node, struct rb_root *root);</span>
<span class="p_add">+interval_tree_remove(struct interval_tree_node *node,</span>
<span class="p_add">+		     struct rb_root_cached *root);</span>
 
 extern struct interval_tree_node *
<span class="p_del">-interval_tree_iter_first(struct rb_root *root,</span>
<span class="p_add">+interval_tree_iter_first(struct rb_root_cached *root,</span>
 			 unsigned long start, unsigned long last);
 
 extern struct interval_tree_node *
<span class="p_header">diff --git a/include/linux/interval_tree_generic.h b/include/linux/interval_tree_generic.h</span>
<span class="p_header">index 58370e1862ad..f096423c8cbd 100644</span>
<span class="p_header">--- a/include/linux/interval_tree_generic.h</span>
<span class="p_header">+++ b/include/linux/interval_tree_generic.h</span>
<span class="p_chunk">@@ -65,11 +65,13 @@</span> <span class="p_context"> RB_DECLARE_CALLBACKS(static, ITPREFIX ## _augment, ITSTRUCT, ITRB,	      \</span>
 									      \
 /* Insert / remove interval nodes from the tree */			      \
 									      \
<span class="p_del">-ITSTATIC void ITPREFIX ## _insert(ITSTRUCT *node, struct rb_root *root)	      \</span>
<span class="p_add">+ITSTATIC void ITPREFIX ## _insert(ITSTRUCT *node,			      \</span>
<span class="p_add">+				  struct rb_root_cached *root)	 	      \</span>
 {									      \
<span class="p_del">-	struct rb_node **link = &amp;root-&gt;rb_node, *rb_parent = NULL;	      \</span>
<span class="p_add">+	struct rb_node **link = &amp;root-&gt;rb_root.rb_node, *rb_parent = NULL;    \</span>
 	ITTYPE start = ITSTART(node), last = ITLAST(node);		      \
 	ITSTRUCT *parent;						      \
<span class="p_add">+	bool leftmost = true;						      \</span>
 									      \
 	while (*link) {							      \
 		rb_parent = *link;					      \
<span class="p_chunk">@@ -78,18 +80,22 @@</span> <span class="p_context"> ITSTATIC void ITPREFIX ## _insert(ITSTRUCT *node, struct rb_root *root)	      \</span>
 			parent-&gt;ITSUBTREE = last;			      \
 		if (start &lt; ITSTART(parent))				      \
 			link = &amp;parent-&gt;ITRB.rb_left;			      \
<span class="p_del">-		else							      \</span>
<span class="p_add">+		else {							      \</span>
 			link = &amp;parent-&gt;ITRB.rb_right;			      \
<span class="p_add">+			leftmost = false;				      \</span>
<span class="p_add">+		}							      \</span>
 	}								      \
 									      \
 	node-&gt;ITSUBTREE = last;						      \
 	rb_link_node(&amp;node-&gt;ITRB, rb_parent, link);			      \
<span class="p_del">-	rb_insert_augmented(&amp;node-&gt;ITRB, root, &amp;ITPREFIX ## _augment);	      \</span>
<span class="p_add">+	rb_insert_augmented_cached(&amp;node-&gt;ITRB, root,			      \</span>
<span class="p_add">+				   leftmost, &amp;ITPREFIX ## _augment);	      \</span>
 }									      \
 									      \
<span class="p_del">-ITSTATIC void ITPREFIX ## _remove(ITSTRUCT *node, struct rb_root *root)	      \</span>
<span class="p_add">+ITSTATIC void ITPREFIX ## _remove(ITSTRUCT *node,			      \</span>
<span class="p_add">+				  struct rb_root_cached *root)		      \</span>
 {									      \
<span class="p_del">-	rb_erase_augmented(&amp;node-&gt;ITRB, root, &amp;ITPREFIX ## _augment);	      \</span>
<span class="p_add">+	rb_erase_augmented_cached(&amp;node-&gt;ITRB, root, &amp;ITPREFIX ## _augment);  \</span>
 }									      \
 									      \
 /*									      \
<span class="p_chunk">@@ -140,15 +146,35 @@</span> <span class="p_context"> ITPREFIX ## _subtree_search(ITSTRUCT *node, ITTYPE start, ITTYPE last)	      \</span>
 }									      \
 									      \
 ITSTATIC ITSTRUCT *							      \
<span class="p_del">-ITPREFIX ## _iter_first(struct rb_root *root, ITTYPE start, ITTYPE last)      \</span>
<span class="p_add">+ITPREFIX ## _iter_first(struct rb_root_cached *root,			      \</span>
<span class="p_add">+			ITTYPE start, ITTYPE last)			      \</span>
 {									      \
<span class="p_del">-	ITSTRUCT *node;							      \</span>
<span class="p_add">+	ITSTRUCT *node, *leftmost;					      \</span>
 									      \
<span class="p_del">-	if (!root-&gt;rb_node)						      \</span>
<span class="p_add">+	if (!root-&gt;rb_root.rb_node)					      \</span>
 		return NULL;						      \
<span class="p_del">-	node = rb_entry(root-&gt;rb_node, ITSTRUCT, ITRB);			      \</span>
<span class="p_add">+									      \</span>
<span class="p_add">+	/*								      \</span>
<span class="p_add">+	 * Fastpath range intersection/overlap between A: [a0, a1] and	      \</span>
<span class="p_add">+	 * B: [b0, b1] is given by:					      \</span>
<span class="p_add">+	 *								      \</span>
<span class="p_add">+	 *         a0 &lt;= b1 &amp;&amp; b0 &lt;= a1					      \</span>
<span class="p_add">+	 *								      \</span>
<span class="p_add">+	 *  ... where A holds the lock range and B holds the smallest	      \</span>
<span class="p_add">+	 * &#39;start&#39; and largest &#39;last&#39; in the tree. For the later, we	      \</span>
<span class="p_add">+	 * rely on the root node, which by augmented interval tree	      \</span>
<span class="p_add">+	 * property, holds the largest value in its last-in-subtree.	      \</span>
<span class="p_add">+	 * This allows mitigating some of the tree walk overhead for	      \</span>
<span class="p_add">+	 * for non-intersecting ranges, maintained and consulted in O(1).     \</span>
<span class="p_add">+	 */								      \</span>
<span class="p_add">+	node = rb_entry(root-&gt;rb_root.rb_node, ITSTRUCT, ITRB);		      \</span>
 	if (node-&gt;ITSUBTREE &lt; start)					      \
 		return NULL;						      \
<span class="p_add">+									      \</span>
<span class="p_add">+	leftmost = rb_entry(root-&gt;rb_leftmost, ITSTRUCT, ITRB);		      \</span>
<span class="p_add">+	if (ITSTART(leftmost) &gt; last)					      \</span>
<span class="p_add">+		return NULL;						      \</span>
<span class="p_add">+									      \</span>
 	return ITPREFIX ## _subtree_search(node, start, last);		      \
 }									      \
 									      \
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index 46b9ac5e8569..3a2652efbbfb 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -1992,13 +1992,13 @@</span> <span class="p_context"> extern int nommu_shrink_inode_mappings(struct inode *, size_t, size_t);</span>
 
 /* interval_tree.c */
 void vma_interval_tree_insert(struct vm_area_struct *node,
<span class="p_del">-			      struct rb_root *root);</span>
<span class="p_add">+			      struct rb_root_cached *root);</span>
 void vma_interval_tree_insert_after(struct vm_area_struct *node,
 				    struct vm_area_struct *prev,
<span class="p_del">-				    struct rb_root *root);</span>
<span class="p_add">+				    struct rb_root_cached *root);</span>
 void vma_interval_tree_remove(struct vm_area_struct *node,
<span class="p_del">-			      struct rb_root *root);</span>
<span class="p_del">-struct vm_area_struct *vma_interval_tree_iter_first(struct rb_root *root,</span>
<span class="p_add">+			      struct rb_root_cached *root);</span>
<span class="p_add">+struct vm_area_struct *vma_interval_tree_iter_first(struct rb_root_cached *root,</span>
 				unsigned long start, unsigned long last);
 struct vm_area_struct *vma_interval_tree_iter_next(struct vm_area_struct *node,
 				unsigned long start, unsigned long last);
<span class="p_chunk">@@ -2008,11 +2008,12 @@</span> <span class="p_context"> struct vm_area_struct *vma_interval_tree_iter_next(struct vm_area_struct *node,</span>
 	     vma; vma = vma_interval_tree_iter_next(vma, start, last))
 
 void anon_vma_interval_tree_insert(struct anon_vma_chain *node,
<span class="p_del">-				   struct rb_root *root);</span>
<span class="p_add">+				   struct rb_root_cached *root);</span>
 void anon_vma_interval_tree_remove(struct anon_vma_chain *node,
<span class="p_del">-				   struct rb_root *root);</span>
<span class="p_del">-struct anon_vma_chain *anon_vma_interval_tree_iter_first(</span>
<span class="p_del">-	struct rb_root *root, unsigned long start, unsigned long last);</span>
<span class="p_add">+				   struct rb_root_cached *root);</span>
<span class="p_add">+struct anon_vma_chain *</span>
<span class="p_add">+anon_vma_interval_tree_iter_first(struct rb_root_cached *root,</span>
<span class="p_add">+				  unsigned long start, unsigned long last);</span>
 struct anon_vma_chain *anon_vma_interval_tree_iter_next(
 	struct anon_vma_chain *node, unsigned long start, unsigned long last);
 #ifdef CONFIG_DEBUG_VM_RB
<span class="p_header">diff --git a/include/linux/rmap.h b/include/linux/rmap.h</span>
<span class="p_header">index 43ef2c30cb0f..22c298c6cc26 100644</span>
<span class="p_header">--- a/include/linux/rmap.h</span>
<span class="p_header">+++ b/include/linux/rmap.h</span>
<span class="p_chunk">@@ -55,7 +55,9 @@</span> <span class="p_context"> struct anon_vma {</span>
 	 * is serialized by a system wide lock only visible to
 	 * mm_take_all_locks() (mm_all_locks_mutex).
 	 */
<span class="p_del">-	struct rb_root rb_root;	/* Interval tree of private &quot;related&quot; vmas */</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Interval tree of private &quot;related&quot; vmas */</span>
<span class="p_add">+	struct rb_root_cached rb_root;</span>
 };
 
 /*
<span class="p_header">diff --git a/include/rdma/ib_umem_odp.h b/include/rdma/ib_umem_odp.h</span>
<span class="p_header">index fb67554aabd6..5eb7f5bc8248 100644</span>
<span class="p_header">--- a/include/rdma/ib_umem_odp.h</span>
<span class="p_header">+++ b/include/rdma/ib_umem_odp.h</span>
<span class="p_chunk">@@ -111,22 +111,25 @@</span> <span class="p_context"> int ib_umem_odp_map_dma_pages(struct ib_umem *umem, u64 start_offset, u64 bcnt,</span>
 void ib_umem_odp_unmap_dma_pages(struct ib_umem *umem, u64 start_offset,
 				 u64 bound);
 
<span class="p_del">-void rbt_ib_umem_insert(struct umem_odp_node *node, struct rb_root *root);</span>
<span class="p_del">-void rbt_ib_umem_remove(struct umem_odp_node *node, struct rb_root *root);</span>
<span class="p_add">+void rbt_ib_umem_insert(struct umem_odp_node *node,</span>
<span class="p_add">+			struct rb_root_cached *root);</span>
<span class="p_add">+void rbt_ib_umem_remove(struct umem_odp_node *node,</span>
<span class="p_add">+			struct rb_root_cached *root);</span>
 typedef int (*umem_call_back)(struct ib_umem *item, u64 start, u64 end,
 			      void *cookie);
 /*
  * Call the callback on each ib_umem in the range. Returns the logical or of
  * the return values of the functions called.
  */
<span class="p_del">-int rbt_ib_umem_for_each_in_range(struct rb_root *root, u64 start, u64 end,</span>
<span class="p_add">+int rbt_ib_umem_for_each_in_range(struct rb_root_cached *root,</span>
<span class="p_add">+				  u64 start, u64 end,</span>
 				  umem_call_back cb, void *cookie);
 
 /*
  * Find first region intersecting with address range.
  * Return NULL if not found
  */
<span class="p_del">-struct ib_umem_odp *rbt_ib_umem_lookup(struct rb_root *root,</span>
<span class="p_add">+struct ib_umem_odp *rbt_ib_umem_lookup(struct rb_root_cached *root,</span>
 				       u64 addr, u64 length);
 
 static inline int ib_umem_mmu_notifier_retry(struct ib_umem *item,
<span class="p_header">diff --git a/include/rdma/ib_verbs.h b/include/rdma/ib_verbs.h</span>
<span class="p_header">index 593ad2640d2f..81665480a4ab 100644</span>
<span class="p_header">--- a/include/rdma/ib_verbs.h</span>
<span class="p_header">+++ b/include/rdma/ib_verbs.h</span>
<span class="p_chunk">@@ -1420,7 +1420,7 @@</span> <span class="p_context"> struct ib_ucontext {</span>
 
 	struct pid             *tgid;
 #ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
<span class="p_del">-	struct rb_root      umem_tree;</span>
<span class="p_add">+	struct rb_root_cached   umem_tree;</span>
 	/*
 	 * Protects .umem_rbroot and tree, as well as odp_mrs_count and
 	 * mmu notifiers registration.
<span class="p_header">diff --git a/lib/interval_tree_test.c b/lib/interval_tree_test.c</span>
<span class="p_header">index df495fe81421..0e343fd29570 100644</span>
<span class="p_header">--- a/lib/interval_tree_test.c</span>
<span class="p_header">+++ b/lib/interval_tree_test.c</span>
<span class="p_chunk">@@ -19,14 +19,14 @@</span> <span class="p_context"> __param(bool, search_all, false, &quot;Searches will iterate all nodes in the tree&quot;);</span>
 
 __param(uint, max_endpoint, ~0, &quot;Largest value for the interval&#39;s endpoint&quot;);
 
<span class="p_del">-static struct rb_root root = RB_ROOT;</span>
<span class="p_add">+static struct rb_root_cached root = RB_ROOT_CACHED;</span>
 static struct interval_tree_node *nodes = NULL;
 static u32 *queries = NULL;
 
 static struct rnd_state rnd;
 
 static inline unsigned long
<span class="p_del">-search(struct rb_root *root, unsigned long start, unsigned long last)</span>
<span class="p_add">+search(struct rb_root_cached *root, unsigned long start, unsigned long last)</span>
 {
 	struct interval_tree_node *node;
 	unsigned long results = 0;
<span class="p_header">diff --git a/mm/interval_tree.c b/mm/interval_tree.c</span>
<span class="p_header">index f2c2492681bf..b47664358796 100644</span>
<span class="p_header">--- a/mm/interval_tree.c</span>
<span class="p_header">+++ b/mm/interval_tree.c</span>
<span class="p_chunk">@@ -28,7 +28,7 @@</span> <span class="p_context"> INTERVAL_TREE_DEFINE(struct vm_area_struct, shared.rb,</span>
 /* Insert node immediately after prev in the interval tree */
 void vma_interval_tree_insert_after(struct vm_area_struct *node,
 				    struct vm_area_struct *prev,
<span class="p_del">-				    struct rb_root *root)</span>
<span class="p_add">+				    struct rb_root_cached *root)</span>
 {
 	struct rb_node **link;
 	struct vm_area_struct *parent;
<span class="p_chunk">@@ -55,7 +55,7 @@</span> <span class="p_context"> void vma_interval_tree_insert_after(struct vm_area_struct *node,</span>
 
 	node-&gt;shared.rb_subtree_last = last;
 	rb_link_node(&amp;node-&gt;shared.rb, &amp;parent-&gt;shared.rb, link);
<span class="p_del">-	rb_insert_augmented(&amp;node-&gt;shared.rb, root,</span>
<span class="p_add">+	rb_insert_augmented(&amp;node-&gt;shared.rb, &amp;root-&gt;rb_root,</span>
 			    &amp;vma_interval_tree_augment);
 }
 
<span class="p_chunk">@@ -74,7 +74,7 @@</span> <span class="p_context"> INTERVAL_TREE_DEFINE(struct anon_vma_chain, rb, unsigned long, rb_subtree_last,</span>
 		     static inline, __anon_vma_interval_tree)
 
 void anon_vma_interval_tree_insert(struct anon_vma_chain *node,
<span class="p_del">-				   struct rb_root *root)</span>
<span class="p_add">+				   struct rb_root_cached *root)</span>
 {
 #ifdef CONFIG_DEBUG_VM_RB
 	node-&gt;cached_vma_start = avc_start_pgoff(node);
<span class="p_chunk">@@ -84,13 +84,13 @@</span> <span class="p_context"> void anon_vma_interval_tree_insert(struct anon_vma_chain *node,</span>
 }
 
 void anon_vma_interval_tree_remove(struct anon_vma_chain *node,
<span class="p_del">-				   struct rb_root *root)</span>
<span class="p_add">+				   struct rb_root_cached *root)</span>
 {
 	__anon_vma_interval_tree_remove(node, root);
 }
 
 struct anon_vma_chain *
<span class="p_del">-anon_vma_interval_tree_iter_first(struct rb_root *root,</span>
<span class="p_add">+anon_vma_interval_tree_iter_first(struct rb_root_cached *root,</span>
 				  unsigned long first, unsigned long last)
 {
 	return __anon_vma_interval_tree_iter_first(root, first, last);
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index 0e517be91a89..33cb79f73394 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -2593,7 +2593,7 @@</span> <span class="p_context"> static void unmap_mapping_range_vma(struct vm_area_struct *vma,</span>
 	zap_page_range_single(vma, start_addr, end_addr - start_addr, details);
 }
 
<span class="p_del">-static inline void unmap_mapping_range_tree(struct rb_root *root,</span>
<span class="p_add">+static inline void unmap_mapping_range_tree(struct rb_root_cached *root,</span>
 					    struct zap_details *details)
 {
 	struct vm_area_struct *vma;
<span class="p_chunk">@@ -2657,7 +2657,7 @@</span> <span class="p_context"> void unmap_mapping_range(struct address_space *mapping,</span>
 		details.last_index = ULONG_MAX;
 
 	i_mmap_lock_write(mapping);
<span class="p_del">-	if (unlikely(!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap)))</span>
<span class="p_add">+	if (unlikely(!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap.rb_root)))</span>
 		unmap_mapping_range_tree(&amp;mapping-&gt;i_mmap, &amp;details);
 	i_mmap_unlock_write(mapping);
 }
<span class="p_header">diff --git a/mm/mmap.c b/mm/mmap.c</span>
<span class="p_header">index f19efcf75418..8121c70df96f 100644</span>
<span class="p_header">--- a/mm/mmap.c</span>
<span class="p_header">+++ b/mm/mmap.c</span>
<span class="p_chunk">@@ -684,7 +684,7 @@</span> <span class="p_context"> int __vma_adjust(struct vm_area_struct *vma, unsigned long start,</span>
 	struct mm_struct *mm = vma-&gt;vm_mm;
 	struct vm_area_struct *next = vma-&gt;vm_next, *orig_vma = vma;
 	struct address_space *mapping = NULL;
<span class="p_del">-	struct rb_root *root = NULL;</span>
<span class="p_add">+	struct rb_root_cached *root = NULL;</span>
 	struct anon_vma *anon_vma = NULL;
 	struct file *file = vma-&gt;vm_file;
 	bool start_changed = false, end_changed = false;
<span class="p_chunk">@@ -3314,7 +3314,7 @@</span> <span class="p_context"> static DEFINE_MUTEX(mm_all_locks_mutex);</span>
 
 static void vm_lock_anon_vma(struct mm_struct *mm, struct anon_vma *anon_vma)
 {
<span class="p_del">-	if (!test_bit(0, (unsigned long *) &amp;anon_vma-&gt;root-&gt;rb_root.rb_node)) {</span>
<span class="p_add">+	if (!test_bit(0, (unsigned long *) &amp;anon_vma-&gt;rb_root.rb_root.rb_node)) {</span>
 		/*
 		 * The LSB of head.next can&#39;t change from under us
 		 * because we hold the mm_all_locks_mutex.
<span class="p_chunk">@@ -3330,7 +3330,7 @@</span> <span class="p_context"> static void vm_lock_anon_vma(struct mm_struct *mm, struct anon_vma *anon_vma)</span>
 		 * anon_vma-&gt;root-&gt;rwsem.
 		 */
 		if (__test_and_set_bit(0, (unsigned long *)
<span class="p_del">-				       &amp;anon_vma-&gt;root-&gt;rb_root.rb_node))</span>
<span class="p_add">+				       &amp;anon_vma-&gt;root-&gt;rb_root.rb_root.rb_node))</span>
 			BUG();
 	}
 }
<span class="p_chunk">@@ -3432,7 +3432,7 @@</span> <span class="p_context"> int mm_take_all_locks(struct mm_struct *mm)</span>
 
 static void vm_unlock_anon_vma(struct anon_vma *anon_vma)
 {
<span class="p_del">-	if (test_bit(0, (unsigned long *) &amp;anon_vma-&gt;root-&gt;rb_root.rb_node)) {</span>
<span class="p_add">+	if (test_bit(0, (unsigned long *) &amp;anon_vma-&gt;root-&gt;rb_root.rb_root.rb_node)) {</span>
 		/*
 		 * The LSB of head.next can&#39;t change to 0 from under
 		 * us because we hold the mm_all_locks_mutex.
<span class="p_chunk">@@ -3446,7 +3446,7 @@</span> <span class="p_context"> static void vm_unlock_anon_vma(struct anon_vma *anon_vma)</span>
 		 * anon_vma-&gt;root-&gt;rwsem.
 		 */
 		if (!__test_and_clear_bit(0, (unsigned long *)
<span class="p_del">-					  &amp;anon_vma-&gt;root-&gt;rb_root.rb_node))</span>
<span class="p_add">+					  &amp;anon_vma-&gt;root-&gt;rb_root.rb_root.rb_node))</span>
 			BUG();
 		anon_vma_unlock_write(anon_vma);
 	}
<span class="p_header">diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="p_header">index ced14f1af6dc..ad479e5e081d 100644</span>
<span class="p_header">--- a/mm/rmap.c</span>
<span class="p_header">+++ b/mm/rmap.c</span>
<span class="p_chunk">@@ -390,7 +390,7 @@</span> <span class="p_context"> void unlink_anon_vmas(struct vm_area_struct *vma)</span>
 		 * Leave empty anon_vmas on the list - we&#39;ll need
 		 * to free them outside the lock.
 		 */
<span class="p_del">-		if (RB_EMPTY_ROOT(&amp;anon_vma-&gt;rb_root)) {</span>
<span class="p_add">+		if (RB_EMPTY_ROOT(&amp;anon_vma-&gt;rb_root.rb_root)) {</span>
 			anon_vma-&gt;parent-&gt;degree--;
 			continue;
 		}
<span class="p_chunk">@@ -424,7 +424,7 @@</span> <span class="p_context"> static void anon_vma_ctor(void *data)</span>
 
 	init_rwsem(&amp;anon_vma-&gt;rwsem);
 	atomic_set(&amp;anon_vma-&gt;refcount, 0);
<span class="p_del">-	anon_vma-&gt;rb_root = RB_ROOT;</span>
<span class="p_add">+	anon_vma-&gt;rb_root = RB_ROOT_CACHED;</span>
 }
 
 void __init anon_vma_init(void)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



